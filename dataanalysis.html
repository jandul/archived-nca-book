<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Data analysis | Advances in Necessary Condition Analysis</title>
  <meta name="description" content="Necessary Condition Analysis (NCA) is an emerging research method that is based on necessity logic. If a condition is not present, the outcome will not exist. Other factors cannot compensate for its absence. This is different from common causal reasoning where factors produce the outcome and can be compensated. The book intends to support users, readers and reviewers of NCA to better understand the method." />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Data analysis | Advances in Necessary Condition Analysis" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://bookdown.org/ncabook/advanced_nca2//Image/cover2b.png" />
  <meta property="og:description" content="Necessary Condition Analysis (NCA) is an emerging research method that is based on necessity logic. If a condition is not present, the outcome will not exist. Other factors cannot compensate for its absence. This is different from common causal reasoning where factors produce the outcome and can be compensated. The book intends to support users, readers and reviewers of NCA to better understand the method." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Data analysis | Advances in Necessary Condition Analysis" />
  
  <meta name="twitter:description" content="Necessary Condition Analysis (NCA) is an emerging research method that is based on necessity logic. If a condition is not present, the outcome will not exist. Other factors cannot compensate for its absence. This is different from common causal reasoning where factors produce the outcome and can be compensated. The book intends to support users, readers and reviewers of NCA to better understand the method." />
  <meta name="twitter:image" content="https://bookdown.org/ncabook/advanced_nca2//Image/cover2b.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data.html"/>
<link rel="next" href="mathematical.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.33/datatables.js"></script>
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
|<img src="logoNCA.png" width="270" height="270">
<li><a href="./">Advances in NCA</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1</b> Summary of NCA</a>
<ul>
<li class="chapter" data-level="1.1" data-path="summary.html"><a href="summary.html#standalone"><i class="fa fa-check"></i><b>1.1</b> NCA as stand-alone method</a></li>
<li class="chapter" data-level="1.2" data-path="summary.html"><a href="summary.html#complementary"><i class="fa fa-check"></i><b>1.2</b> NCA as a complementary method</a></li>
<li class="chapter" data-level="1.3" data-path="summary.html"><a href="summary.html#formulate"><i class="fa fa-check"></i><b>1.3</b> Formulate the necessary condition hypothesis</a></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html#collect"><i class="fa fa-check"></i><b>1.4</b> Collect the data</a></li>
<li class="chapter" data-level="1.5" data-path="summary.html"><a href="summary.html#dataanalysissummary"><i class="fa fa-check"></i><b>1.5</b> Analyse the data</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="summary.html"><a href="summary.html#prepare-the-analysis"><i class="fa fa-check"></i><b>1.5.1</b> Prepare the analysis</a></li>
<li class="chapter" data-level="1.5.2" data-path="summary.html"><a href="summary.html#load-the-data"><i class="fa fa-check"></i><b>1.5.2</b> Load the data</a></li>
<li class="chapter" data-level="1.5.3" data-path="summary.html"><a href="summary.html#estimate-effect-size-and-the-p-value-with-nca_analysis"><i class="fa fa-check"></i><b>1.5.3</b> Estimate effect size and the p value with <code>nca_analysis</code></a></li>
<li class="chapter" data-level="1.5.4" data-path="summary.html"><a href="summary.html#create-output-with-nca_output"><i class="fa fa-check"></i><b>1.5.4</b> Create output with <code>nca_output</code></a></li>
<li class="chapter" data-level="1.5.5" data-path="summary.html"><a href="summary.html#summarybottleneck"><i class="fa fa-check"></i><b>1.5.5</b> Perform the bottleneck analysis with <code>nca_output</code></a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="summary.html"><a href="summary.html#report"><i class="fa fa-check"></i><b>1.6</b> Report the results</a></li>
<li class="chapter" data-level="1.7" data-path="summary.html"><a href="summary.html#guidelines"><i class="fa fa-check"></i><b>1.7</b> Basic guidelines for good NCA practice</a></li>
<li class="chapter" data-level="1.8" data-path="summary.html"><a href="summary.html#review"><i class="fa fa-check"></i><b>1.8</b> SCoRe-NCA. A checklist for reviewing an NCA publication</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>2</b> Theory</a>
<ul>
<li class="chapter" data-level="2.1" data-path="theory.html"><a href="theory.html#partstheory"><i class="fa fa-check"></i><b>2.1</b> The four parts of a theory</a></li>
<li class="chapter" data-level="2.2" data-path="theory.html"><a href="theory.html#formulationnecessity"><i class="fa fa-check"></i><b>2.2</b> Formulation of necessity hypotheses</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="theory.html"><a href="theory.html#sources"><i class="fa fa-check"></i><b>2.2.1</b> Sources with potential necessary conditions</a></li>
<li class="chapter" data-level="2.2.2" data-path="theory.html"><a href="theory.html#thoughtexperiment"><i class="fa fa-check"></i><b>2.2.2</b> Thought experiment</a></li>
<li class="chapter" data-level="2.2.3" data-path="theory.html"><a href="theory.html#direction"><i class="fa fa-check"></i><b>2.2.3</b> Direction of necessity</a></li>
<li class="chapter" data-level="2.2.4" data-path="theory.html"><a href="theory.html#relatedmultiple"><i class="fa fa-check"></i><b>2.2.4</b> Related multiple necessary conditions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="theory.html"><a href="theory.html#justificationnecessity"><i class="fa fa-check"></i><b>2.3</b> Justification of necessity hypotheses</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="theory.html"><a href="theory.html#temporalorder"><i class="fa fa-check"></i><b>2.3.1</b> Temporal order</a></li>
<li class="chapter" data-level="2.3.2" data-path="theory.html"><a href="theory.html#causalmechanism"><i class="fa fa-check"></i><b>2.3.2</b> Causal mechinism</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="theory.html"><a href="theory.html#theoreticalcontribution"><i class="fa fa-check"></i><b>2.4</b> Theoretical contribution</a></li>
<li class="chapter" data-level="2.5" data-path="theory.html"><a href="theory.html#theorytypes"><i class="fa fa-check"></i><b>2.5</b> Types of necessity theories</a></li>
<li class="chapter" data-level="2.6" data-path="theory.html"><a href="theory.html#morecorners"><i class="fa fa-check"></i><b>2.6</b> Two empty corners</a></li>
<li class="chapter" data-level="2.7" data-path="theory.html"><a href="theory.html#necessarybutnotsufficient"><i class="fa fa-check"></i><b>2.7</b> The meaning of ‘necessary but not sufficient’</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data.html"><a href="data.html#transformation"><i class="fa fa-check"></i><b>3.1</b> Data transformation</a></li>
<li class="chapter" data-level="3.2" data-path="data.html"><a href="data.html#experiment"><i class="fa fa-check"></i><b>3.2</b> Experiment</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="data.html"><a href="data.html#the-traditional-experiment"><i class="fa fa-check"></i><b>3.2.1</b> The traditional experiment</a></li>
<li class="chapter" data-level="3.2.2" data-path="data.html"><a href="data.html#necessityexperiment"><i class="fa fa-check"></i><b>3.2.2</b> The necessity experiment</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data.html"><a href="data.html#samplesize"><i class="fa fa-check"></i><b>3.3</b> Sample size</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="data.html"><a href="data.html#smalln"><i class="fa fa-check"></i><b>3.3.1</b> Small N studies</a></li>
<li class="chapter" data-level="3.3.2" data-path="data.html"><a href="data.html#largen"><i class="fa fa-check"></i><b>3.3.2</b> Large N studies</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="data.html"><a href="data.html#quantitative"><i class="fa fa-check"></i><b>3.4</b> Quantitative data</a></li>
<li class="chapter" data-level="3.5" data-path="data.html"><a href="data.html#qualitative"><i class="fa fa-check"></i><b>3.5</b> Qualitative data</a></li>
<li class="chapter" data-level="3.6" data-path="data.html"><a href="data.html#longitudinal"><i class="fa fa-check"></i><b>3.6</b> Longitudinal, panel and time-series data</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="data.html"><a href="data.html#pooled"><i class="fa fa-check"></i><b>3.6.1</b> NCA with pooled data</a></li>
<li class="chapter" data-level="3.6.2" data-path="data.html"><a href="data.html#nca-for-describing-time-trends"><i class="fa fa-check"></i><b>3.6.2</b> NCA for describing time trends</a></li>
<li class="chapter" data-level="3.6.3" data-path="data.html"><a href="data.html#interpretation"><i class="fa fa-check"></i><b>3.6.3</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="data.html"><a href="data.html#setmembership"><i class="fa fa-check"></i><b>3.7</b> Set membership data</a></li>
<li class="chapter" data-level="3.8" data-path="data.html"><a href="data.html#outliers"><i class="fa fa-check"></i><b>3.8</b> Outliers</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="data.html"><a href="data.html#outliertypes"><i class="fa fa-check"></i><b>3.8.1</b> Outlier types</a></li>
<li class="chapter" data-level="3.8.2" data-path="data.html"><a href="data.html#outlieridentification"><i class="fa fa-check"></i><b>3.8.2</b> Outlier identification</a></li>
<li class="chapter" data-level="3.8.3" data-path="data.html"><a href="data.html#outlierdecisionmaking"><i class="fa fa-check"></i><b>3.8.3</b> Outlier decision approach</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dataanalysis.html"><a href="dataanalysis.html"><i class="fa fa-check"></i><b>4</b> Data analysis</a>
<ul>
<li class="chapter" data-level="4.1" data-path="dataanalysis.html"><a href="dataanalysis.html#visualinspection"><i class="fa fa-check"></i><b>4.1</b> Visual inspection of the scatter plot</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="dataanalysis.html"><a href="dataanalysis.html#is-the-expected-corner-empty"><i class="fa fa-check"></i><b>4.1.1</b> Is the expected corner empty?</a></li>
<li class="chapter" data-level="4.1.2" data-path="dataanalysis.html"><a href="dataanalysis.html#selectioneilingline"><i class="fa fa-check"></i><b>4.1.2</b> What is an appropriate ceiling line?</a></li>
<li class="chapter" data-level="4.1.3" data-path="dataanalysis.html"><a href="dataanalysis.html#what-are-potential-outliers"><i class="fa fa-check"></i><b>4.1.3</b> What are potential outliers?</a></li>
<li class="chapter" data-level="4.1.4" data-path="dataanalysis.html"><a href="dataanalysis.html#what-is-the-data-pattern-in-the-rest-of-plot"><i class="fa fa-check"></i><b>4.1.4</b> What is the data pattern in the rest of plot?</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="dataanalysis.html"><a href="dataanalysis.html#inkind"><i class="fa fa-check"></i><b>4.2</b> The ‘empty space: Necessary condition ’in kind’</a></li>
<li class="chapter" data-level="4.3" data-path="dataanalysis.html"><a href="dataanalysis.html#bottleneck"><i class="fa fa-check"></i><b>4.3</b> The bottleneck table: Necessary conditions ‘in degree’</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="dataanalysis.html"><a href="dataanalysis.html#percentagerange"><i class="fa fa-check"></i><b>4.3.1</b> Levels expressed as percentage of range</a></li>
<li class="chapter" data-level="4.3.2" data-path="dataanalysis.html"><a href="dataanalysis.html#actual"><i class="fa fa-check"></i><b>4.3.2</b> Levels expressed as actual values</a></li>
<li class="chapter" data-level="4.3.3" data-path="dataanalysis.html"><a href="dataanalysis.html#percentile"><i class="fa fa-check"></i><b>4.3.3</b> Levels expressed as percentiles</a></li>
<li class="chapter" data-level="4.3.4" data-path="dataanalysis.html"><a href="dataanalysis.html#percentagemax"><i class="fa fa-check"></i><b>4.3.4</b> Levels expressed as percentage of maximum</a></li>
<li class="chapter" data-level="4.3.5" data-path="dataanalysis.html"><a href="dataanalysis.html#bottleneckothercorners"><i class="fa fa-check"></i><b>4.3.5</b> Interpretation of the bottleneck table with other corners</a></li>
<li class="chapter" data-level="4.3.6" data-path="dataanalysis.html"><a href="dataanalysis.html#na"><i class="fa fa-check"></i><b>4.3.6</b> NN and NA in the bottleneck table</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="dataanalysis.html"><a href="dataanalysis.html#robustnesschecks"><i class="fa fa-check"></i><b>4.4</b> Robustness checks</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="dataanalysis.html"><a href="dataanalysis.html#choiceceiling"><i class="fa fa-check"></i><b>4.4.1</b> Choice of ceiling line</a></li>
<li class="chapter" data-level="4.4.2" data-path="dataanalysis.html"><a href="dataanalysis.html#choiceeffectsize"><i class="fa fa-check"></i><b>4.4.2</b> Choice of the threshold level of the effect size</a></li>
<li class="chapter" data-level="4.4.3" data-path="dataanalysis.html"><a href="dataanalysis.html#choicepvalue"><i class="fa fa-check"></i><b>4.4.3</b> Choice of the threshold level of the p value</a></li>
<li class="chapter" data-level="4.4.4" data-path="dataanalysis.html"><a href="dataanalysis.html#choicescope"><i class="fa fa-check"></i><b>4.4.4</b> Choice of the scope</a></li>
<li class="chapter" data-level="4.4.5" data-path="dataanalysis.html"><a href="dataanalysis.html#choiceoutlier"><i class="fa fa-check"></i><b>4.4.5</b> Choice of outlier removal</a></li>
<li class="chapter" data-level="4.4.6" data-path="dataanalysis.html"><a href="dataanalysis.html#choice-of-target-outcome"><i class="fa fa-check"></i><b>4.4.6</b> Choice of target outcome</a></li>
<li class="chapter" data-level="4.4.7" data-path="dataanalysis.html"><a href="dataanalysis.html#robustnesstable"><i class="fa fa-check"></i><b>4.4.7</b> Robustness table</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="dataanalysis.html"><a href="dataanalysis.html#ncaregression"><i class="fa fa-check"></i><b>4.5</b> Combining NCA with regression analysis</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="dataanalysis.html"><a href="dataanalysis.html#introduction"><i class="fa fa-check"></i><b>4.5.1</b> Introduction</a></li>
<li class="chapter" data-level="4.5.2" data-path="dataanalysis.html"><a href="dataanalysis.html#logic-and-theory"><i class="fa fa-check"></i><b>4.5.2</b> Logic and theory</a></li>
<li class="chapter" data-level="4.5.3" data-path="dataanalysis.html"><a href="dataanalysis.html#data-analysis"><i class="fa fa-check"></i><b>4.5.3</b> Data analysis</a></li>
<li class="chapter" data-level="4.5.4" data-path="dataanalysis.html"><a href="dataanalysis.html#how-to-combine-nca-and-regression"><i class="fa fa-check"></i><b>4.5.4</b> How to combine NCA and regression</a></li>
<li class="chapter" data-level="4.5.5" data-path="dataanalysis.html"><a href="dataanalysis.html#what-is-the-same-in-nca-and-regression"><i class="fa fa-check"></i><b>4.5.5</b> What is the same in NCA and regression?</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="dataanalysis.html"><a href="dataanalysis.html#ncaplssem"><i class="fa fa-check"></i><b>4.6</b> Combining NCA with (PLS-)SEM</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="dataanalysis.html"><a href="dataanalysis.html#stepsncasem"><i class="fa fa-check"></i><b>4.6.1</b> Steps for conducting NCA with SEM</a></li>
<li class="chapter" data-level="4.6.2" data-path="dataanalysis.html"><a href="dataanalysis.html#examplencaplssem"><i class="fa fa-check"></i><b>4.6.2</b> Demonstration of combining NCA and PLS-SEM with R</a></li>
<li class="chapter" data-level="4.6.3" data-path="dataanalysis.html"><a href="dataanalysis.html#recommendations-for-combining-nca-and-pls-sem"><i class="fa fa-check"></i><b>4.6.3</b> Recommendations for combining NCA and (PLS-)SEM</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="dataanalysis.html"><a href="dataanalysis.html#ncaqca"><i class="fa fa-check"></i><b>4.7</b> Combining NCA with QCA</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="dataanalysis.html"><a href="dataanalysis.html#introduction-to-qca"><i class="fa fa-check"></i><b>4.7.1</b> Introduction to QCA</a></li>
<li class="chapter" data-level="4.7.2" data-path="dataanalysis.html"><a href="dataanalysis.html#the-differences-between-nca-and-qca"><i class="fa fa-check"></i><b>4.7.2</b> The differences between NCA and QCA</a></li>
<li class="chapter" data-level="4.7.3" data-path="dataanalysis.html"><a href="dataanalysis.html#recommendation-for-combining-nca-and-qca"><i class="fa fa-check"></i><b>4.7.3</b> Recommendation for combining NCA and QCA</a></li>
<li class="chapter" data-level="4.7.4" data-path="dataanalysis.html"><a href="dataanalysis.html#examples"><i class="fa fa-check"></i><b>4.7.4</b> Examples</a></li>
<li class="chapter" data-level="4.7.5" data-path="dataanalysis.html"><a href="dataanalysis.html#misinterpretationsqca"><i class="fa fa-check"></i><b>4.7.5</b> Logical misinterpretations when combining NCA and QCA</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="dataanalysis.html"><a href="dataanalysis.html#causalinference"><i class="fa fa-check"></i><b>4.8</b> Causal inference</a></li>
<li class="chapter" data-level="4.9" data-path="dataanalysis.html"><a href="dataanalysis.html#metaanalysis"><i class="fa fa-check"></i><b>4.9</b> Meta-analysis</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mathematical.html"><a href="mathematical.html"><i class="fa fa-check"></i><b>5</b> NCA’s mathematical backgrounds</a>
<ul>
<li class="chapter" data-level="5.1" data-path="mathematical.html"><a href="mathematical.html#formalexpression"><i class="fa fa-check"></i><b>5.1</b> Formal mathematical expression</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="mathematical.html"><a href="mathematical.html#effectsize"><i class="fa fa-check"></i><b>5.1.1</b> Effect size</a></li>
<li class="chapter" data-level="5.1.2" data-path="mathematical.html"><a href="mathematical.html#necinefficiency"><i class="fa fa-check"></i><b>5.1.2</b> Necessity inefficiency</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="mathematical.html"><a href="mathematical.html#multiplenca"><i class="fa fa-check"></i><b>5.2</b> Multiple NCA</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistical.html"><a href="statistical.html"><i class="fa fa-check"></i><b>6</b> NCA’s statistics</a>
<ul>
<li class="chapter" data-level="6.1" data-path="statistical.html"><a href="statistical.html#ncas-statistical-expression"><i class="fa fa-check"></i><b>6.1</b> NCA’s statistical expression</a></li>
<li class="chapter" data-level="6.2" data-path="statistical.html"><a href="statistical.html#permutationtest"><i class="fa fa-check"></i><b>6.2</b> NCA’s statistical test</a></li>
<li class="chapter" data-level="6.3" data-path="statistical.html"><a href="statistical.html#simulations-with-nca"><i class="fa fa-check"></i><b>6.3</b> Simulations with NCA</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="statistical.html"><a href="statistical.html#requirementssim"><i class="fa fa-check"></i><b>6.3.1</b> Requirements for simulations with NCA</a></li>
<li class="chapter" data-level="6.3.2" data-path="statistical.html"><a href="statistical.html#power"><i class="fa fa-check"></i><b>6.3.2</b> Simulations for estimating the power of NCA’s statistical test</a></li>
<li class="chapter" data-level="6.3.3" data-path="statistical.html"><a href="statistical.html#ceilingquality"><i class="fa fa-check"></i><b>6.3.3</b> Simulations for evaluating a ceiling line and its effect size</a></li>
<li class="chapter" data-level="6.3.4" data-path="statistical.html"><a href="statistical.html#simulations-of-correlation"><i class="fa fa-check"></i><b>6.3.4</b> Simulations of correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="miscellaneous.html"><a href="miscellaneous.html"><i class="fa fa-check"></i><b>7</b> Miscellaneous</a>
<ul>
<li class="chapter" data-level="7.1" data-path="miscellaneous.html"><a href="miscellaneous.html#software"><i class="fa fa-check"></i><b>7.1</b> NCA software</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="miscellaneous.html"><a href="miscellaneous.html#rsoftware"><i class="fa fa-check"></i><b>7.1.1</b> Main NCA software: R package</a></li>
<li class="chapter" data-level="7.1.2" data-path="miscellaneous.html"><a href="miscellaneous.html#othersoftware"><i class="fa fa-check"></i><b>7.1.2</b> Other NCA software packages</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="miscellaneous.html"><a href="miscellaneous.html#learning-about-nca"><i class="fa fa-check"></i><b>7.2</b> Learning about NCA</a></li>
<li class="chapter" data-level="7.3" data-path="miscellaneous.html"><a href="miscellaneous.html#hqscatterplots"><i class="fa fa-check"></i><b>7.3</b> Producing high-quality NCA scatter plots</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="miscellaneous.html"><a href="miscellaneous.html#standard-plot"><i class="fa fa-check"></i><b>7.3.1</b> Standard plot</a></li>
<li class="chapter" data-level="7.3.2" data-path="miscellaneous.html"><a href="miscellaneous.html#standard-plot-with-basic-adaptations"><i class="fa fa-check"></i><b>7.3.2</b> Standard plot with basic adaptations</a></li>
<li class="chapter" data-level="7.3.3" data-path="miscellaneous.html"><a href="miscellaneous.html#standard-plot-with-advanced-adaptations"><i class="fa fa-check"></i><b>7.3.3</b> Standard plot with advanced adaptations</a></li>
<li class="chapter" data-level="7.3.4" data-path="miscellaneous.html"><a href="miscellaneous.html#plot-with-plotly"><i class="fa fa-check"></i><b>7.3.4</b> Plot with <code>plotly</code></a></li>
<li class="chapter" data-level="7.3.5" data-path="miscellaneous.html"><a href="miscellaneous.html#plot-with-ggplot"><i class="fa fa-check"></i><b>7.3.5</b> Plot with <code>ggplot</code></a></li>
<li class="chapter" data-level="7.3.6" data-path="miscellaneous.html"><a href="miscellaneous.html#saving-the-plot-from-within-the-r-script"><i class="fa fa-check"></i><b>7.3.6</b> Saving the plot from within the R script</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="miscellaneous.html"><a href="miscellaneous.html#additionalcode"><i class="fa fa-check"></i><b>7.4</b> Additional functions for use with the NCA softare in R (beta)</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="miscellaneous.html"><a href="miscellaneous.html#ncarobustnesstablegeneral"><i class="fa fa-check"></i><b>7.4.1</b> <code>nca_robustness_table_general.R</code></a></li>
<li class="chapter" data-level="7.4.2" data-path="miscellaneous.html"><a href="miscellaneous.html#ncarobustnesschecksgeneral"><i class="fa fa-check"></i><b>7.4.2</b> <code>nca_robustness_checks_general.R</code></a></li>
<li class="chapter" data-level="7.4.3" data-path="miscellaneous.html"><a href="miscellaneous.html#getoutliers"><i class="fa fa-check"></i><b>7.4.3</b> <code>get_outliers.R</code></a></li>
<li class="chapter" data-level="7.4.4" data-path="miscellaneous.html"><a href="miscellaneous.html#getindicatordata"><i class="fa fa-check"></i><b>7.4.4</b> <code>get_indicator_data_TAM.R</code></a></li>
<li class="chapter" data-level="7.4.5" data-path="miscellaneous.html"><a href="miscellaneous.html#estimatesemmodel"><i class="fa fa-check"></i><b>7.4.5</b> <code>estimate_sem_model_TAM.R</code></a></li>
<li class="chapter" data-level="7.4.6" data-path="miscellaneous.html"><a href="miscellaneous.html#significancesem"><i class="fa fa-check"></i><b>7.4.6</b> <code>get_signficance_sem.R</code></a></li>
<li class="chapter" data-level="7.4.7" data-path="miscellaneous.html"><a href="miscellaneous.html#unstandardize"><i class="fa fa-check"></i><b>7.4.7</b> <code>unstandardize.R</code></a></li>
<li class="chapter" data-level="7.4.8" data-path="miscellaneous.html"><a href="miscellaneous.html#normalize"><i class="fa fa-check"></i><b>7.4.8</b> <code>normalize.R</code></a></li>
<li class="chapter" data-level="7.4.9" data-path="miscellaneous.html"><a href="miscellaneous.html#getbottleneckcases"><i class="fa fa-check"></i><b>7.4.9</b> <code>get_bottleneck_cases.R</code></a></li>
<li class="chapter" data-level="7.4.10" data-path="miscellaneous.html"><a href="miscellaneous.html#getipmadf"><i class="fa fa-check"></i><b>7.4.10</b> <code>get_ipma_df.R</code></a></li>
<li class="chapter" data-level="7.4.11" data-path="miscellaneous.html"><a href="miscellaneous.html#getipmaplot"><i class="fa fa-check"></i><b>7.4.11</b> <code>get_ipma_plot.R</code></a></li>
<li class="chapter" data-level="7.4.12" data-path="miscellaneous.html"><a href="miscellaneous.html#getcipmadf"><i class="fa fa-check"></i><b>7.4.12</b> <code>get_cipma_df.R</code></a></li>
<li class="chapter" data-level="7.4.13" data-path="miscellaneous.html"><a href="miscellaneous.html#getcipmaplot"><i class="fa fa-check"></i><b>7.4.13</b> <code>get_cipma_plot.R</code></a></li>
<li class="chapter" data-level="7.4.14" data-path="miscellaneous.html"><a href="miscellaneous.html#getsinglebottleneckcases"><i class="fa fa-check"></i><b>7.4.14</b> <code>get_single_bottleneck_cases.R</code></a></li>
<li class="chapter" data-level="7.4.15" data-path="miscellaneous.html"><a href="miscellaneous.html#getbipmadf"><i class="fa fa-check"></i><b>7.4.15</b> <code>get_bipma_df.R</code></a></li>
<li class="chapter" data-level="7.4.16" data-path="miscellaneous.html"><a href="miscellaneous.html#getbipmaplot"><i class="fa fa-check"></i><b>7.4.16</b> <code>get_bipma_plot.R</code></a></li>
<li class="chapter" data-level="7.4.17" data-path="miscellaneous.html"><a href="miscellaneous.html#ncasem"><i class="fa fa-check"></i><b>7.4.17</b> <code>ncasem.R</code></a></li>
<li class="chapter" data-level="7.4.18" data-path="miscellaneous.html"><a href="miscellaneous.html#ncasemexample"><i class="fa fa-check"></i><b>7.4.18</b> <code>ncasem_example_TAM.R</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="glossary.html"><a href="glossary.html"><i class="fa fa-check"></i>Glossary</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<a href="https://www.erim.eur.nl/necessary-condition-analysis/">
<img alt="erim" src="NCAwebsite2.png" width="270"></a
<a href="https://www.erim.eur.nl/necessary-condition-analysis/" target="blank">NCA website</a></li>
<li><a href="mailto:jdul@rsm.nl">Send email to the author</a>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advances in Necessary Condition Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="dataanalysis" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> Data analysis<a href="dataanalysis.html#dataanalysis" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<!-- ## \textcolor{gray}{The absence of control variables} -->
<!-- ## <span style="color: #D3D3D3">The absence of control variables</span> -->
<!-- Under construction -->
<div id="visualinspection" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Visual inspection of the scatter plot<a href="dataanalysis.html#visualinspection" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The starting point for NCA’s data analysis is a visual inspection of the <span class="math inline">\(XY\)</span> scatter plot. This is a qualitative examination of the data pattern. By visual inspection the following questions can be answered:</p>
<ul>
<li>Is the expected corner of the <span class="math inline">\(XY\)</span> plot empty?</li>
<li>What is an appropriate ceiling line?</li>
<li>What are potential outliers?</li>
<li>What is the data pattern in the rest of plot?</li>
</ul>
<p>Visual inspection of the scatter plot is illustrated with <code>nca.example</code>, in particular for testing of the hypothesis that Individualism is necessary for Innovation performance. Figure <a href="dataanalysis.html#fig:visualinspectionfig">4.1</a> shows the scatter plot of Individualism versus Innovation performance with all 28 cases as black dots.</p>
<div class="figure"><span style="display:block;" id="fig:visualinspectionfig"></span>
<img src="visualinspection2.png" alt="Scatter plot of Individualism and  Innovation performance for evaluating the empty space, the appropriateness of the ceiling line, potential outliers, and the density of the cases in relevant areas." width="100%" />
<p class="caption">
Figure 4.1: Scatter plot of Individualism and Innovation performance for evaluating the empty space, the appropriateness of the ceiling line, potential outliers, and the density of the cases in relevant areas.
</p>
</div>
<div id="is-the-expected-corner-empty" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Is the expected corner empty?<a href="dataanalysis.html#is-the-expected-corner-empty" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>According to the hypothesis a high level of <span class="math inline">\(X\)</span> is necessary for a high level of <span class="math inline">\(Y\)</span> such that the upper left corner is expected to be empty. Figure <a href="dataanalysis.html#fig:visualinspectionfig">4.1</a> shows that cases with a low value of <span class="math inline">\(X\)</span> have a low value of <span class="math inline">\(Y\)</span>, and that cases with a high value of <span class="math inline">\(Y\)</span> have a high value of <span class="math inline">\(X\)</span>. The upper left corner is indeed empty. NCA’s effect size quantifies the size of the empty area in the scatter plot. After visual inspection the size of the empty space can be obtained with the <code>NCA</code> software by using the <code>summaries</code> argument of the <code>nca_output</code> function.</p>
</div>
<div id="selectioneilingline" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> What is an appropriate ceiling line?<a href="dataanalysis.html#selectioneilingline" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The ceiling line represents the border between the area with cases and the area without cases. Figure <a href="dataanalysis.html#fig:visualinspectionfig">4.1</a> shows the two default ceiling lines. The CR-FDH ceiling is often selected when the border is theoretically assumed to be linear, or when the condition and outcome have many levels (e.g., are continuous). The CE-FDH ceiling is often selected when the condition or outcome have few levels (e.g., are discrete). When the decision about the ceiling line is not made a priori the ceiling line can be selected by visual inspection of the scatter plot. When de border looks linear the CR-FDH line may be selected, and when it looks non-linear the CE-FDH line may be the best choice. After visual inspection the appropriateness of the ceiling line may be verified with the NCA’s ceiling accuracty and fit measures. Ceiling accuracy is the percentage of cases on or below the ceiling line. The ceiling accuracy of an appropriate ceiling line is close to 100%. NCA’s fit measure is the effect size of a selected ceiling as a percentage of the effect size of the CE-FDH line. The selected ceiling line may be inappropriate when fit deviates considerably from 100%. Ceiling accuracy and fit can be obtained with the <code>NCA</code> software by using the <code>summaries</code> argument of <code>nca_output</code> function.</p>
</div>
<div id="what-are-potential-outliers" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> What are potential outliers?<a href="dataanalysis.html#what-are-potential-outliers" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Outliers are cases that are relatively ‘far away’ from other cases. These cases can be identified by visual inspection of the scatter plot. In NCA potential outliers are the cases that construct the ceiling line (‘ceiling outliers’) and the cases that construct the scope (‘scope outliers’). NCA defines an outlier as a case that has a large influence on the effect size when removed (see Section <a href="data.html#outliers">3.8</a>). After visual inspection, potential outliers can be verified with the <code>NCA</code> software by using the <code>nca_outlier</code> function.</p>
</div>
<div id="what-is-the-data-pattern-in-the-rest-of-plot" class="section level3 hasAnchor" number="4.1.4">
<h3><span class="header-section-number">4.1.4</span> What is the data pattern in the rest of plot?<a href="dataanalysis.html#what-is-the-data-pattern-in-the-rest-of-plot" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Although NCA focuses on the empty area in the scatter plot, the full space can also be informative for necessity. In particular the density of cases in other corners, the density of cases near the scope limits, and the density of cases near the ceiling line contain relevant information for necessity.</p>
<div id="density-of-cases-in-other-corners" class="section level4 hasAnchor" number="4.1.4.1">
<h4><span class="header-section-number">4.1.4.1</span> Density of cases in other corners<a href="dataanalysis.html#density-of-cases-in-other-corners" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The presence of many cases in the lower left corner, thus cases with a low value of <span class="math inline">\(X\)</span> that do not show a high value of <span class="math inline">\(Y\)</span>, is supportive for the necessary condition hypothesis. Similarly, the presence of many cases in the upper right corner, thus cases with a high value of <span class="math inline">\(X\)</span> that show a high value of <span class="math inline">\(Y\)</span>, is also supportive for the necessary condition hypothesis. If only a few cases were present in these corners the emptiness of the upper left corner could be a random result. This also applies when the majority of cases are in the lower right corner. After visual inspection, the randomness of the empty space (when the variables are unrelated) is identified with NCA’s statistical test that is part of the <code>NCA</code> software. The NCA’s p value can be obtained by using the <code>test.rep</code> argument in the <code>nca_analysis</code> function and by subsequently by using the <code>summaries</code> argument in the <code>nca_output</code> function.</p>
<p>Although NCA focuses on the emptiness of the corner that is expected to be empty according to the hypothesis, it is also possible to explore the <em>emptiness</em> of other corners. When theoretical support is available, the emptiness of another corner could be formulated as an additional necessary condition hypothesis. Such hypothesis is formulated in terms of the absence or a low value of <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> (see Section <a href="theory.html#morecorners">2.6</a>). After visual inspection, any corner in the scatter plot can be evaluated with the NCA software by using the <code>corner</code> argument in the <code>nca_analysis</code> function.</p>
</div>
<div id="density-of-cases-near-the-scope-limits" class="section level4 hasAnchor" number="4.1.4.2">
<h4><span class="header-section-number">4.1.4.2</span> Density of cases near the scope limits<a href="dataanalysis.html#density-of-cases-near-the-scope-limits" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Cases near the scope limit of <span class="math inline">\(X = X_{max}\)</span> have met the necessary condition of a high level of <span class="math inline">\(X\)</span> being necessary for a high level of <span class="math inline">\(Y\)</span>. For certain levels of <span class="math inline">\(X &gt; X_c\)</span>, where <span class="math inline">\(X_c\)</span> is the intersection between the ceiling line and the line <span class="math inline">\(Y = Y_{max}\)</span>, <span class="math inline">\(X\)</span> is not necessary for <span class="math inline">\(Y\)</span> (‘condition inefficiency’). When most cases are in the condition inefficiency area <span class="math inline">\(X_c &lt; X &lt; X_{max}\)</span>, the necessary condition could be considered as ‘trivial’. Most cases have met the necessary condition, whereas only a few cases have not.
Cases near the scope limit of <span class="math inline">\(Y = Y_{min}\)</span> have a low level of the outcome. Up to a level <span class="math inline">\(Y = Y_c\)</span>, where <span class="math inline">\(Y_c\)</span> is the intersection between the ceiling line and the line <span class="math inline">\(X = X_{min}\)</span>, <span class="math inline">\(Y\)</span> is not constrained by <span class="math inline">\(X\)</span> (‘outcome inefficiency’). When most cases are in the outcome inefficiency area <span class="math inline">\(Y_{min} &lt; Y &lt; Y_c\)</span>, the necessary condition could be considered ‘irrelevant’; the condition is not constraining the outcome in that area. The condition and outcome inefficiencies can be obstained with the <code>NCA</code> software by using the <code>summaries</code> argument of <code>nca_output</code> function.</p>
</div>
<div id="density-of-cases-near-the-ceiling-line" class="section level4 hasAnchor" number="4.1.4.3">
<h4><span class="header-section-number">4.1.4.3</span> Density of cases near the ceiling line<a href="dataanalysis.html#density-of-cases-near-the-ceiling-line" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Cases near the ceiling line will be able to achieve a higher outcome unless the necessary condition increases. These cases can be considered as “best cases” (assuming that the outcome is desirable, and the condition is an effort). For a given level of the condition the maximum possible outcome for that level of condition is achieved by other unknown variables). Thus, for a certain level of the condition, cases near the ceiling have achieved a relatively high level of the outcome compared to cases with similar level of the condition. Furthermore, cases near the outcome ‘support’ the estimation of the ceiling line. With many cases near the ceiling line, the support of the ceiling line is high.</p>
</div>
</div>
</div>
<div id="inkind" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> The ‘empty space: Necessary condition ’in kind’<a href="dataanalysis.html#inkind" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Necessary condition hypotheses are qualitative statements like ‘<span class="math inline">\(X\)</span> is necessary for <span class="math inline">\(Y\)</span>’. The statement indicates that it is impossible to have <span class="math inline">\(Y\)</span> without <span class="math inline">\(X\)</span>. Consequently, if the statement holds, the space corresponding to having <span class="math inline">\(Y\)</span> but not <span class="math inline">\(X\)</span> in an <span class="math inline">\(XY\)</span> plot or contingency table does not have observations, thus is empty. To calculate the size of the empty space, NCA draws a border line (ceiling line) between the empty space without observation and the full space with observations. The size of the empty space relative to the full space is the effect size and indicates the constraint that <span class="math inline">\(X\)</span> poses on <span class="math inline">\(Y\)</span>. When the effect size is relevant (e.g., <span class="math inline">\(d &gt; 0.1\)</span>), and when the empty space is unlikely to be a random result of unrelated <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (e.g., <span class="math inline">\(p &lt; 0.05\)</span>), the researcher may conclude that there is empirical evidence for the hypothesis. Thus, after having evaluated <em>theoretical support</em>, the <em>effect size</em> and the <em>p value</em>, the hypothesis ‘<span class="math inline">\(X\)</span> is necessary for <span class="math inline">\(Y\)</span>’ may be supported. This hypothesis is formulated in a qualitative way and describes the necessary condition <em>in kind</em>. The effect size and its p value can be produced with the <code>NCA</code> software using the <code>nca_analysis</code> function.</p>
<p>Even for small samples, NCA can estimate an effect size an a relevant p value. An effect size can be calculate for a sample size <span class="math inline">\(N &gt; 1\)</span> (at least two cases must be available) and a relevant p value can be calculated when for a sample size <span class="math inline">\(N &gt; 3\)</span>. The reasons for these thresholds are as follows. NCA’s effect size can be calculated as long as is a ceiling line can be drawn in the <span class="math inline">\(XY\)</span> plot. NCA estimates the ceiling line from empirical data and for drawing a line at least two points are needed (<span class="math inline">\(N = 2\)</span>). NCA assumes that the ceiling line is not pure horizontal and not pure vertical (although the CE-FDH step function has horizontal and vertical parts). When the ceiling line represents the situation that the presence or high value of <span class="math inline">\(X\)</span> is necessary for the presence or high value of Y, the empty space is located in the upper left corner of the scatter plot. For <span class="math inline">\(N = 2\)</span> the first case is in the lower left corner (<span class="math inline">\(x = 0, y = 0\)</span>), and the second case is in the upper right corner (<span class="math inline">\(x = 1, y = 1\)</span>). Then the effect size is 1 (CE-FDH). For all other situations with <span class="math inline">\(N = 2\)</span>, the effect size is 0 or not defined (pure horizontal or pure vertical line).
<!-- The p-value refers to the probability that the observed data pattern is obtained when the variables are unrelated. For $N = 2$ with effect size = 1, the p value is 0.5, thus the probability that observed effect size is the result of variables that are unrelated is 0.5, which is far above the common threshold of 0.05. This means that the observed effect size is not statistically ‘significant’.  -->
For calculating the p value, NCA’s statistical test (see Section <a href="statistical.html#permutationtest">6.2</a>) compares the effect size of the observed sample (with <span class="math inline">\(N\)</span> observed cases) with the effect sizes of created samples with <span class="math inline">\(N\)</span> fictive cases when <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are unrelated. Fictive cases that represent non-relatedness between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are obtained by combining observed <span class="math inline">\(X\)</span> values with observed <span class="math inline">\(Y\)</span> values into new samples. The total number of created samples with a unique combination (permutations) of fictive cases is <span class="math inline">\(N!\)</span> (<span class="math inline">\(N\)</span> factorial). Only one of the permutations corresponds to the observed sample. For each sample the effect size is calculated. The p value is then defined as the probability (p) that the effect size of the observed sample is equal to or larger than the effect size of all samples. If this probability is small (e.g., <span class="math inline">\(p &lt; .05\)</span>), a ‘significant’ result is obtained. This means that the observed sample is unlikely the result of a random process of unrelated variables (the null hypothesis is rejected), suggesting support for an alternative hypothesis.</p>
<!-- The p value helps to avoid a false positive conclusion, namely that the effect size is the result of a necessity relationship between X and Y, whereas actually it may be a random result of unrelated variables. -->
<p>For example, for a sample size of <span class="math inline">\(N = 2\)</span> the total number of unique samples or permutations (including the observed sample) is <span class="math inline">\(1 * 2 = 2\)</span>. When the observed sample consists of case 1 <span class="math inline">\((x_1,y_1)\)</span> and case 2 <span class="math inline">\((x_2,y_2)\)</span> then the observed <span class="math inline">\(x\)</span>-values <span class="math inline">\((x_1,x_2)\)</span> and the observed <span class="math inline">\(y\)</span>-values <span class="math inline">\((y_1,y_2)\)</span> can be combined into two unique samples of size <span class="math inline">\(N = 2\)</span>: the observed sample with observed case 1 <span class="math inline">\((x_1,y_1)\)</span> and observed case 2 <span class="math inline">\((x_2, y_2)\)</span>, and the alternative created sample of <span class="math inline">\(N = 2\)</span> with two fictive cases <span class="math inline">\((x_1,y_2)\)</span> and <span class="math inline">\((x_2, y_1)\)</span>. For example, when the observed sample has case 1 is <span class="math inline">\((0,0)\)</span> and case 2 is <span class="math inline">\((1,1)\)</span> the observed effect size is 1. The effect size of the alternative sample has the cases <span class="math inline">\((1,0)\)</span> and <span class="math inline">\((0,1)\)</span> with effect size is 0. The probability that the effect size of the observed sample is equal to or larger than the effect sizes of the two sample is 1 in 2, thus <span class="math inline">\(p = 0.5\)</span>. This means that the effect size of 1 is a ‘non-significant’ result because the probability that the observed effect size is caused by unrelated variables is not small enough (not below 0.05).
Similarly, for sample size <span class="math inline">\(N = 3\)</span> the total number of unique samples is <span class="math inline">\(1 * 2 * 3 = 6\)</span>, and the smallest possible p value is <span class="math inline">\(1/6 = 0.167\)</span>, for <span class="math inline">\(N = 4\)</span> the total number of unique samples is <span class="math inline">\(1 * 2 * 3 * 4 = 24\)</span>, and the smallest possible p value is <span class="math inline">\(1/24 = 0.042\)</span>, and for <span class="math inline">\(N = 5\)</span> the total number of unique samples is <span class="math inline">\(1 * 2 * 3 * 4 * 5 = 120\)</span>, and the smallest possible p value is <span class="math inline">\(1/120 = 0.008\)</span>, etc. Thus, only from <span class="math inline">\(N = 4\)</span> it is possible to obtain a p value that is small enough for making conclusions about the ‘statistical significance’ of an effect size.
When sample size increases, the total number of unique samples increases rapidly, and the possible p value decreases rapidly. For <span class="math inline">\(N = 10\)</span> the total number of samples (permutations) is 3628800 and the corresponding possible p value is smaller than 0.0000003. For <span class="math inline">\(N = 20\)</span> is the total number of samples is a number of 19 digits with a corresponding possible p value that has 18 zero’s after the decimal point. When N is large the computation of the effect sizes of all samples (permutations) requires unrealistic computation times. Therefore, NCA uses a random sample from all possible samples and estimates the p value with this selection of samples. Therefore, NCA’s statistical test is an ‘approximate permutation test’. In the <code>NCA</code> software this test is implemented with the <code>test.rep</code> argument in the nca_analysis function to provide the number of samples to be analyzed, for example 10000 (the larger the more precision but also more computation time). When the test.rep value is larger than <span class="math inline">\(N!\)</span> (which is relevant for small N), the software selects all <span class="math inline">\(N!\)</span> samples for the p value calculation.
The <code>NCA</code> software can also be used for estimating the effect size and p value for small N.</p>
</div>
<div id="bottleneck" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> The bottleneck table: Necessary conditions ‘in degree’<a href="dataanalysis.html#bottleneck" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For additional insights, a necessity relationship can be formulated in a quantitative way: the necessary condition <em>in degree</em>: “<em>level</em> of <span class="math inline">\(X\)</span> is necessary for <em>level</em> of <span class="math inline">\(Y\)</span>”. The bottleneck table is a helpful tool for evaluating necessary conditions in degree. The bottleneck table is the tabular representation of the ceiling line. The first column is the outcome <span class="math inline">\(Y\)</span> and the next columns are the necessary conditions. The values in the table are levels of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> corresponding to the ceiling line.
By reading the bottleneck table row by row from left to right it can be evaluated for which particular level of <span class="math inline">\(Y\)</span>, which particular threshold levels of the conditions <span class="math inline">\(X\)</span> are necessary. The bottleneck table includes only conditions that are supposed to be necessary conditions in kind. Conditions that are not supposed to be necessary (e.g., because the effect size is too small or the p value too large) are usually excluded from the table ((see Section <a href="dataanalysis.html#causalinference">4.8</a>). The bottleneck table can be produced with the <code>NCA</code> software using the argument <code>bottlenecks = 'TRUE'</code> in the <code>nca_output</code> function.</p>
<p>Figure <a href="dataanalysis.html#fig:salesoutputfig">4.2</a> shows the software output of a particular bottleneck table <span class="citation">(<a href="#ref-dul2021marketing">Dul, Hauff, et al., 2021</a>)</span> showing two personality traits of sales persons that were identified as necessary conditions for <em>Sales performance</em> (<span class="math inline">\(Y\)</span>): <em>Ambition</em> (<span class="math inline">\(X_1\)</span>) and <em>Sociability</em> (<span class="math inline">\(X_2\)</span>) because there is theoretical support for it, the effect sizes are relatively large (d &gt; 0.10), and the p values are relatively low (p &lt; 0.05).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:salesoutputfig"></span>
<img src="sales%20output.png" alt="Bottleneck table with two necessary conditions for sales performance [Adapted from @dul2021marketing]. NN = not necessary." width="100%" />
<p class="caption">
Figure 4.2: Bottleneck table with two necessary conditions for sales performance <span class="citation">(Adapted from <a href="#ref-dul2021marketing">Dul, Hauff, et al., 2021</a>)</span>. NN = not necessary.
</p>
</div>
<p>The example shows that up to level 40 of Sales performance, Ambition and Sociability are <em>not</em> necessary (NN). For level 50 and 60 of Sales performance only Ambition is necessary and for higher levels of Sales performance both personality traits are necessary. For example, for a level of 70 of Sales performance, Ambition must be at least 29.4 and Sociability at least 23.2. If a case (a sales person) has a level of a condition that is lower than the threshold value, this person cannot achieve the corresponding level of Sale performance. The condition is a bottleneck. For the highest level of Sales performance, the required threshold levels of Ambition and Sociability are 66.8 and 98.4 respectively.</p>
<div id="percentagerange" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Levels expressed as percentage of range<a href="dataanalysis.html#percentagerange" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Figure <a href="dataanalysis.html#fig:salesoutputfig">4.2</a> is an example of a default bottleneck table produced by the <code>NCA</code> software. This table has 11 rows with levels of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> expressed as ‘percentage.range’. The <em>range</em> is the maximum level minus the minimal level. A level of 0% of the range corresponds to the minimum level, 100% the maximum level, and 50% the middle level between these extremes. In the first row, the <span class="math inline">\(Y\)</span> level is 0% of the <span class="math inline">\(Y\)</span> range, and in the eleventh row it is 100%. In the default bottleneck table the levels of <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>’s are expressed as percentages of their respective ranges.</p>
<!-- ### \textcolor{gray}{Levels expressed as actual values} -->
<!-- ### <span style="color: #D3D3D3">Levels expressed as actual values</span> {#actual} -->
<!-- under construction -->
</div>
<div id="actual" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Levels expressed as actual values<a href="dataanalysis.html#actual" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The levels of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> in the bottleneck table can also be expressed as actual values. Actual values are the values of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> as they are in the original dataset (and in the scatter plot). This way of expressing the levels can help to compare the bottleneck table results with the original data and with the scatter plot results. Expressing the levels of <span class="math inline">\(X\)</span> with actual values can be done with the argument <code>bottleneck.x = 'actual'</code> in the <code>nca_analysis</code> function of the <code>NCA</code> software, and the actual values of <span class="math inline">\(Y\)</span> can be shown in the bottleneck table with the argument <code>bottleneck.y = 'actual'</code>.</p>
<p>One practical use of a bottleneck table with actual values is illustrated with the example of sales performance. Figure <a href="dataanalysis.html#fig:salesfig">4.3</a> combines the bottleneck table with the scatter plots.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:salesfig"></span>
<img src="sales.png" alt="Left: Bottleneck table with two necessary conditions for sales performance. Right: The red dot is a specific sales person with sales performance = 4, Ambition = 65 and Sociability = 59 [Adapted from @dul2021marketing]. NN = not necessary." width="100%" />
<p class="caption">
Figure 4.3: Left: Bottleneck table with two necessary conditions for sales performance. Right: The red dot is a specific sales person with sales performance = 4, Ambition = 65 and Sociability = 59 <span class="citation">(Adapted from <a href="#ref-dul2021marketing">Dul, Hauff, et al., 2021</a>)</span>. NN = not necessary.
</p>
</div>
<p>The actual values of Sales performance range from 0 to 5.5, and for both conditions from 0 to 100. The left side of Figure <a href="dataanalysis.html#fig:salesfig">4.3</a> shows that up to level of 2 of Sales performance, none of the conditions are necessary. The scatter plots shows that cases with very low level of Ambition or Sociability still can achieve a level of 2 of Sales performance. However, for level 4 of Sales performance Ambition must be at least 33 and Sociability at least 29. The scatter plot shows that several cases have not reached these threshold levels of the conditions. This means that these cases do not reach level 4 of Sales performance. The scatter plots also show that cases exist with (much) higher levels of the conditions than these threshold levels and yet do not reach level of 4 of Sales performance: Ambition and Sociability are necessary, but not sufficient for Sales performance.</p>
<p>The right side of Figure <a href="dataanalysis.html#fig:salesfig">4.3</a> shows a particular case with Sales performance level 4, Ambition level 65 and Sociability level 59. For this person Sociability is the bottleneck for moving from level 4 to level 5 of Sales performance. Level 5 of Sales performance requires level 55 of Ambition and this is already achieved by this person. However, the person’s level of Sociability is 59 and this is below the threshold level that is required for level 5 of Sales performance. For reaching this level of Sales performance, this person must increase the level of Sociability (e.g., by training). Improving the Ambition without improving Sociability has no effect and is a waste of effort. For other persons, the individual situation might be different (e.g., Ambition but not Sociability is the bottleneck, both are bottlenecks, or none is a bottleneck). This type of bottleneck analysis allows the researcher to better understand the bottlenecks of individual cases and how to act on individual cases.</p>
</div>
<div id="percentile" class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Levels expressed as percentiles<a href="dataanalysis.html#percentile" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The levels of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> can also be expressed as percentiles. This can be helpful for selecting ‘important’ necessary conditions when acting on a group of cases. The percentile is a score where a certain percentage of scores fall below that score. For example, 90 percentile of <span class="math inline">\(X\)</span> is a score of <span class="math inline">\(X\)</span> that is so high that 90% of the observed <span class="math inline">\(X\)</span>-scores fall below that <span class="math inline">\(X\)</span>-score. Similarly, 5 percentile of <span class="math inline">\(X\)</span> is a score of <span class="math inline">\(X\)</span> that is so low that 5% of the observed <span class="math inline">\(X\)</span>-scores fall below that <span class="math inline">\(X\)</span>-score.
The bottleneck can be expressed with percentiles by using the argument <code>bottleneck.x = 'percentile'</code> and/or <code>bottleneck.y = 'percentile'</code> in the <code>nca_analysis</code> function of the <code>NCA</code> software. Figure <a href="dataanalysis.html#fig:salespercentilesfig">4.4</a> shows the example bottleneck table with the level of <span class="math inline">\(Y\)</span> expressed as actual values, and the level of the <span class="math inline">\(X\)</span>s as percentiles.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:salespercentilesfig"></span>
<img src="salespercentiles.png" alt="Bottleneck table with levels of $Y$ expressed as actual and levels of $X$ as percentiles. Between brackets are the cumulative number of cases that have not reached the threshold levels. The total number of cases is 108. [Adapted from @dul2021marketing]." width="100%" />
<p class="caption">
Figure 4.4: Bottleneck table with levels of <span class="math inline">\(Y\)</span> expressed as actual and levels of <span class="math inline">\(X\)</span> as percentiles. Between brackets are the cumulative number of cases that have not reached the threshold levels. The total number of cases is 108. <span class="citation">(Adapted from <a href="#ref-dul2021marketing">Dul, Hauff, et al., 2021</a>)</span>.
</p>
</div>
<p>A percentile level of <span class="math inline">\(X\)</span> corresponds to the percentage of cases that are <em>unable</em> to reach the threshold level of <span class="math inline">\(X\)</span> and thus the corresponding level of <span class="math inline">\(Y\)</span> in the same row. If in a certain row (e.g., row with <span class="math inline">\(Y\)</span> = 3) the percentile of <span class="math inline">\(X\)</span> is small (e.g., 4% for Ambition), only a few cases (4 of 108 = 4%) where not able to reach the required level of <span class="math inline">\(X\)</span> for the corresponding level of <span class="math inline">\(Y\)</span>. If the percentile of <span class="math inline">\(X\)</span> is large (e.g., row with <span class="math inline">\(Y\)</span> = 5.5), many cases where not able to reach the required level of <span class="math inline">\(X\)</span> for the corresponding level of <span class="math inline">\(Y\)</span>: 68 of 108 = 63% for Ambition and 106 of 108 = 98% for Sociability. Therefore, the percentile for <span class="math inline">\(X\)</span> is an indication of the ‘importance’ of the necessary conditions: how many cases were unable to reach the required level of the necessary condition for a particular level of the outcome. When several necessary conditions exist, this information may be relevant for prioritizing a collective action on a group of cases by focusing on bottleneck conditions with high percentile values of <span class="math inline">\(X\)</span>.</p>
<p>Further details of using and interpreting the bottleneck table in this specific example can be seen in <a href="https://youtu.be/AmguFDIoMYo">this video</a>.</p>
</div>
<div id="percentagemax" class="section level3 hasAnchor" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> Levels expressed as percentage of maximum<a href="dataanalysis.html#percentagemax" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The final way of expressing the levels of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is less commonly used. It is possible to express levels of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> as percentage of their maximum levels. The bottleneck table can be expressed with percentage of maximum by using the argument <code>bottleneck.x = 'percentage.max'</code> or <code>bottleneck.y = 'percentage.max'</code> in the <code>nca_analysis</code> function of the <code>NCA</code> software.</p>
<!-- <!-- ### \textcolor{gray}{Levels expressed as actual values} -->
<!-- ### <span style="color: #D3D3D3">Levels expressed as actual values</span> {#actual} -->
<!-- under construction -->
<!-- Possible interpretation of percentiles in NCA’s the bottleneck table  -->
<!-- Percentile P for X.  -->
<!-- Relevant definition: The percentage P of cases that have not achieved the required score of condition X for the target score of outcome Y. -->
<!-- If P is relatively small (e.g., 20%) a relatively small percentage of cases (20%) was not able to satisfy the necessary condition. It suggests ‘trivialness’’ of the necessary condition for collective actions for satisfying the necessary condition. -->
<!-- If P is relatively large (e.g., 80%), a relatively large percentage of cases (80%) was not able to satisfy the necessary condition. It suggests ‘importance’ of the necessary condition for collective actions aiming at satisfying the necessary condition. -->
<!-- Percentile P for Y.  -->
<!-- Relevant definition: The percentage 100- P of cases that have achieved the target score of condition Y. -->
<!-- If P is relatively small (e.g., 20%) a relatively large percentage of cases (100 - 20% = 80%) was able to achieve the outcome. It suggests an ‘ordinary’, unambitious outcome level. -->
<!-- If P is relatively large (e.g., 80%), a relatively small percentage of cases (100-80% = 20%) was able achieve the outcome (20% ‘best cases’) . It suggest an ‘exceptional’, ambitious outcome level. -->
</div>
<div id="bottleneckothercorners" class="section level3 hasAnchor" number="4.3.5">
<h3><span class="header-section-number">4.3.5</span> Interpretation of the bottleneck table with other corners<a href="dataanalysis.html#bottleneckothercorners" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The above sections refer to analyzing the upper left corner in the <span class="math inline">\(XY\)</span> plot, corresponding to the situation that the presence or a high value of <span class="math inline">\(X\)</span> is necessary for the presence or a high value of <span class="math inline">\(Y\)</span>. Then, when <span class="math inline">\(X\)</span> is expressed as ‘percentage range’, ‘actual value’ or ‘percentage maximum’ the bottleneck table shows the minimum required level of <span class="math inline">\(X\)</span> for a given value of <span class="math inline">\(Y\)</span>. When <span class="math inline">\(X\)</span> is expressed as ‘percentiles’, the bottleneck table shows the percentage of cases that are unable to reach the required level of <span class="math inline">\(X\)</span> for a given value of <span class="math inline">\(Y\)</span>.</p>
<p>The interpretation of the bottleneck table is different when other corners than the upper left corner are analysed (see Section <a href="summary.html#formulate">1.3</a>).</p>
<div id="interpretation-of-the-bottleneck-table-with-corner-2" class="section level4 hasAnchor" number="4.3.5.1">
<h4><span class="header-section-number">4.3.5.1</span> Interpretation of the bottleneck table with corner = 2<a href="dataanalysis.html#interpretation-of-the-bottleneck-table-with-corner-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For corner = 2, the upper right corner is empty suggesting that the absence or low value of <span class="math inline">\(X\)</span> is necessary for the presence or high value of <span class="math inline">\(Y\)</span>. This means that for a given value of <span class="math inline">\(Y\)</span>, the value of <span class="math inline">\(X\)</span> must be equal to or <em>lower</em> than the threshold value according to the ceiling line. When <span class="math inline">\(X\)</span> is expressed as ‘percentage range’, ‘actual value’ or ‘percentage maximum’ the bottleneck table shows the <em>maximum</em> required level of <span class="math inline">\(X\)</span> for a given value of <span class="math inline">\(Y\)</span>. In other words, for each row in the bottleneck table (representing the target level of <span class="math inline">\(Y\)</span>), the corresponding level of <span class="math inline">\(X\)</span> must be <em>at most</em> the level mentioned in the bottleneck table.
When <span class="math inline">\(X\)</span> is expressed as ‘percentiles’, the bottleneck table still shows the percentage and number of cases that are unable to reach the required level of <span class="math inline">\(X\)</span> for a given value of <span class="math inline">\(Y\)</span>.</p>
</div>
<div id="interpretation-of-the-bottleneck-table-with-corner-3" class="section level4 hasAnchor" number="4.3.5.2">
<h4><span class="header-section-number">4.3.5.2</span> Interpretation of the bottleneck table with corner = 3<a href="dataanalysis.html#interpretation-of-the-bottleneck-table-with-corner-3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For corner = 3, the lower left corner is empty suggesting that the presence or high value of <span class="math inline">\(X\)</span> is necessary for the absence or low value of <span class="math inline">\(Y\)</span>. This means that for a given value of <span class="math inline">\(Y\)</span>, the value of <span class="math inline">\(X\)</span> must be equal to or <em>higher</em> than the threshold value according to the ceiling line. When <span class="math inline">\(X\)</span> is expressed as ‘percentage range’, ‘actual value’ or ‘percentage maximum’ the bottleneck table shows the <em>minimum</em> required level of <span class="math inline">\(X\)</span> for a given value of <span class="math inline">\(Y\)</span>. In other words, for each row in the bottleneck table (representing the target level of <span class="math inline">\(Y\)</span>), the corresponding level of <span class="math inline">\(X\)</span> must be <em>at least</em> the level mentioned in the bottleneck table. However, the first column in the bottleneck table (representing <span class="math inline">\(Y\)</span>) is now reversed. The first row has a high <span class="math inline">\(Y\)</span> value and the last row has the low values as the target outcome is low. When percentages are used for <span class="math inline">\(Y\)</span> (percentile or percentage of maximum) then 0% corresponds to a highest level of <span class="math inline">\(Y\)</span> and 100% to the lowest level of <span class="math inline">\(Y\)</span>.
When <span class="math inline">\(X\)</span> is expressed as ‘percentiles’, the bottleneck table still shows the percentage and number of cases that are unable to reach the required level of <span class="math inline">\(X\)</span> for a given value of <span class="math inline">\(Y\)</span>.</p>
</div>
<div id="interpretation-of-the-bottleneck-table-with-corner-4" class="section level4 hasAnchor" number="4.3.5.3">
<h4><span class="header-section-number">4.3.5.3</span> Interpretation of the bottleneck table with corner = 4<a href="dataanalysis.html#interpretation-of-the-bottleneck-table-with-corner-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For corner = 4, the lower right corner is empty suggesting that the absence or low value of <span class="math inline">\(X\)</span> is necessary for the absence or low value of <span class="math inline">\(Y\)</span>. This means that for a given value of <span class="math inline">\(Y\)</span>, the value of <span class="math inline">\(X\)</span> must be equal to or <em>lower</em> than the threshold value according to the ceiling line. When <span class="math inline">\(X\)</span> is expressed as ‘percentage range’, ‘actual value’ or ‘percentage maximum’ the bottleneck table shows the <em>maximum</em> required level of <span class="math inline">\(X\)</span> for a given value of <span class="math inline">\(Y\)</span>. In other words, for each row in the bottleneck table (representing the target level of <span class="math inline">\(Y\)</span>), the corresponding level of <span class="math inline">\(X\)</span> must be <em>at most</em> the level mentioned in the bottleneck table. However, the first column in the bottleneck table (representing <span class="math inline">\(Y\)</span>) is now reversed. The first row has a high <span class="math inline">\(Y\)</span> value and the last row has the low values as the target outcome is low. When percentages are used for <span class="math inline">\(Y\)</span> (percentile or percentage of maximum) then 0% corresponds to a highest level of <span class="math inline">\(Y\)</span> and 100% to the lowest level of <span class="math inline">\(Y\)</span>.
When <span class="math inline">\(X\)</span> is expressed as ‘percentiles’, the bottleneck table still shows the percentage and number of cases that are unable to reach the required level of <span class="math inline">\(X\)</span> for a given value of <span class="math inline">\(Y\)</span>.</p>
</div>
</div>
<div id="na" class="section level3 hasAnchor" number="4.3.6">
<h3><span class="header-section-number">4.3.6</span> NN and NA in the bottleneck table<a href="dataanalysis.html#na" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A NN (Not Necessary) in the bottleneck table means that <span class="math inline">\(X\)</span> is not necessary for <span class="math inline">\(Y\)</span> for the particular level of <span class="math inline">\(Y\)</span>. With any value of <span class="math inline">\(X\)</span> it is possible to achieve the particular level of <span class="math inline">\(Y\)</span>.</p>
<p>An NA (Not Applicable) in the bottleneck table is a warning that it is not possible to compute a value for the <span class="math inline">\(X\)</span>. There are two possible reasons for it, the first more often than the second:</p>
<ol style="list-style-type: decimal">
<li><p>The maximum possible value of the condition for the particular level of <span class="math inline">\(Y\)</span> according to the ceiling line is lower than the actually observed maximum value. This can happen for example when the CR ceiling (which is a trend line) runs at <span class="math inline">\(X\)</span> = <span class="math inline">\(X_{max}\)</span> (which is the right vertical line of the scope in the scatter plot) under the line <span class="math inline">\(Y\)</span> = <span class="math inline">\(Y_{max}\)</span> (which is the upper horizontal line of the scope). If this happens the researcher can either explain why this NA appears in the bottleneck table, or can change NA into the highest observed level of <span class="math inline">\(X\)</span>. The latter can be done with the argument <code>cutoff = 1</code> in the <code>nca_analysis</code> function.</p></li>
<li><p>In a bottleneck table with multiple conditions, one case determines the <span class="math inline">\(Y_{max}\)</span> value and that case has a missing value for the condition with the NA (but not for another condition). When all cases are complete (have no missing values) or when at least one case exist that has a complete observation (<span class="math inline">\(X\)</span>, <span class="math inline">\(Y_{max}\)</span>) for the given condition, the NA will not appear. The action to be taken is either to explain why this NA appears, or to delete the incomplete case from the bottleneck table analysis (and accept that the <span class="math inline">\(Y_{max}\)</span> in the bottleneck table does not correspond to the actually observed <span class="math inline">\(Y_{max}\)</span>).</p></li>
</ol>
</div>
</div>
<div id="robustnesschecks" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Robustness checks<a href="dataanalysis.html#robustnesschecks" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When conducting empirical research, a researcher must make a variety of theoretical and methodological choices to obtain results. Often, also other plausible choices could have been made. In a robustness check the sensitivity of the results of other plausible choices is evaluated. The check focuses on the sensitivity of the main estimates and the researcher’s main conclusion (e.g., about a hypothesis). Evaluating the robustness of a result is therefore a good practice for any empirical research method. For example, in regression analysis the regression coefficient is a main estimate that can be sensitive for inclusion or exclusion of potential confounders in the regression model (model specification) <span class="citation">(<a href="#ref-lu2014robustness">X. Lu &amp; White, 2014</a>)</span> or for the selection of the functional form of the regression equation (linear or non-linear). Another example of a researcher’s choice is the threshold p value (e.g., <span class="math inline">\(p = 0.05\)</span> or <span class="math inline">\(p = 0.01\)</span>) for (non)rejection of the hypothesis <span class="citation">(<a href="#ref-benjamin2018redefine">Benjamin et al., 2018</a>)</span>.
In NCA, the effect size and the p value are two main estimates for concluding whether a necessity relationship is credible. These estimates can be sensitive for several choices. Some choices are outside the realm of NCA, for example choices related to the data that are used as input to NCA (research design, sampling, measurement, pre-processing of data) or the threshold level of statistical significance. Other choices are NCA-specific, such as the choice of the ceiling line (e.g., CE-FDH or CR-FDH), the choice of the scope (empirical or theoretical), the threshold level of the necessity effect size (e.g., 0.1 or 0.2), and the handling of NCA-relevant outliers (keep or remove). All these choices have an effect on the necessity in kind conclusion whether or not a condition is necessary. A robustness check for necessity in degree evaluates the effect on the number of bottleneck cases (cases that are unable to achieve the required level of the condition for the target level of the outcome.</p>
<p>This section discuss these researcher’s choices that are candidates for a robustness check. The selected candidates are coices regarding ceiling line, threshold levels of the d value and the p value, scope and outliers. The section introduces the NCA robustness table. This table shows the influence of researcher’s choices on the main NCA results.</p>
<div id="choiceceiling" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Choice of ceiling line<a href="dataanalysis.html#choiceceiling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In NCA <em>model specification</em> refers to the variables that are selected as potential necessary conditions. <em>Functional form</em> refers to the form of the ceiling line. NCA is a (multiple) bivariate analysis where the inclusion or exclusion of other variables does not affect the results. However, the functional form of the necessity model may affect the results. The two default ceiling lines are linear (straight line CR-FDH) and piece-wise linear (step function CE-FDH), and the NCA results depend on the choice of the ceiling line. The researcher usually selects the ceiling line based on the type of data (discrete or continuous) or on whether the expected or observed pattern of the border between the area with and without data is linear or non-linear. For example, when the data has a small number of discrete levels with a jumpy border, the researcher may decide to select the CE-FDH ceiling line. When the researcher assumes a linear ceiling line in the population, the straight ceiling line CR-FDH may be selected. The choice of the ceiling line is partly subjective because there are no hard criteria for the best ceiling form (see also Section <a href="statistical.html#ceilingquality">6.3.3</a>). Therefore, a robustness check with another plausible ceiling line is warranted. When the selected ceiling line is obviously the best choice (e.g., CE-FDH when the condition or outcome is dichotomous), it makes no sense to mechanistically select another line (e.g., CR-FDH) as this is not a reasonable alternative. If other ceiling line choices are also plausible, it makes sense to check the effect of this other choice. For example, Figure <a href="dataanalysis.html#fig:exampleWestern">4.5</a> shows the scatter plot with the two default ceiling lines for testing the hypothesis that in Western countries a culture of individualism is necessary for innovation performance <span class="citation">(<a href="#ref-dul2020book">Dul, 2020</a>)</span>.</p>
<div class="figure"><span style="display:block;" id="fig:exampleWestern"></span>
<img src="exampleWestern.png" alt="Example of a ceiling line robustness check: Comparing the results of two ceiling lines." width="100%" />
<p class="caption">
Figure 4.5: Example of a ceiling line robustness check: Comparing the results of two ceiling lines.
</p>
</div>
<p>In this example the choice of the ceiling line is not obvious. As suggested in <span class="citation">Dul (<a href="#ref-dul2020book">2020</a>)</span> a robustness check could consist of performing the analysis with both ceiling lines and comparing the results. The results for the CE-FDH ceiling line are <span class="math inline">\(d = 0.58\)</span> and <span class="math inline">\(p = 0.002\)</span>, and for the CR-FDH ceiling line are <span class="math inline">\(d = 0.51\)</span> and <span class="math inline">\(p =  0.003\)</span>. Given the researcher’s other choices (e.g., effect size threshold = 0.1; p value threshold = 0.05) the ceiling line robustness check consists of evaluating whether the researcher’s conclusion about the necessity hypothesis remains the same (robust result) or differs (fragile result). In this case both ceiling lines produce the same conclusion regarding necessity in kind: the necessity hypothesis is supported, which suggests that this is a robust result.</p>
<p>In the situation of a dichotomous necessary condition where the condition or the outcome (or both) have only two values, the only feasible ceiling line is the CE_FDH ceiling line. The CR_FDH ceiling line is not a plausible alternative as it does not fit the step-wise data pattern, and the results are already known: the CR_FDH effect size is half of the CE_FDH effect size, whereas the p values are the same. In this situation, the robustness check should exclude selecting another ceiling line.</p>
<p>Regarding necessity in degree the bottleneck tables (with outcome and conditions expressed as percentiles) shows that the results are more variable. For example, Figure <a href="#:bottleneckCECR"><strong>??</strong></a> shows that for a “high” level of the outcome that can only be achieved by 25% of the cases (75th percentile), 32% of the cases (8 cases) cannot achieve the required level for the condition individualism when the CE-FDH line is used, whereas 20% of the cases (5 cases) cannot achieve when the CR-FDH line is used.</p>
<div class="figure"><span style="display:block;" id="fig:bottlenecksCECR"></span>
<img src="bottlenecksCECRsmall.png" alt="Bottleneck tables of for two ceiling lines." width="100%" />
<p class="caption">
Figure 4.6: Bottleneck tables of for two ceiling lines.
</p>
</div>
</div>
<div id="choiceeffectsize" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Choice of the threshold level of the effect size<a href="dataanalysis.html#choiceeffectsize" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The researcher could also have made another choice for the effect size threshold level. If the threshold level is changed from the common 0.1 value (“small effect”) to a larger value of 0.2 (“medium effect”), the conclusion about necessity would not change. Since the observed effect size is verly large, the robustness check of effect size threshold suggests a robust result.</p>
</div>
<div id="choicepvalue" class="section level3 hasAnchor" number="4.4.3">
<h3><span class="header-section-number">4.4.3</span> Choice of the threshold level of the p value<a href="dataanalysis.html#choicepvalue" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The researcher could also have made another choice for the p value threshold level. If the threshold level is changed from the common 0.05 value to a smaller value of 0.01, the conclusion about necessity would not change. Singe the estimated p values is very small, the robustness check of effect size threshold suggests a robust result.</p>
</div>
<div id="choicescope" class="section level3 hasAnchor" number="4.4.4">
<h3><span class="header-section-number">4.4.4</span> Choice of the scope<a href="dataanalysis.html#choicescope" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Whereas regression analysis assumes that the variables of the regression model are unbounded (can have values between minus and plus infinity, see Section <a href="dataanalysis.html#ncaregression">4.5</a>), NCA assumes that the variables in the necessity model are bounded (have minimum and maximum values). As a default the NCA selects the bounds based on the <em>observed</em> minimum and maximum values of the condition and the outcome to define the ‘empirical scope’. However, it is also possible to conduct NCA with a theoretically defined scope (‘theoretical scope’). The robustness of the result could be checked by selecting another plausible scope (‘theoretical scope’) than the default empirical scope, or when the original choice was a theoretical scope to select the empirical scope or a different theoretical scope. For example, the researcher may have selected the empirical scope for an analysis with variables measured with a Likert scale, but the scale’s minimum and maximum values are not used. Then the researcher can conduct a robustness check with a theoretical scope defined with the extreme values of the scale. Changing the scope for a larger theoretical scope generally results in a <em>larger</em> effect size. Therefore, such change may affect the researcher’s original conclusion that the hypothesis is rejected, but will not change an original conclusion that the hypothesis is supported. The latter is shown in Figure <a href="dataanalysis.html#fig:exampleWesternScope">4.7</a>. The scatter plot has a theoretical scope that is larger than the empirical scope. The condition ranges from 20 to 100 and the outcome from 0 to 120. The effect size for the CE-FDH ceiling line has increased from <span class="math inline">\(d = 0.58\)</span> (<span class="math inline">\(p = 0.002\)</span>) to <span class="math inline">\(d = 0.61\)</span> (<span class="math inline">\(p = 0.002\)</span>). Changing a theoretical scope for a smaller scope generally results in a <em>smaller</em> effect size. Such change may affect the researcher’s original conclusion that the hypothesis is supported, but will not change an original conclusion that the hypothesis is rejected.</p>
<div class="figure"><span style="display:block;" id="fig:exampleWesternScope"></span>
<img src="exampleWesternScope.png" alt="Example of a scope robustness check: Comparing the results with the empirical and the theoretical scope (difference is shaded)." width="100%" />
<p class="caption">
Figure 4.7: Example of a scope robustness check: Comparing the results with the empirical and the theoretical scope (difference is shaded).
</p>
</div>
<p>When the researcher would have selected a theoretical scope for the analysis and changes that for a smaller theoretical scope, the effect size will be <em>smaller</em> and may also affect the researcher’s conclusion about the hypothesis from ‘rejected’ to ‘not rejected’.</p>
</div>
<div id="choiceoutlier" class="section level3 hasAnchor" number="4.4.5">
<h3><span class="header-section-number">4.4.5</span> Choice of outlier removal<a href="dataanalysis.html#choiceoutlier" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A removal of outliers potentially has a large influence on the results as NCA results can be sensitive for outliers (see Section <a href="data.html#outliers">3.8</a>). Ceiling outliers (outliers that define the ceiling line) and scope outliers (outliers that define the scope) usually increase the effect size when removed. For example, in Figure <a href="dataanalysis.html#fig:exampleWesternOutlier">4.10</a> Finland is a potential ceiling outlier that increases the CE-FDH effect size from 0.58 (<span class="math inline">\(p = 0.002\)</span>) to 0.62 (<span class="math inline">\(p = 0.001\)</span>) and Mexico is a potential scope outlier that increases the effect size slightly. However, when an outlier is both a ceiling outlier and a scope outlier the effect may decrease. This applies to the potential outlier USA, where the effect size decreases from 0.58 (<span class="math inline">\(p = 0.002\)</span>) to 0.52 (<span class="math inline">\(p = 0.012\)</span>) when this potential outlier is removed.</p>
<p>For getting a first impression about the role of removing outliers two robustness checks can be done. In the first check the most influential single outlier (largest effect on the effect size if removed is selected, and this potential outlier is removed from the dataset. The potential outliers can be identified with the NCA software as follows:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="dataanalysis.html#cb63-1" tabindex="-1"></a><span class="fu">nca_outliers</span>(data, <span class="st">&quot;Individualism&quot;</span>, <span class="st">&quot;Innovation performance&quot;</span>, <span class="at">ceiling =</span> <span class="st">&quot;ce_fdh&quot;</span>, <span class="at">k =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>The results are shown in Figure <a href="dataanalysis.html#fig:singleoutlier">4.8</a>, where eff.or is the original effect size, eff.nw is the new effect size after removing the potential outlier, dif.abs and dif.rel are the absolute and relative differences between the new and original effect size and ‘ceiling’ and ‘scope’ indicate whether the potential outliers is a ceiling outlier or a scope outlier (or both). It turns out the USA is the largest outlier. When this case is removed from the dataset the NCA results are changed as indicated above.</p>
<div class="figure"><span style="display:block;" id="fig:singleoutlier"></span>
<img src="outliers_single.png" alt="The influence of removing a single potential outlier on the effect size." width="100%" />
<p class="caption">
Figure 4.8: The influence of removing a single potential outlier on the effect size.
</p>
</div>
<p>In the second check, multiple outliers (for example a set of two) are selected that have the largest influence on the effect size when removed as a set. This outlier analysis can be initiated as follows:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="dataanalysis.html#cb64-1" tabindex="-1"></a><span class="fu">nca_outliers</span>(data, <span class="st">&quot;Individualism&quot;</span>, <span class="st">&quot;Innovation performance&quot;</span>, <span class="at">ceiling =</span> <span class="st">&quot;ce_fdh&quot;</span>, <span class="at">k =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:multipleoutlier"></span>
<img src="outliers_multiple.png" alt="The influence of removing two potential outliers on the effect size." width="100%" />
<p class="caption">
Figure 4.9: The influence of removing two potential outliers on the effect size.
</p>
</div>
<p>The results show that the set ‘Finland-Sweden’ is the most influential outlier duo. If this duo is removed from the dataset, the effect size increases and the p value reduces.</p>
<div class="figure"><span style="display:block;" id="fig:exampleWesternOutlier"></span>
<img src="exampleWesternOutlier.png" alt="Potential outliers. Mexico = potential scope outlier; Finland, Sweden = potential ceiling outliers; USA = potential scope and ceiling outlier. USA is the most influential single outlier. Finland - Sweden is the most influential combination of multiple (two) outliers." width="100%" />
<p class="caption">
Figure 4.10: Potential outliers. Mexico = potential scope outlier; Finland, Sweden = potential ceiling outliers; USA = potential scope and ceiling outlier. USA is the most influential single outlier. Finland - Sweden is the most influential combination of multiple (two) outliers.
</p>
</div>
<p>If this crude outlier approach with removing a single most influential outlier and aset of multiple most influential outliers does not change the conclusions, the results can be considered robust. Note, however, that a careful consideration is needed about an outlier decision: What are potential outliers, what are reasons of removing or not removing them (see decision tree about outliers in Section <a href="data.html#outliers">3.8</a>), and what is their influence on the effect size. Outliers are usually only removed when they are erroneous (measurement error or sampling error) or when they are exceptional (very large influence on the effect size when removed). In the current example, the influence of removing potential outliers is relatively modest; keeping them seems to be the most appropriate approach.</p>
</div>
<div id="choice-of-target-outcome" class="section level3 hasAnchor" number="4.4.6">
<h3><span class="header-section-number">4.4.6</span> Choice of target outcome<a href="dataanalysis.html#choice-of-target-outcome" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The last robustness check explores the stability of the bottleneck analysis in terms of the number of bottleneck cases (that cannot achieve the target outcome because the condition is not satisfied) when the target outcome is mildly changed. For example, when the original target outcome is 75% (percentile) what is the influence on the percentage and number of bottleneck cases when the target outcome is somewhat lower (70%) or higher (80%).</p>
<div class="figure"><span style="display:block;" id="fig:exampleWesternTarget"></span>
<img src="exampleWesternTarget.png" alt="The effect of changing the target outcome from 75 percentile to 70 and 80 percentile." width="100%" />
<p class="caption">
Figure 4.11: The effect of changing the target outcome from 75 percentile to 70 and 80 percentile.
</p>
</div>
<p>Figure <a href="dataanalysis.html#fig:exampleWesternTarget">4.11</a> shows that for each of these levels of the outcome the required minimum level of the condition is 63. Eight cases (32%) have not reached that level of the condition, which makes them bottleneck cases. The number of bottleneck cases does not change with minor changes of the target outcome.</p>
</div>
<div id="robustnesstable" class="section level3 hasAnchor" number="4.4.7">
<h3><span class="header-section-number">4.4.7</span> Robustness table<a href="dataanalysis.html#robustnesstable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The results the robustness checks can be summarized in a NCA robustness table (<a href="dataanalysis.html#tab:robustchecksgeneral">4.1</a>) where the original NCA results are compared with the results when different, also feasible choices are made. The first row shows the original results, and the next rows give the results after changes are explored. The nine changes: ceiling line change, d threshold change, p threshold change, scope change, single outlier removal, multiple outlier removal, target lower, and target higher. For checking the robustness of <em>necessity in kind</em>, effect size, p value, and conclusion about necessity (assuming theoretical support) are displayed. For checking the robustness of <em>necessity in degree</em> the percentage (%) and number (#) of bottleneck cases that are unable to achieve the required level of the condition for a selected target level of the outcome are shown.
The NCA robustness table shows that the original results of this example are robust.</p>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:400px; overflow-x: scroll; width:100%; ">
<table style="width:30%; font-size: 9px; width: auto !important; margin-left: auto; margin-right: auto; font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;" class="table lightable-paper">
<caption style="font-size: initial !important;">
<span id="tab:robustchecksgeneral">Table 4.1: </span>NCA robustness table
</caption>
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;border-bottom: 2px solid black;">
Robustness check
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;border-bottom: 2px solid black;">
Effect size
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;border-bottom: 2px solid black;">
p value
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;border-bottom: 2px solid black;">
Necessity
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;border-bottom: 2px solid black;">
Bottlenecks(%)
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;border-bottom: 2px solid black;">
Bottlenecks(#)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
Individualism
</td>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Original
</td>
<td style="text-align:left;">
0.58
</td>
<td style="text-align:right;">
0.100
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
8
</td>
</tr>
<tr>
<td style="text-align:left;">
Ceiling change
</td>
<td style="text-align:left;">
0.51
</td>
<td style="text-align:right;">
0.100
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
d threshold change
</td>
<td style="text-align:left;">
0.58
</td>
<td style="text-align:right;">
0.100
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
8
</td>
</tr>
<tr>
<td style="text-align:left;">
p threshold change
</td>
<td style="text-align:left;">
0.58
</td>
<td style="text-align:right;">
0.100
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
8
</td>
</tr>
<tr>
<td style="text-align:left;">
Scope change
</td>
<td style="text-align:left;">
0.61
</td>
<td style="text-align:right;">
0.100
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
8
</td>
</tr>
<tr>
<td style="text-align:left;">
Single outlier removal
</td>
<td style="text-align:left;">
0.52
</td>
<td style="text-align:right;">
0.100
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
33.3
</td>
<td style="text-align:right;">
8
</td>
</tr>
<tr>
<td style="text-align:left;">
Multiple outlier removal
</td>
<td style="text-align:left;">
0.67
</td>
<td style="text-align:right;">
0.100
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
34.8
</td>
<td style="text-align:right;">
8
</td>
</tr>
<tr>
<td style="text-align:left;">
Target lower
</td>
<td style="text-align:left;">
0.58
</td>
<td style="text-align:right;">
0.100
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
8
</td>
</tr>
<tr>
<td style="text-align:left;border-bottom: 2px solid black;">
Target higher
</td>
<td style="text-align:left;border-bottom: 2px solid black;">
0.58
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
0.100
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
no
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
32
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
8
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
</tbody>
</table>
</div>
<p>The NCA robustness table for a specific necessity relationship with one condition and one outcome can be produced with the following code that makes use of three functions: <code>nca_robustness_table_general</code>, <code>nca_robustness_checks_general</code>, and <code>get_outliers</code>. The <code>R</code> code for these functions can be found in Sections <a href="miscellaneous.html#ncarobustnesstablegeneral">7.4.1</a>, <a href="miscellaneous.html#ncarobustnesschecksgeneral">7.4.2</a>, and <a href="miscellaneous.html#getoutliers">7.4.3</a>, respectively.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="dataanalysis.html#cb65-1" tabindex="-1"></a><span class="co"># General robustness table for a single necessity relationship. </span></span>
<span id="cb65-2"><a href="dataanalysis.html#cb65-2" tabindex="-1"></a><span class="fu">library</span>(NCA)</span>
<span id="cb65-3"><a href="dataanalysis.html#cb65-3" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;nca_robustness_table_general.R&quot;</span>)</span>
<span id="cb65-4"><a href="dataanalysis.html#cb65-4" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;nca_robustness_checks_general.R&quot;</span>)</span>
<span id="cb65-5"><a href="dataanalysis.html#cb65-5" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;get_outliers.R&quot;</span>)</span>
<span id="cb65-6"><a href="dataanalysis.html#cb65-6" tabindex="-1"></a></span>
<span id="cb65-7"><a href="dataanalysis.html#cb65-7" tabindex="-1"></a><span class="co"># Example (nca.example with Western countries)</span></span>
<span id="cb65-8"><a href="dataanalysis.html#cb65-8" tabindex="-1"></a><span class="fu">data</span>(nca.example)</span>
<span id="cb65-9"><a href="dataanalysis.html#cb65-9" tabindex="-1"></a>data <span class="ot">&lt;-</span> nca.example </span>
<span id="cb65-10"><a href="dataanalysis.html#cb65-10" tabindex="-1"></a>data <span class="ot">&lt;-</span> data[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">14</span>,<span class="dv">22</span>,<span class="dv">26</span>),] <span class="co">#exclude non-Western countries</span></span>
<span id="cb65-11"><a href="dataanalysis.html#cb65-11" tabindex="-1"></a>conditions <span class="ot">&lt;-</span> <span class="st">&quot;Individualism&quot;</span></span>
<span id="cb65-12"><a href="dataanalysis.html#cb65-12" tabindex="-1"></a>outcome <span class="ot">&lt;-</span> <span class="st">&quot;Innovation performance&quot;</span></span>
<span id="cb65-13"><a href="dataanalysis.html#cb65-13" tabindex="-1"></a>bottleneck.y <span class="ot">&lt;-</span> <span class="st">&quot;percentile&quot;</span></span>
<span id="cb65-14"><a href="dataanalysis.html#cb65-14" tabindex="-1"></a>plots <span class="ot">&lt;-</span> <span class="cn">FALSE</span> <span class="co"># do not show scatter plots</span></span>
<span id="cb65-15"><a href="dataanalysis.html#cb65-15" tabindex="-1"></a></span>
<span id="cb65-16"><a href="dataanalysis.html#cb65-16" tabindex="-1"></a><span class="co"># Define original analysis</span></span>
<span id="cb65-17"><a href="dataanalysis.html#cb65-17" tabindex="-1"></a>define_check <span class="ot">&lt;-</span> <span class="cf">function</span>(</span>
<span id="cb65-18"><a href="dataanalysis.html#cb65-18" tabindex="-1"></a>    name, </span>
<span id="cb65-19"><a href="dataanalysis.html#cb65-19" tabindex="-1"></a>    <span class="at">ceiling =</span> <span class="st">&quot;ce_fdh&quot;</span>, <span class="co"># original</span></span>
<span id="cb65-20"><a href="dataanalysis.html#cb65-20" tabindex="-1"></a>    <span class="at">d_threshold =</span> <span class="fl">0.1</span>, <span class="co"># original</span></span>
<span id="cb65-21"><a href="dataanalysis.html#cb65-21" tabindex="-1"></a>    <span class="at">p_threshold =</span> <span class="fl">0.05</span>, <span class="co"># original</span></span>
<span id="cb65-22"><a href="dataanalysis.html#cb65-22" tabindex="-1"></a>    <span class="at">scope =</span> <span class="cn">NULL</span>, <span class="co"># original </span></span>
<span id="cb65-23"><a href="dataanalysis.html#cb65-23" tabindex="-1"></a>    <span class="at">outliers =</span> <span class="dv">0</span>, <span class="co"># original</span></span>
<span id="cb65-24"><a href="dataanalysis.html#cb65-24" tabindex="-1"></a>    <span class="at">target_outcome =</span> <span class="dv">75</span> <span class="co"># original</span></span>
<span id="cb65-25"><a href="dataanalysis.html#cb65-25" tabindex="-1"></a>) {</span>
<span id="cb65-26"><a href="dataanalysis.html#cb65-26" tabindex="-1"></a>  <span class="fu">list</span>(</span>
<span id="cb65-27"><a href="dataanalysis.html#cb65-27" tabindex="-1"></a>    <span class="at">name =</span> name,</span>
<span id="cb65-28"><a href="dataanalysis.html#cb65-28" tabindex="-1"></a>    <span class="at">ceiling =</span> ceiling,</span>
<span id="cb65-29"><a href="dataanalysis.html#cb65-29" tabindex="-1"></a>    <span class="at">d_threshold =</span> d_threshold,</span>
<span id="cb65-30"><a href="dataanalysis.html#cb65-30" tabindex="-1"></a>    <span class="at">p_threshold =</span> p_threshold,</span>
<span id="cb65-31"><a href="dataanalysis.html#cb65-31" tabindex="-1"></a>    <span class="at">scope =</span> scope,</span>
<span id="cb65-32"><a href="dataanalysis.html#cb65-32" tabindex="-1"></a>    <span class="at">outliers =</span> outliers,</span>
<span id="cb65-33"><a href="dataanalysis.html#cb65-33" tabindex="-1"></a>    <span class="at">target_outcome =</span> target_outcome</span>
<span id="cb65-34"><a href="dataanalysis.html#cb65-34" tabindex="-1"></a>  )</span>
<span id="cb65-35"><a href="dataanalysis.html#cb65-35" tabindex="-1"></a>}</span>
<span id="cb65-36"><a href="dataanalysis.html#cb65-36" tabindex="-1"></a></span>
<span id="cb65-37"><a href="dataanalysis.html#cb65-37" tabindex="-1"></a><span class="co"># Define robustness checks (differences with Original)</span></span>
<span id="cb65-38"><a href="dataanalysis.html#cb65-38" tabindex="-1"></a>checks <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb65-39"><a href="dataanalysis.html#cb65-39" tabindex="-1"></a>  <span class="fu">define_check</span>(<span class="st">&quot;Original&quot;</span>),</span>
<span id="cb65-40"><a href="dataanalysis.html#cb65-40" tabindex="-1"></a>  <span class="fu">define_check</span>(<span class="st">&quot;Ceiling change&quot;</span>, <span class="at">ceiling =</span> <span class="st">&quot;cr_fdh&quot;</span>),</span>
<span id="cb65-41"><a href="dataanalysis.html#cb65-41" tabindex="-1"></a>  <span class="fu">define_check</span>(<span class="st">&quot;d threshold change&quot;</span>, <span class="at">d_threshold =</span> <span class="fl">0.2</span>),</span>
<span id="cb65-42"><a href="dataanalysis.html#cb65-42" tabindex="-1"></a>  <span class="fu">define_check</span>(<span class="st">&quot;p threshold change&quot;</span>, <span class="at">p_threshold =</span> <span class="fl">0.01</span>),</span>
<span id="cb65-43"><a href="dataanalysis.html#cb65-43" tabindex="-1"></a>  <span class="fu">define_check</span>(<span class="st">&quot;Scope change&quot;</span>, <span class="at">scope =</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="dv">20</span>, <span class="dv">100</span>, <span class="dv">0</span>, <span class="dv">250</span>))),</span>
<span id="cb65-44"><a href="dataanalysis.html#cb65-44" tabindex="-1"></a>  <span class="fu">define_check</span>(<span class="st">&quot;Single outlier removal&quot;</span>, <span class="at">outliers =</span> <span class="dv">1</span>),</span>
<span id="cb65-45"><a href="dataanalysis.html#cb65-45" tabindex="-1"></a>  <span class="fu">define_check</span>(<span class="st">&quot;Multiple outlier removal&quot;</span>, <span class="at">outliers =</span> <span class="dv">2</span>),</span>
<span id="cb65-46"><a href="dataanalysis.html#cb65-46" tabindex="-1"></a>  <span class="fu">define_check</span>(<span class="st">&quot;Target lower&quot;</span>, <span class="at">target_outcome =</span> <span class="dv">80</span>),</span>
<span id="cb65-47"><a href="dataanalysis.html#cb65-47" tabindex="-1"></a>  <span class="fu">define_check</span>(<span class="st">&quot;Target higher&quot;</span>, <span class="at">target_outcome =</span> <span class="dv">90</span>)</span>
<span id="cb65-48"><a href="dataanalysis.html#cb65-48" tabindex="-1"></a>)</span>
<span id="cb65-49"><a href="dataanalysis.html#cb65-49" tabindex="-1"></a></span>
<span id="cb65-50"><a href="dataanalysis.html#cb65-50" tabindex="-1"></a><span class="co"># Conduct robustness checks and produce robustness table</span></span>
<span id="cb65-51"><a href="dataanalysis.html#cb65-51" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">nca_robustness_table_general</span>(</span>
<span id="cb65-52"><a href="dataanalysis.html#cb65-52" tabindex="-1"></a>  <span class="at">data =</span> data,</span>
<span id="cb65-53"><a href="dataanalysis.html#cb65-53" tabindex="-1"></a>  <span class="at">conditions =</span> conditions,</span>
<span id="cb65-54"><a href="dataanalysis.html#cb65-54" tabindex="-1"></a>  <span class="at">outcome =</span> outcome,</span>
<span id="cb65-55"><a href="dataanalysis.html#cb65-55" tabindex="-1"></a>  <span class="at">ceiling =</span> ceiling,</span>
<span id="cb65-56"><a href="dataanalysis.html#cb65-56" tabindex="-1"></a>  <span class="at">scope =</span> scope,</span>
<span id="cb65-57"><a href="dataanalysis.html#cb65-57" tabindex="-1"></a>  <span class="at">d_threshold =</span> d_threshold,</span>
<span id="cb65-58"><a href="dataanalysis.html#cb65-58" tabindex="-1"></a>  <span class="at">p_threshold =</span> p_threshold,</span>
<span id="cb65-59"><a href="dataanalysis.html#cb65-59" tabindex="-1"></a>  <span class="at">outliers =</span> outliers,</span>
<span id="cb65-60"><a href="dataanalysis.html#cb65-60" tabindex="-1"></a>  <span class="at">bottleneck.y =</span> bottleneck.y,</span>
<span id="cb65-61"><a href="dataanalysis.html#cb65-61" tabindex="-1"></a>  <span class="at">target_outcome =</span> target_outcome,</span>
<span id="cb65-62"><a href="dataanalysis.html#cb65-62" tabindex="-1"></a>  <span class="at">plots =</span> plots,</span>
<span id="cb65-63"><a href="dataanalysis.html#cb65-63" tabindex="-1"></a>  <span class="at">checks =</span> checks</span>
<span id="cb65-64"><a href="dataanalysis.html#cb65-64" tabindex="-1"></a>)</span>
<span id="cb65-65"><a href="dataanalysis.html#cb65-65" tabindex="-1"></a></span>
<span id="cb65-66"><a href="dataanalysis.html#cb65-66" tabindex="-1"></a><span class="co"># View results</span></span>
<span id="cb65-67"><a href="dataanalysis.html#cb65-67" tabindex="-1"></a><span class="fu">print</span>(results)</span></code></pre></div>
<!-- ```{r robustnesstablecode, echo = TRUE, eval = FALSE} -->
<!-- library(NCA) -->
<!-- # NCA robustness function -->
<!-- nca_robustness <- function(data,  -->
<!--                            conditions,  -->
<!--                            outcome,  -->
<!--                            ceiling = "ce_fdh",  -->
<!--                            scope = NULL,  -->
<!--                            d_threshold = 0.1,  -->
<!--                            p_threshold = 0.05,  -->
<!--                            outliers = 0,  -->
<!--                            bottleneck.y = "percentile",  -->
<!--                            target_outcome = 75,  -->
<!--                            plots = FALSE) { -->
<!--   # Process outliers if needed -->
<!--   if (outliers != 0) { -->
<!--     source("get_outliers.R") -->
<!--     out <- get_outliers(data, conditions, outcome, ceiling, outliers) -->
<!--     all_outliers <- unname(unlist(out$outliers_df)[!is.na(out$outliers_df)]) -->
<!--     data <- data[-all_outliers, ] -->
<!--   } -->
<!--   # Run the NCA analysis -->
<!--   model <- nca_analysis( -->
<!--     data,  -->
<!--     conditions,  -->
<!--     outcome,  -->
<!--     ceilings = ceiling,  -->
<!--     bottleneck.x = 'percentile', -->
<!--     bottleneck.y = bottleneck.y,  -->
<!--     steps = c(target_outcome, NA), -->
<!--     test.rep = 10000, -->
<!--     scope = scope -->
<!--   ) -->
<!--   nca_output(model, summaries = FALSE, pdf = plots) -->
<!--   # Extract effect size and p value -->
<!--   effect_size <- sapply(conditions, function(p) model$summaries[[p]][[2]][[2]]) -->
<!--   p_value <- sapply(conditions, function(p) model$summaries[[p]][[2]][[6]]) -->
<!--   necessity <- ifelse(effect_size >= d_threshold & p_value <= p_threshold, "yes", "no") -->
<!--   # Extract the bottlenecks data frame from the model -->
<!--   b <- as.data.frame(model$bottlenecks[[1]]) -->
<!--   row_index <- which(b[[1]] == target_outcome) -->
<!--   row_values <- b[row_index, -1] -->
<!--   Bottlenecks1 <- as.numeric(row_values) -->
<!--   Bottlenecks2 <- round(Bottlenecks1 * nrow(data) / 100) -->
<!--   # Dataframe results -->
<!--   results_all <- data.frame( -->
<!--     Condition = conditions, -->
<!--     Effect_size = effect_size, -->
<!--     p_value = p_value, -->
<!--     Necessity = necessity, -->
<!--     Bottlenecks_percent = Bottlenecks1, -->
<!--     Bottlenecks_count = Bottlenecks2 -->
<!--   ) -->
<!--   return(results_all) -->
<!-- } -->
<!-- # Function to perform robustness checks -->
<!-- perform_robustness_checks <- function(data, -->
<!--                                       conditions, -->
<!--                                       outcome,  -->
<!--                                       ceiling = "ce_fdh", -->
<!--                                       scope = NULL,  -->
<!--                                       d_threshold = 0.1, -->
<!--                                       p_threshold = 0.05, -->
<!--                                       outliers = 0, -->
<!--                                       bottleneck.y = "percentile", -->
<!--                                       target_outcome = 75, -->
<!--                                       plots = FALSE) { -->
<!--   # Define the configurations for each robustness check -->
<!--   checks <- list( -->
<!--     list(name = "Original", ceiling = "ce_fdh", d_threshold = 0.1, p_threshold = 0.05, scope = NULL, outliers = 0, target_outcome = 75), -->
<!--     list(name = "Ceiling change", ceiling = "cr_fdh", d_threshold = 0.1, p_threshold = 0.05, scope = NULL, outliers = 0, target_outcome = 75), -->
<!--     list(name = "d threshold change", ceiling = "ce_fdh", d_threshold = 0.2, p_threshold = 0.05, scope = NULL, outliers = 0, target_outcome = 75), -->
<!--     list(name = "p threshold change", ceiling = "ce_fdh", d_threshold = 0.1, p_threshold = 0.01, scope = NULL, outliers = 0, target_outcome = 75), -->
<!--     list(name = "Scope change", ceiling = "ce_fdh", d_threshold = 0.1, p_threshold = 0.05, scope = list(c(20, 100, 0, 250)), outliers = 0, target_outcome = 75), -->
<!--     list(name = "Single outlier removal", ceiling = "ce_fdh", d_threshold = 0.1, p_threshold = 0.05, scope = NULL, outliers = 1, target_outcome = 75), -->
<!--     list(name = "Multiple outlier removal", ceiling = "ce_fdh", d_threshold = 0.1, p_threshold = 0.05, scope = NULL, outliers = 2, target_outcome = 75), -->
<!--     list(name = "Target lower", ceiling = "ce_fdh", d_threshold = 0.1, p_threshold = 0.05, scope = NULL, outliers = 0, target_outcome = 80), -->
<!--     list(name = "Target higher", ceiling = "ce_fdh", d_threshold = 0.1, p_threshold = 0.05, scope = NULL, outliers = 0, target_outcome = 90) -->
<!--   ) -->
<!--   # Initialize an empty list to store results -->
<!--   results_list <- list() -->
<!--   # Perform each robustness check -->
<!--   for (check in checks) { -->
<!--     result <- nca_robustness( -->
<!--       data = data, -->
<!--       conditions = conditions, -->
<!--       outcome = outcome, -->
<!--       ceiling = check$ceiling, -->
<!--       scope = check$scope, -->
<!--       d_threshold = d_threshold, -->
<!--       p_threshold = p_threshold, -->
<!--       outliers = check$outliers, -->
<!--       bottleneck.y = bottleneck.y, -->
<!--       target_outcome = check$target_outcome, -->
<!--       plots = plots -->
<!--     ) -->
<!--     result$`Robustness check` <- check$name -->
<!--     results_list[[check$name]] <- result -->
<!--   } -->
<!--   # Combine all results into one data frame -->
<!--   results_all <- do.call(rbind, results_list) -->
<!--   # Reorder columns -->
<!--   results_all <- results_all[c("Condition", "Robustness check", "Effect_size", "p_value", "Necessity", "Bottlenecks_percent", "Bottlenecks_count")] -->
<!--   row.names(results_all) = NULL -->
<!--   # Reorganize the dataframe into new blocks -->
<!--   n <- length(conditions) # Block size -->
<!--   rows_per_block <- seq(1, n) # Sequence of row indices in one block -->
<!--   # Create a new column to assign new block numbers -->
<!--   results_all$NewBlock <- rep(rows_per_block, length.out = nrow(results_all)) -->
<!--   # Split the dataframe into blocks and combine the blocks sequentially -->
<!--   reorganized_df <- do.call(rbind, lapply(rows_per_block, function(i) { -->
<!--     results_all[results_all$NewBlock == i, ] # Subset rows for the current block -->
<!--   })) -->
<!--   # Remove the helper column and reset row names -->
<!--   reorganized_df <- reorganized_df[, -ncol(reorganized_df)] -->
<!--   row.names(reorganized_df) <- NULL -->
<!--   return(reorganized_df) -->
<!-- } -->
<!-- # Example (Western countries) -->
<!-- data(nca.example) -->
<!-- data <- nca.example  -->
<!-- data <- data[-c(14,22,26),] -->
<!-- conditions <- "Individualism" -->
<!-- outcome <- "Innovation performance" -->
<!-- ceiling <- "ce_fdh" -->
<!-- scope <- NULL -->
<!-- d_threshold <- 0.1 -->
<!-- p_threshold <- 0.05 -->
<!-- outliers <- 0 -->
<!-- bottleneck.y <- "percentile" -->
<!-- target_outcome <- 75 -->
<!-- plots <- FALSE -->
<!-- # Perform robustness checks -->
<!-- results <- perform_robustness_checks( -->
<!--   data = data, -->
<!--   conditions = conditions, -->
<!--   outcome = outcome, -->
<!--   ceiling = ceiling, -->
<!--   scope = scope, -->
<!--   d_threshold = d_threshold, -->
<!--   p_threshold = p_threshold, -->
<!--   outliers = outliers, -->
<!--   bottleneck.y = bottleneck.y, -->
<!--   target_outcome = target_outcome, -->
<!--   plots = plots -->
<!-- ) -->
<!-- # View results -->
<!-- print(results) -->
<!-- ``` -->
<!-- ## \textcolor{gray}{Combining NCA with regression} -->
<!-- ## <span style="color: #D3D3D3">Combining NCA with regression</span> {#ncaregression} -->
<!-- under construction -->
</div>
</div>
<div id="ncaregression" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Combining NCA with regression analysis<a href="dataanalysis.html#ncaregression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- see: [NCA website](https://www.erim.eur.nl/necessary-condition-analysis/publications/book/complementing-nca-and-regression/). -->
<!-- gray}{Combining NCA with QCA} -->
<!-- ## <span style="color: #D3D3D3">Combining NCA with QCA</span> {#ncaqca} -->
<!-- under construction -->
<div id="introduction" class="section level3 hasAnchor" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> Introduction<a href="dataanalysis.html#introduction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Regression is the mother of all data analyses in the social sciences. It was invented more than 100 years ago when Francis Galton <span class="citation">(<a href="#ref-galton1886regression">Galton, 1886</a>)</span> quantified the pattern in the scores of parental height and child height (see Figure <a href="dataanalysis.html#fig:ncaols1fig">4.12</a> showing the original graph).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ncaols1fig"></span>
<img src="Figure1ncaols.png" alt="Francis Galton’s (1886) graph with data on Parent height ('mid-parents height') and Child height ('Adult children height')." width="50%" />
<p class="caption">
Figure 4.12: Francis Galton’s (1886) graph with data on Parent height (‘mid-parents height’) and Child height (‘Adult children height’).
</p>
</div>
<p>In Figure <a href="dataanalysis.html#fig:ncaols2fig">4.13</a> Galton’s data are shown in two <span class="math inline">\(XY\)</span> scatter plots.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ncaols2fig"></span>
<img src="Figure2ncaols.png" alt="Scatter plots of the relationship between Parent height ($X$) and Child height ($Y$) (after Galton (1886). A. With a regression line. B. With a ceiling line." width="100%" />
<p class="caption">
Figure 4.13: Scatter plots of the relationship between Parent height (<span class="math inline">\(X\)</span>) and Child height (<span class="math inline">\(Y\)</span>) (after Galton (1886). A. With a regression line. B. With a ceiling line.
</p>
</div>
<p>Galton drew lines though the middle of the data for describing the average trend between Parental height and Child height: the regression line (Figure <a href="dataanalysis.html#fig:ncaols2fig">4.13</a> A). For example, with a Parent height of 175 cm, the estimated average Child height is about 170 cm. Galton could also have drawn a line on top of the data for describing the necessity of Parent height for Child height: the ceiling line (Figure <a href="#fig:ncaols2"><strong>??</strong></a> B). For example, with a Parent height of 175 cm, the estimated maximum possible Child height is about 195 cm. But Galton did not draw a ceiling line, and the social sciences have adopted the average trend line as the basis for many data analysis approaches. Regression analysis has developed over the years and many variants exist. The main variant is Ordinary Least Squares (OLS) regression. It is used for example in Simple Linear Regression (SLR), Multiple Linear Regression (MLR), path analysis, variance-based Structural Equation Modeling (SEM) and Partial Least Squares Structural Equation Modeling (PLS-SEM). In this section I compare OLS regression with NCA.</p>
</div>
<div id="logic-and-theory" class="section level3 hasAnchor" number="4.5.2">
<h3><span class="header-section-number">4.5.2</span> Logic and theory<a href="dataanalysis.html#logic-and-theory" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>OLS regression uses additive, average effect logic. The regression line (Figure <a href="dataanalysis.html#fig:ncaols2fig">4.13</a> A) predicts the average <span class="math inline">\(Y\)</span> for a given <span class="math inline">\(X\)</span>. Because the cases are scattered, for a given <span class="math inline">\(X\)</span> also higher and lower values of <span class="math inline">\(Y\)</span> than the average value of <span class="math inline">\(Y\)</span> are possible. With one <span class="math inline">\(X\)</span> (Simple Linear Regression), <span class="math inline">\(Y\)</span> is predicted by the regression equation is:</p>
<p><span class="math display" id="eq:ols1">\[\begin{equation}
\tag{4.1}
Y = β_0  + β_1 X + ɛ(X)
\end{equation}\]</span></p>
<p>where <span class="math inline">\(β_0\)</span> is the intercept of the regression line, <span class="math inline">\(β_1\)</span> is the slope of the regression line, and <span class="math inline">\(ɛ(X)\)</span> is the error term representing the scatter around the regression line for a given <span class="math inline">\(X\)</span>. The slope of the regression line (regression coefficient) is estimated by minimizing the squared vertical distances between the observed <span class="math inline">\(Y\)</span>-values and the regression line (‘least squares’). The error term includes the effect of all other factors that can contribute to the outcome <span class="math inline">\(Y\)</span>.</p>
<p>For the parent-child data, the regression equation is <span class="math inline">\(Y = 57.5 + 0.64 X + ɛ(X)\)</span>. OLS regression assumes that on average <span class="math inline">\(ɛ(X) = 0\)</span>. Thus, when <span class="math inline">\(X\)</span> (Parent height) is 175 cm, the estimated average Child height is about 170 cm. In contrast NCA’s C-LP ceiling line is defined by <span class="math inline">\(Y_c = -129 + 1.85 X\)</span>. Thus, when <span class="math inline">\(X\)</span> (Parent height) is 175 cm, the estimated maximum possible Child height is about 195 cm. Normally, in NCA the ceiling line is interpreted inversely (e.g., in the bottleneck table): <span class="math inline">\(X_c = (Y_c + 129)/1.85\)</span> indicating, while assuming a non-decreasing ceiling line, that a minimum level of <span class="math inline">\(X = X_c\)</span> is necessary (but not sufficient) for a target level of <span class="math inline">\(Y =Y_c\)</span>. When parents wish to have a child of 200 cm it is necessary (but not sufficient) that their Parent height is at least about 177 cm.</p>
<p>To allow for doing statistical tests with OLS, it is usually assumed that the error term for a given <span class="math inline">\(X\)</span> is normally distributed (with average value 0): cases close to the regression line for the given <span class="math inline">\(X\)</span> are more likely than cases far from the regression line. The normal distribution is unbounded, hence very high or very low values of <span class="math inline">\(Y\)</span> are possible, though not likely. This implies that any high value of <span class="math inline">\(Y\)</span> is possible. Even without the assumption of the normal distribution of the error term, a fundamental assumption of OLS is that the <span class="math inline">\(Y\)</span> value is unbounded <span class="citation">(<a href="#ref-berry1993understanding">Berry, 1993</a>)</span>. Thus, very large child heights (e.g., 300 cm) are theoretically possible in OLS, but unlikely. This assumption contradicts NCA’s logic in which <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are presumed bounded. <span class="math inline">\(X\)</span> puts a limit on <span class="math inline">\(Y\)</span> and thus there is a border represented by the ceiling line. The limits can be empirically observed in the sample (e.g., the height of the observed tallest person in the sample is 205 cm) for defining NCA’s empirical scope or can be theoretically defined (e.g., the height of the ever-observed tallest person of 272 cm) for defining the NCA’s theoretical scope.</p>
<p>Additivity is another part of regression logic. It is assumed that the terms of the regression equation are added. Next to <span class="math inline">\(X\)</span>, the error term is always added in the regression equation. Possibly also other <span class="math inline">\(X\)</span>’s or combination of <span class="math inline">\(X\)</span>’s are added in the regression equation (multiple regression, see below). This means that the terms that make up the equation can compensate for each other. For example, when <span class="math inline">\(X\)</span> is low, <span class="math inline">\(Y\)</span> can still be achieved when other terms (error term or other <span class="math inline">\(X\)</span>’s) give a higher contribution to <span class="math inline">\(Y\)</span>. The additive logic implies that for achieving a certain level of <span class="math inline">\(Y\)</span>, no <span class="math inline">\(X\)</span> is necessary. This additive logic contradicts NCA’s logic that <span class="math inline">\(X\)</span> is necessary: <span class="math inline">\(Y\)</span> cannot be achieved when the necessary factor does not have the right level, and this absence of <span class="math inline">\(X\)</span> cannot be compensated by other factors.</p>
<p>Results of a regression analysis are usually interpreted in terms of probabilistic sufficiency. A common probabilistic sufficiency-type of hypotheses is ‘<span class="math inline">\(X\)</span> likely increases <span class="math inline">\(Y\)</span>’ or ‘<span class="math inline">\(X\)</span> has an average positive effect on <span class="math inline">\(Y\)</span>’. Such hypothesis can be tested with regression analysis. The hypothesis is considered to be supported if the regression coefficient is positive. Often, it is then suggested that <span class="math inline">\(X\)</span> is sufficient to produce an increase the likelyhood of the outcome <span class="math inline">\(Y\)</span>. The results also suggest that a given <span class="math inline">\(X\)</span> is not necessary for producing the outcome <span class="math inline">\(Y\)</span> because other factors in the regression model (other <span class="math inline">\(X\)</span>’s and the error term) can compensate for the absence of a low level of <span class="math inline">\(X\)</span>.</p>
</div>
<div id="data-analysis" class="section level3 hasAnchor" number="4.5.3">
<h3><span class="header-section-number">4.5.3</span> Data analysis<a href="dataanalysis.html#data-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Most regression models include more than one <span class="math inline">\(X\)</span>. The black box of the error term is opened and other <span class="math inline">\(X\)</span>’s are added to the regression equation (Multiple Linear Regression - MLR), for example:</p>
<p><span class="math display" id="eq:ols2">\[\begin{equation}
\tag{4.2}
Y = β_0 + β_1 X_1 + β_2 X_2 + \epsilon_X
\end{equation}\]</span></p>
<p>where <span class="math inline">\(β_1\)</span> and <span class="math inline">\(β_2\)</span> are the regression coefficients. By adding more factors that contribute to <span class="math inline">\(Y\)</span> into the equation, <span class="math inline">\(Y\)</span> is predicted for given combinations of <span class="math inline">\(X\)</span>’s,and a larger part of the scatter is explained. R<span class="math inline">\(^2\)</span> is the amount of explained variance of a regression model and can have values between 0 and 1. By adding more factors, usually more variance is explained resulting in higher values of R<span class="math inline">\(^2\)</span>.</p>
<p>Another reason to add more factors is to avoid ‘omitted variable bias’. This bias is the result of not including factors that correlate with <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, which causes in biased estimations of the regression coefficients. Hence, the common standard of regression is not the simple OLS regression with one factor, but multiple regression with many factors including control variables to reduce omitted variable bias. By adding more relevant factors, the prediction of <span class="math inline">\(Y\)</span> becomes better and the risk of omitted variable bias is reduced. Adding factors in the equation is not just adding new factors (<span class="math inline">\(X\)</span>). Some factors may be combined such as squaring a factor (<span class="math inline">\(X^2\)</span>) to represent a non-linear effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, or taking the product of two factors <span class="math inline">\((X_2 * X_2)\)</span> to represent the interaction between these factors. Such combination of factors are added as a separate terms into the regression equation. Also, other regression-based approaches such as SEM and PLS-SEM include many factors. In SEM models factors are ‘latent variables’ of the measurement model of the SEM approach.</p>
<p>A study by <span class="citation">Bouquet &amp; Birkinshaw (<a href="#ref-bouquet2008weight">2008</a>)</span> is an example of the prediction of an average outcome using MLR by adding many terms including combined factors in the regression equation. This highly cited article in the <em>Academy of Management Journal</em> studies multinational enterprises (MNE’s) to predict how subsidiary companies gain attention from their headquarters (<span class="math inline">\(Y\)</span>). They use a multiple regression model with 25 terms (<span class="math inline">\(X\)</span>’s and combination of <span class="math inline">\(X\)</span>’s) and an ‘error’ term <span class="math inline">\(ɛ\)</span>. With the regression model the average outcome (average attention) for a group of cases (or for the theoretical ‘the average case’) for given values of the terms can be estimated. The error term represents all unknown factors that have a positive or negative effect on the outcome but are not included in the model, assuming that the average effect of the error term is zero. <span class="math inline">\(β_0\)</span> is a constant and the other <span class="math inline">\(β_i\)</span>’s are the regression coefficients of the terms, indicating how strong the term is related to the outcome (when all other terms are constant). The regression model is:</p>
<!-- \begin{equation} -->
<!-- (\#eq:ols3) -->
<p><span class="math inline">\(Attention = \\
β_0 \\
+ β_1\ Subsidiary\ size \\
+ β_2\ Subsidiary\ age  \\
+ β_3\ (Subsidiary\ age)^2 \\
+ β_4\ Subsidiary\ autonomy \\
+ β_5\ Subsidiary\ performance \\
+ β_6\ (Subsidiary\ performance)^2 \\
+ β_7\ Subsidiary\ functional\ scope \\
+ β_8\ Subsidiary\ market\ scope \\
+ β_9\ Geographic\ area\ structure \\
+ β_{10}\ Matrix\ structure \\
+ β_{11}\ Geographic\ scope \\
+ β_{12}\ Headquarter\ AsiaPacific\ parentage \\
+ β_{13}\ Headquarter\ NorthAmerican\ parentage \\
+ β_{14}\ Headquarter\ subsidiary\ cultural\ distance \\
+ β_{15}\ Presence\ of\ MNEs\ in\ local\ market \\
+ β_{16}\ Local\ market\ size \\
+ β_{17}\ Subsidiary\ strength\ within\ MNE\ Network \\
+ β_{18}\ Subsidiary\ initiative\ taking \\
+ β_{19}\ Subsidiary\ profile\ building \\
+ β_{20}\ Headquarter\ subsidiary\ geographic\ distance \\
+ β_{21}\ (Initiative\ taking * Geographic\ distance) \\
+ β_{22}\ (Profile\ building * Geographic\ distance) \\
+ β_{23}\ Subsidiary\ downstream\ competence \\
+ β_{24}\ (Initiative\ taking * Downstream\ competence) \\
+ β_{25}\ (Profile\ building * Downstream\ competence) \\
+ \epsilon\)</span></p>
<p>The 25 terms of single and combined factors in the regression equation explain 27% of the variance (R<span class="math inline">\(^2\)</span> = 0.27). Thus, the error term (representing the not included factors) represent the other 73% percent (unexplained variance). Single terms predict only a small part of the outcome. For example, ‘subsidiary initiative taking’ (term 18) is responsible for 2% to the explained variance.</p>
<p>The example shows that adding more factors makes the model more complex and less understandable and therefore less useful in practice. The contrast with NCA is large. NCA can have a model with only one factor that perfectly explains the absence of a certain level of an outcome when the factor is not present at the right level for that outcome.
Whereas regression models must include factors that correlate with other factors and with the outcome to avoid biased estimation of the regression coefficient, NCA’s effect size for a necessary factor is not influenced by the absence or presence of other factors in the model. This is illustrated with and example about the effect of a sales person’s personality on sales performance using data of 108 cases (sales representatives from a large USA food manufacturer) obtained with The Hogan Personality Inventory (HPI) personality assessment tool for predicting organizational performance <span class="citation">(<a href="#ref-hogan2002hogan">Hogan &amp; Hogan, 2007</a>)</span>. Details of the example are in <span class="citation">Dul, Hauff, et al. (<a href="#ref-dul2021marketing">2021</a>)</span>. The statistical descriptives of the data (mean, standard deviation, correlation) are shown in Figure <a href="dataanalysis.html#fig:ncaols3">4.14</a> A. Ambition and Sociability are correlated with <span class="math inline">\(Y\)</span> as well as each other. Hence, if one of them is omitted from the model the regression results may be biased.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ncaols3"></span>
<img src="Figure3ncaols.png" alt="Example of the results of a regression analysis and NCA. Effect of four personality traits of sales persons on sales performance. A. Descriptive statistics. B. Results of regression analysis and NCA for two different models.  Data from @hogan2002hogan"  />
<p class="caption">
Figure 4.14: Example of the results of a regression analysis and NCA. Effect of four personality traits of sales persons on sales performance. A. Descriptive statistics. B. Results of regression analysis and NCA for two different models. Data from <span class="citation">Hogan &amp; Hogan (<a href="#ref-hogan2002hogan">2007</a>)</span>
</p>
</div>
<p>The omission of one variable is shown in Figure <a href="dataanalysis.html#fig:ncaols3">4.14</a> B, middle column. The full model (Model 1) includes all four personality factors. The regression results show that Ambition and Sociability have positive average effects on Sales performance (regression coefficients 0.13 and 0.16 respectively, and Learning approach has a negative average effect on Sales performance (regression coefficient -0.11). Interpersonal sensitivity has virtually no average effect on Sales performance (regression coefficient 0.01). The p values for Ambition and Sociability are relatively small. Model 2 has only three factors because Sociability is omitted. The regression results show that the regression coefficients of all three remaining factors have changed. The regression coefficient for Ambition has increased to 0.18, and the regression coefficients of the other two factors have minor differences (because these factors are less correlated with the omitted variable). Hence, in a regression model that is not correctly specified because factors that correlate with factors that are included in the model and with the outcome are not included, the regression coefficients of the included factors may be biased (omitted variable bias). However, the results of the NCA analysis does not change when a variable is omitted (Figure <a href="dataanalysis.html#fig:ncaols3">4.14</a> B, right column). This means that an NCA model does not suffer from omitted variable bias.</p>
</div>
<div id="how-to-combine-nca-and-regression" class="section level3 hasAnchor" number="4.5.4">
<h3><span class="header-section-number">4.5.4</span> How to combine NCA and regression<a href="dataanalysis.html#how-to-combine-nca-and-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Regression and NCA are fundamentally different and complementary. A regression analysis can be added to a NCA study to evaluate the average effect of the identified necessary condition for the outcome. However, the researcher must then include all relevant factors, also those that are not expected to be necessary, to avoid omitted variable bias, and must obtain measurement scores for these factors.
When NCA is added to a regression study, not much extra effort is required. Such regression study can be a multiple regression analysis, or the analysis of the structural model of variance based structural equation modeling (SEM), Partial Least Squares structural equation modeling (PLS-SEM) or another regression technique. If a theoretical argument is available for a factor (indicator or latent construct) being necessary for an outcome, any factor that is included in the regression model (independent variables, moderators, mediators) can also be treated as a potential necessary condition that can be tested with NCA. This could be systematically done:</p>
<ul>
<li><p>For all factors in the regression model that are potential necessary conditions.</p></li>
<li><p>For those factors that provide a surprising result in the regression analysis (e.g., in terms of direction of the regression coefficient, see below the situation of disparate duality) to better understand the result.</p></li>
<li><p>For those factors that show no or a limited effect in the regression analysis (small regression coefficient) to check whether such ‘unimportant’ factors on average still may be necessary for a certain outcome.</p></li>
<li><p>For those factors that have a large effect in the regression analysis (large regression coefficient) to check whether an ‘important’ factor on average may also be necessary.</p></li>
</ul>
<p>When adding NCA to a regression analysis more insight about the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> can be obtained.</p>
<p>Figure <a href="dataanalysis.html#fig:ncaols4">4.15</a> shows a example of a combined NCA and simple OLS regression analysis.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ncaols4"></span>
<img src="Figure4ncaols.png" alt="Example of interpretation of findings from regression analysis and NCA"  />
<p class="caption">
Figure 4.15: Example of interpretation of findings from regression analysis and NCA
</p>
</div>
<!-- setwd("~") -->
<!-- library(NCA) -->
<!-- set.seed (13) -->
<!-- n =100 -->
<!-- c = 1.2 -->
<!-- X <- runif(n) -->
<!-- Y <- X + c*runif(n) -->
<!-- cor(X,Y) -->
<!-- data <- data.frame(X,Y) -->
<!-- modelN <- nca_analysis(data,1,2, ceilings = c('ols', 'c_lp'), test.rep = 10000) -->
<!-- modelN -->
<!-- ("ncaols.ppdfdf",5,5)  -->
<!-- nca_output(modelN, plots=T) -->
<!-- y1 <- 1.3 -->
<!-- abline(h = y1, lty=2, col = 'red') -->
<!-- xc1 <- (y1 - modelN$summaries$X$params[10])/modelN$summaries$X$params[9] -->
<!-- xc1 -->
<!-- abline(v = xc1, lty=2, col = 'red') -->
<!-- modelR<-lm(Y~X) -->
<!-- summary(modelR) -->
<!-- xr1 <- (y1- modelR$coefficients[1])/modelR$coefficients[2]  -->
<!-- xr1 -->
<!-- abline(v=xr1, lty=2, col = 'red') -->
<!-- text(min(X), y1, round(y1,1)) -->
<!-- text(xc1, min(Y), round(xc1,2)) -->
<!-- text(xr1, min(Y), round(xr1,2)) -->
<!-- yr2<- modelR$coefficients[1] + modelR$coefficients[2]*xc1  -->
<!-- yc2<- modelN$summaries$X$params[10] + modelN$summaries$X$params[9]*xr1 -->
<!-- abline(h = yr2, lty=2, col = 'red') -->
<!-- abline(h = yc2, lty=2, col = 'red') -->
<!-- text(min(X), yr2, round(yr2,1)) -->
<!-- text(min(X), yc2, round(yc2,1)) -->
<!-- dev.off() -->
<p><span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are related with correlation coefficient 0.58. The data may be interpreted as an indication of a necessity relationship, an indication of an average effect relationship, or both. The average relationship is illustrated with a green OLS regression line with intercept 0.66 and slope 0.9 (p &lt; 0.001). The ceiling line (C-LP) is illustrated with the dashed blue with intercept 1.1 and slope 1.0 (effect size d = 0.24; p &lt; 0.001). According the ceiling line, for an outcome value <span class="math inline">\(Y = 1.3\)</span>, a minimum level of the condition of <span class="math inline">\(X = 0.15\)</span> is necessary. According to the vertical line <span class="math inline">\(X = 0.15\)</span>, the <em>average</em> value of the outcome for this value the condition is <span class="math inline">\(Y = 0.8\)</span>. In other words, for a given value of <span class="math inline">\(X\)</span> (e.g., <span class="math inline">\(X =0.15\)</span>), NCA predicts the <em>maximum</em> possible value of <span class="math inline">\(Y\)</span> (<span class="math inline">\(Y = 1.3\)</span>), whereas OLS regression predicts the <em>average</em> value of <span class="math inline">\(Y\)</span> (<span class="math inline">\(Y = 0.8\)</span>). OLS regression does not predict a maximum value of <span class="math inline">\(Y\)</span>. Regression analysis assumes that any value of <span class="math inline">\(Y\)</span> is possible. Also very high values of <span class="math inline">\(Y\)</span>, up to infinity, are possible, but unlikely. The horizontal line <span class="math inline">\(Y = 1.3\)</span> not only intersects the ceiling line, showing the required level of <span class="math inline">\(X = 0.15\)</span> that all cases must have satisfied to be able to reach <span class="math inline">\(Y = 1.3\)</span>, but also the OLS regression line, showing that the <em>average</em> outcome <span class="math inline">\(Y = 1.3\)</span> is obtained when <span class="math inline">\(X = 0.72\)</span>. The vertical line <span class="math inline">\(X = 0.72\)</span> intersects the ceiling line at <span class="math inline">\(Y = 1.9\)</span>, showing that this outcome level is maximally possible when the condition level <span class="math inline">\(X = 0.72\)</span>.</p>
<p>In this example the regression line has the same direction as the ceiling line. There is a positive average effect and a ‘positive’ necessity effect (high level of <span class="math inline">\(X\)</span> is necessary for high level of <span class="math inline">\(Y\)</span>). I call this situation: ‘<em>commensurate duality</em>’. Commensurate duality also applies when both lines have negative slopes. It is also possible, but less common that the slope of the ceiling line is positive and the slope of the regression line is negative. In this situation there is a negative average effect and a ‘positive’ necessity effect. A high level of <span class="math inline">\(X\)</span> is necessary for high level of <span class="math inline">\(Y\)</span>, but increasing <span class="math inline">\(X\)</span> on average reduces <span class="math inline">\(Y\)</span>. This can occur when a relatively high number of cases are in the lower right corner of the scatter plot (cases with high <span class="math inline">\(X\)</span> that do not reach high <span class="math inline">\(Y\)</span>). The situation when both lines have opposite slopes is called ‘<em>disparate duality</em>’. A third situation is possible that there is no significant average effect and yet a significant necessity effect, or the other way around. I call this situation ‘<em>impact duality</em>’. The word ‘duality’ refers to a data interpretation battle. Should the observed data pattern be describe with regression analysis, NCA or both? The answer depends on the researcher’s theory. When a conventional theory with additive/average effect logic is used, regression analysis ensures theory-method fit.
When a necessity theory is used, NCA ensures theory-method fit. When a conventional theory and a necessity theory are both used <span class="citation">(e.g., in an ‘embedded necessity theory,’ see <a href="#ref-bokrantz2022building">Bokrantz &amp; Dul, 2023</a> and see Chapter <a href="theory.html#theory">2</a>)</span> both methods should be used to ensure theory-method fit. Hence, it depends on the underlying theory what method(s) should be selected to analyse the data.</p>
</div>
<div id="what-is-the-same-in-nca-and-regression" class="section level3 hasAnchor" number="4.5.5">
<h3><span class="header-section-number">4.5.5</span> What is the same in NCA and regression?<a href="dataanalysis.html#what-is-the-same-in-nca-and-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>I showed that regression has several characteristics that are fundamentally different from the characteristics of NCA. Regression is about average trends, uses additive logic, assumes unbounded <span class="math inline">\(Y\)</span> values, is prone to omitted variable bias, needs control variables, and is used for testing sufficiency-type of hypotheses, whereas NCA is about necessity logic, assumes limited <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, is immune for omitted variable bias, does not need control variables, and is used for testing necessity hypotheses.</p>
<p>However, NCA and regression also share several characteristics. Both NCA and regression are variance-based approaches and use linear algebra (although NCA can also be applied with the set theory approach with Boolean algebra; see Section <a href="dataanalysis.html#ncaqca">4.7</a> on NCA and QCA). Both methods need good (reliable and valid) data without measurement error, although NCA may be more prone to measurement error. For statistical generalization from sample to population both methods need to have a probability sample that is representative for the population, and having larger samples usually give more reliable estimations of the population parameters, although NCA can handle small sample sizes. Additionally, for generalization of the findings of a study both methods need replications with different samples; a one-shot study is not conclusive. Both methods cannot make strong causal interpretations when observational data are used; then at least also theoretical support is needed. When null hypothesis testing is used in both methods, such tests and the corresponding p values have strong limitations and are prone to misinterpretations; a low p value only indicates a potential randomness of the data and is not a prove of the specific alternative hypothesis of interest (average effect, or necessity effect).</p>
<p>When a researcher uses NCA or OLS, these common fundamental limitations should be acknowledged. When NCA and OLS are used in combination the fundamental differences between the methods should be acknowledged. It is important to stress that one method is not better than the other. NCA and OLS are different and address different research questions. To ensure theory-method fit, OLS is the preferred method when the researcher is interested in an average effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, and NCA is the preferred method when the researcher is interested in the necessity effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>.</p>
</div>
</div>
<div id="ncaplssem" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Combining NCA with (PLS-)SEM<a href="dataanalysis.html#ncaplssem" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One of the most common applications of combining NCA with a regression-based method is the use of NCA in the context of Partial Least Squares - Structural Equation Modeling (PLS-SEM). The reason for this popularity may be two-fold.</p>
<ol style="list-style-type: decimal">
<li><p>Leading PLS-SEM proponents introduced NCA as a methodological enrichment of PLS-SEM, and provided specific recommendations <span class="citation">(<a href="#ref-richter2020predictors">Richter, Schubring, et al., 2020</a>; <a href="#ref-richter2022use">Richter et al., 2022</a>; <a href="#ref-richter2023apply">Richter, Hauff, Ringle, et al., 2023</a>)</span> and extensions <span class="citation">(<a href="#ref-hauff2024importance">Hauff et al., 2024</a>; <a href="#ref-sarstedt2024combined">Sarstedt et al., 2024</a>)</span> on how to use NCA in combination with PLS-SEM.</p></li>
<li><p>A basic version of the NCA software became part of a popular software package for conducting PLS-SEM (SmartPLS, see Section <a href="miscellaneous.html#othersoftware">7.1.2</a>).</p></li>
</ol>
<p>NCA has also been applied in combination with other types of SEM such as the classical covariance-based SEM (CB-SEM).</p>
<p>A SEM model consists of two parts. The measurement model defines how latent variables are represented by measured indicators. A latent variable is an unobserved construct that is derived from observed indicators. The structural model specifies how the latent variables are related to each other.</p>
<!-- By default, a probabilistic sufficiency relationship is assumed between the latent variables, and regression analysis is applied to estimate the path coefficient (regression coefficient) of the relationship.  -->
<!-- PLS-SEM estimation uses partial least squares to maximize the explained variance in the latent variable whose variance is explained ('dependent variable'). CB-SEM estimation uses the covariance matrix and estimation techniques like maximum likelihood or generalized least squares. -->
<!-- Combining NCA with SEM means that scores of the latent variables are used as input to NCA to investigate if the relationships between two latent variables are (also) necessary (if there is a theoretical justification for it). In NCA, latent variables of the structural model are given the role of condition or outcome to study their necessity relationship. All guidelines for applying NCA in general (see Sections \@ref(guidelines) and \@ref(review)) also apply to NCA combined with SEM. -->
<!-- xx -->
<p>In both PLS-SEM and CB-SEM, latent variable scores can be obtained and used for further analysis. However, the estimation approach differs. PLS-SEM uses partial least squares to estimate latent variable scores as weighted composites of indicators and to maximize the explained variance in the dependent variables. CB-SEM estimates model parameters based on the covariance matrix, using techniques such as maximum likelihood or generalized least squares. Latent variable scores are not directly estimated in the model fitting process, but can be computed afterward if needed (e.g., as factor scores).</p>
<p>Combining NCA with SEM involves using the estimated scores of the latent variables as input for NCA. This allows researchers to examine whether a relationship between two latent variables are not only related in terms of probabilistic sufficiency (as modeled in SEM) but also in terms of necessity, assuming a theoretical rationale exists. In NCA, latent variables from the structural model can take the role of condition or outcome to study necessity relationships.</p>
<p>All guidelines for applying NCA in general (see Sections <a href="summary.html#guidelines">1.7</a> and <a href="summary.html#review">1.8</a>) also apply to combining NCA with SEM.</p>
<div id="stepsncasem" class="section level3 hasAnchor" number="4.6.1">
<h3><span class="header-section-number">4.6.1</span> Steps for conducting NCA with SEM<a href="dataanalysis.html#stepsncasem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Figure <a href="dataanalysis.html#fig:semflowchart">4.16</a> shows a flowchart for conducting NCA in combination with SEM.
<br></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:semflowchart"></span>
<img src="SEMflowchart.png" alt="Flowchart for conducting NCA in combination with Structural Equation Modeling (SEM)." width="50%" />
<p class="caption">
Figure 4.16: Flowchart for conducting NCA in combination with Structural Equation Modeling (SEM).
</p>
</div>
<p>Below the steps are discussed in detail and an example is given about how to use NCA with PLS-SEM. Since SEM terminology about ‘indicators’, ‘weights’, ‘latent variables’ and ‘rescaling’ varies across the SEM literature, the following terminology is used in this book:
<br></p>
<div style="border: 2px solid #17a2b8; background-color: #e8f7fc; padding: 10px; border-radius: 5px;">
<p><strong>Terminology</strong>
<font size="1"></p>
<p><strong>General</strong>:</p>
<ul>
<li><p>Rescaling: normalization or standardization of original scores.</p></li>
<li><p>Normalization (or min-max normalization): rescaling of scales with new minimum and maximum values (e.g., 0-1 or 0-100).</p></li>
<li><p>Standardization: Rescaling of observed scale values based on the their probability distribution. (z-score)</p></li>
</ul>
<p><strong>Indicator</strong>:</p>
<ul>
<li><p>Indicator (variable). A manifest/measured variable linked to a latent variable.</p></li>
<li><p>Indicator score. The value of an indicator.</p></li>
<li><p>Raw indicator score. The value of the indicator measured on a scale. The scale usually has minimum and maximum values, e.g., Likert scale ranging from 1-5 or 1-7.</p></li>
<li><p>Normalized indicator score. The value of an indicator after min-max normalization of the raw indicator score (e.g., 0-1 scale or percentage scale 0-100).</p></li>
<li><p>Standardized indicator score. The value of an indicator after standardization of the raw indicator (z-score: rescaled such that the mean = 0 and standard deviation = 1).</p></li>
<li><p>Original indicator score. The indicator that is used as input for the SEM model (raw score or standardized score), which can be raw or standardized depending on the estimation settings.</p></li>
</ul>
<p><strong>Weight and loading</strong>:</p>
<ul>
<li><p>(Indicator) weight. In PLS-SEM, the extent to which an indicator contributes to the latent variable score (as part of a weighted composite).</p></li>
<li><p>Standardized indicator weight. Indicator weight using standardized indicators.</p></li>
<li><p>Estimated indicator weight. In PLS-SEM, the estimated coefficient that multiplies an indicator to construct the latent variable score.</p></li>
<li><p>Factor loading. In CB-SEM, the strength of indicator–latent variable relationships.</p></li>
</ul>
<!-- - (Indicator) weight. The extent to which the indicator score contributes the latent variable score. -->
<!-- - Estimated (indicator) weight. (Indicator) weight after SEM model estimation. -->
<!-- - Standardized (indicator) weight. Estimated (indicator) weight that is standardized during the SEM model estimation.  -->
<p><strong>Latent variable</strong>:</p>
<ul>
<li>Latent variable. An unobserved construct linked to multiple indicators.</li>
</ul>
<!-- - Latent variable. A variable constructed by aggregating indicator scores.  -->
<ul>
<li><p>Latent variable score. The value of a latent variable, calculated as a linear combination (weighted sum) of indicator scores.</p></li>
<li><p>Standardized latent variable score. The value of a latent variable obtained by linear combination (weighted sum) of standardized indicator scores (z -score).</p></li>
<li><p>Unstandardized latent variable score. The value of a latent variable expressed in the scale of the original indicators (commonly raw original scores).</p></li>
<li><p>Normalized unstandardized latent variable score. Unstandardized latent variable score after normalization.</p></li>
</ul>
<p></font></p>
</div>
<p><br />
</p>
<!-- ???oud-start -->
<!-- A combined NCA-SEM study first conducts SEM in order to obtain the construct scores that are used as input in to NCA. In the SEM study a measurement model to construct the latent variables is specified from its measured indicators. The structural model is specified and justified while assuming a probabilistic sufficiency relationships between the latent variables.  -->
<!-- ### Step 1: Theorize probabilistic and necessity relationships. -->
<!-- After the model is specified, the probabilistic sufficiency hypotheses and necessity hypotheses are formulated and justified, the data collection and analysis can be done.  -->
<!-- The model in the example includes 9 relationships (the arrows in Figure \@ref(fig:tamfig)). The technology of interest is an e-book reader. Details of the model can be found in @richter2020predictors. By applying SEM, 9 probabilistic sufficiency hypotheses are tested. By applying NCA the same relationships are tested from the perspective of necessity, hence another 9 necessity hypotheses are tested (with NCA). All 18 hypotheses need to be formulated explicitly and be theoretically justified. This means that the theoretical model in a combined NCA-SEM study is by definition an 'embedded necessity theory', where necessity relationships and probabilistic relationships exist in one theory [@bokrantz2022building]. -->
<!-- #### Step 2: Conduct SEM -->
<!-- One of the outputs of the SEM model estimation is the latent variable scores based on measured indicator scores. By default, these scores are standardized (z-scores with a mean of 0 and a standard deviation of 1). Standardization makes path coefficients (regression coefficients) comparable, facilitating the interpretation of probabilistic sufficiency relationships. A notable feature of standardization is that it removes dependency on the scale, including the scale's minimum and maximum values. While this is advantageous for analyzing probabilistic relationships such as in regression analysis where variables are typically assumed to be unbounded, it poses challenges for interpreting NCA results.  -->
<!-- The following Section \@ref(rncaplssem) gives a demonstration of the above steps with the illustrative example using the software platform ```R```. For replication of the analyis the ```R``` code is provided. See Section \@ref(rsoftware)) for a quick-start guide on using ```R``` and the ```NCA``` package. -->
<!-- #### Step 3: Extract latent variable scores -->
<!-- In NCA, a fundamental assumption is that variables are bounded, and have meaningful levels. This is essential being able to calculate the effect size and for understanding necessity in degree using NCA's bottleneck table. The boundedness of variables is common, also in PLS-SEM (e.g., when the indicators are measured with Likert scales). This allows for a min-max normalization, for example 0-1 normalization or 0-100 normalization (e.g., percentages) to make all scales comparable. The 0-1 normalization in NCA results in a scope of 1, such that the ceiling zone (size of the empty space) equals the effect size. While normalization or another linear rescaling is possible but not essential for NCA, a normalization is required for applying PLS-SEM's Importance Performance Map Analysis (IPMA) when the indicators of predictor variables are measured with different scales (e.g., some predictor variables are measure with 1-5 scales, while other with 1-7 scales). Commonly, PLS-SEM uses 0-100 normalization for using IPMA or the integration of NCA in IPMA (combined Importance Performance Map Analysis; cIPMA). When normalization is applied, it is assumed that the variable are bounded, to get a comparable performance measure (0–100%)  for the latent variables.  -->
<!-- #### Step 4: Unstandardize latent variable scores -->
<!-- Before using the latent variable scores for applying NCA and cIPMA, the default standardized latent variables must be transformed into unstandardized latent variable scores.  -->
<!-- #### Step 5: Normalize latent variable scores -->
<!-- In addition normalization is required for cIPMA when not all predictor variables are obtained from indicators measured with the same scale. However, When the same scale was used, normalization is not needed. The latter applies to the 5 predictor variables of the illustrative example, where all indicators are measured with 1-5 Likert scale. Althougt the studies that use this example for applying IPMA and cIPMA conduct 0-100 normalization, when possible, non-normalization is prefered for meaningful interpretation of latent variable scores in terms of the values of the original Likert scales. This is demonstrated in Section \@ref(rncaplssem). -->
<!-- For applying NCA in combination with PLS-SEM the following steps are recommended: -->
<!-- 1. Obtain indicator data. -->
<!-- 2. Estimate the SEM model -->
<!-- 3. Obtain the unstandardized latent variable scores. -->
<!-- 4. Conduct NCA. -->
<!-- 5. Produce cIPMA. -->
<!-- 6. Conduct robustness checks. -->
<!-- ???oud-einde -->
<div id="theorize" class="section level4 hasAnchor" number="4.6.1.1">
<h4><span class="header-section-number">4.6.1.1</span> Step 1: Theorize probabilistic and necessity relationships<a href="dataanalysis.html#theorize" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The first step is a fundamental step for any combined NCA and SEM study. An NCA-SEM study implies that the relationships between the variables are considered from two different causal perspectives: probabilistic sufficiency (SEM) and necessity (NCA). Both SEM and NCA require that the study starts with formulating theoretical expectations about the relationship (e.g., hypotheses). According to SEM, all relationships between latent variables in the structural model are considered probabilistic sufficiency relationships. According to NCA all, a few, or none of the relationships can be hypothesized as necessity relationships as well. Each necessity relationship between latent variables should be theoretically justified (see Section <a href="theory.html#formulationnecessity">2.2</a>). The theoretical justification of applying these different causal lenses to the structural model is essential <span class="citation">(<a href="#ref-dul2024different">Dul, 2024a</a>)</span>. A theory that includes one or more necessity relationships in addition to probabilistic sufficiency relationships is called an ‘embedded necessity theory’ <span class="citation">(<a href="#ref-bokrantz2022building">Bokrantz &amp; Dul, 2023</a>)</span>. The latent variables of a structural model can have two different roles. A ‘predictor’ variable (independent variable; ‘condition’ in NCA) explains or predicts a ‘predicted’ variable (dependent variable; outcome in NCA). For example, when in a structural model a latent variable <span class="math inline">\(M\)</span> mediates the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, then <span class="math inline">\(M\)</span> has two different roles. For the <span class="math inline">\(X\)</span>-<span class="math inline">\(M\)</span> relationship <span class="math inline">\(X\)</span> is the predictor and <span class="math inline">\(M\)</span> is the predicted variable, and for the <span class="math inline">\(M\)</span>-<span class="math inline">\(Y\)</span> relationship <span class="math inline">\(M\)</span> is the predictor and <span class="math inline">\(Y\)</span> the predicted variable. When a relationship is (also) considered a necessity relationship, NCA calls the predictor variable the ‘condition’ and the predicted variable the ‘outcome’.</p>
</div>
<div id="step-2-conduct-sem" class="section level4 hasAnchor" number="4.6.1.2">
<h4><span class="header-section-number">4.6.1.2</span> Step 2: Conduct SEM<a href="dataanalysis.html#step-2-conduct-sem" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<!-- Conducting SEM assumes that data are available about indicators for aggregation to latent variables. SEM entails the formulation of a measurement model that establishes the relationship between indicator variables and latent variables, and a structural model that establishes the relationships between the latent variables. This is followed by estimating the entire model with a selected algorithm (e.g., PLS or CB). NCA is not part of this process, but instead uses the results from the SEM analysis (the latent variable scores) as input for its own procedures. NCA therefore assumes that the analyst ensures that latent variable scores extracted from the SEM model are valid, reliable and meaningful. Recommendations for applying SEM are available in the literature and are not discussed here. Commercial and open-source software packages are available for conducting SEM.   -->
<p>Conducting SEM assumes that data are available on observed indicators that are used to represent latent variables. SEM involves specifying a measurement model, which defines the relationships between indicators and latent variables, and a structural model, which specifies the relationships between latent variables. The complete model is then estimated using a chosen algorithm (e.g., PLS-SEM or CB-SEM). NCA is not part of the SEM estimation process itself, but it uses latent variable scores obtained from SEM as input for its own analysis. Therefore, it is important that the analyst ensures that the latent variable scores extracted from the SEM model are valid, reliable, and interpretable. Recommendations for good SEM practices are available in the literature and are not discussed here. Both commercial and open-source software tools are available to conduct SEM.</p>
</div>
<div id="step-3-extract-latent-variable-scores" class="section level4 hasAnchor" number="4.6.1.3">
<h4><span class="header-section-number">4.6.1.3</span> Step 3: Extract latent variable scores<a href="dataanalysis.html#step-3-extract-latent-variable-scores" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<!-- The latent variables from the SEM model are the input for NCA. During the SEM estimation, commonly the latent variable scores are standardized (z-scores) having a mean of 0 and a standard deviation of 1. Although NCA results are independent of affine (e.g., linear) transformations, for interpretation of results it is recommended that the standardized scores are first unstandardized and then (possibly) normalized. Unstandardized latent variable scores (step 3a, if needed) are directly related to the scale that was used for measuring the indicators of the latent variable (assuming that the same scale was used for all indicators of the latent variable). This allows a meaningful interpretation of the results. Some software packages do not have the possibility to extract the unstandardized latent variable scores. Below an example is give how to obtain unstandardized scores from standardized scores.  -->
<p>The latent variable scores obtained from the SEM model serve as input for NCA. During SEM estimation, latent variable scores are often standardized (z-scores), resulting in scores with a mean of 0 and standard deviation of 1. Although NCA results are invariant to affine transformations (such as standardization or linear rescaling), it is recommended for purposes of interpretation to first unstandardize the latent variable scores, and then, if desired, apply normalization (e.g., min-max scaling). Unstandardized latent variable scores (see Step 3a, if needed) are expressed on a scale that is directly related to the original indicator scale, provided that the same measurement scale was used for all indicators of the latent construct. This allows for more meaningful interpretation of the NCA results, especially when discussing real-world implications and when results are discussed in terms of necessity ‘in degree’ with specified levels of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Note that not all SEM software packages offer the option to extract unstandardized latent variable scores, particularly in CB-SEM, where latent scores are not estimated by default. Below is an example showing how to convert standardized scores back to unstandardized scores when needed.
<!-- When all unstandardized latent variable scores are based on the same indicator scale (with the same minimum and maximum scale values) normalization is not required. Otherwise min-max normalization is needed (Step 3b) such that latent variable scores are comparable (for example in step 5:  produce BIPMA). A common way of min-max normalization is using 0 and 100 as new minimum and maximum values such that the latent variable scores can be interpreted as percentage of the range. Alternatively a 0-1 normalization can be done, which is a convenient but not essential option for NCA as it results in a scope of 1. -->
When all unstandardized latent variable scores are derived from indicators measured on the same scale (i.e., with identical minimum and maximum values), normalization is not required. However, if latent variables have different scales, min-max normalization is recommended (see Step 3b). This ensures that the latent variable scores are comparable, which is particularly important in later steps (e.g., Step 5: producing a BIPMA).</p>
<p>A common approach to min-max normalization is to rescale scores to a 0–100 range, allowing latent variable scores to be interpreted as percentages of their original scale range. Alternatively, rescaling to a 0–1 range can be used, which is often more convenient for NCA, as it yields a scope of 1. However, this is optional and not required for the validity of NCA results.</p>
</div>
<div id="step-4-conduct-nca" class="section level4 hasAnchor" number="4.6.1.4">
<h4><span class="header-section-number">4.6.1.4</span> Step 4: Conduct NCA<a href="dataanalysis.html#step-4-conduct-nca" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The unstandardized and possibly normalized latent variable scores are input to NCA. In the first part of the analysis the hypothesized relationships are tested for ‘necessity in kind’, which is the qualitative statement that <span class="math inline">\(X\)</span> is necessary for <span class="math inline">\(Y\)</span> without specifying levels of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> other than absence/presence or low/high. The observed effect size <span class="math inline">\(d\)</span> and p value are compared with their threshold values (e.g., <span class="math inline">\(d\)</span> = 0.10; p = 0.05) that are set by the researcher to decide if a predictor variable is necessary for a predicted variable, as suggested by the hypothesis.</p>
<p>In the second part, identified necessary conditions are selected for a the bottleneck analysis for ‘necessity in degree’, which is a quantitative statement that level <span class="math inline">\(x_c\)</span> of <span class="math inline">\(X\)</span> is necessary for level <span class="math inline">\(y_c\)</span> of <span class="math inline">\(Y\)</span>. A specific format of this table, with the outcome values expressed as actual values or percentiles, and the conditions expressed as percentiles, provides information for each latent variable about the percentage of cases that are bottlenecks. A bottleneck case is a case that is unable to achieve the required level of the condition for a target level of the outcome. The case is a bottleneck case if it is not possible to achieve the target outcome with the observed value of the condition.</p>
</div>
<div id="producebipma" class="section level4 hasAnchor" number="4.6.1.5">
<h4><span class="header-section-number">4.6.1.5</span> Step 5: Produce BIPMA<a href="dataanalysis.html#producebipma" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The Bottleneck Importance Performance Map Analysis (BIPMA) is an adapted version of the combined Importance Performance Map Analysis (CIPMA) as proposed by <span class="citation">(<a href="#ref-hauff2024importance">Hauff et al., 2024</a>)</span>. CIPMA is a combination of the classic IPMA and NCA.</p>
<p>The goal of IPMA, CIPMA and BIPMA is to assist researchers and practitioners prioritize their actions and resources in terms of selection of the predictor variable that has the largest effect on the predicted variable. An action based on SEM results means that the selected predictor is changed to change the average value of the predicted variable. For a SEM evidence based action on a predictor, it must be assumed that all other predictors are not changing (<em>ceteris paribus</em>). This implies that from IPMA, CIPMA and BIPMA only one predictor can be selected for an action based on SEM. Selection of multiple predictors and taking action on them simultaneously violates the <em>ceteris paribus</em> requirement. Sequential selection of multiple predictors requires that after a change of one predictor, a new SEM analysis must be made that represents the changed situation. Therefore, IPMA, CIPMA and BIPMA are static approaches that can only identify one predictor for evidence-based action based on SEM results. When the action is only based on NCA results, multiple conditions can be addressed as the <em>ceteris paribus</em> assumption does not apply to NCA.</p>
<p>IPMA only uses the SEM results to prioratize actions. It combines two dimensions:</p>
<ul>
<li><p>Importance: The total effects (direct and indirect path coefficients) of a predictor variable on the predicted variable. It represents the strengths of the probabilistic sufficiency (average effect) relation.</p></li>
<li><p>Performance: The average score of a normalized unstandardized predictor variable. It represents how well the predictor variable performs regarding the average (positive) contribution to the predicted variable (the mean score of the predictor).</p></li>
</ul>
<p>Therefore, the practical meaning of IPMA is that action priority should be given to a predictor variable with:</p>
<ol style="list-style-type: decimal">
<li>High level of Importance, and low level of Performance (points in the lower right corner assuming that Importance is represented by the absolute values of the total effects to handle negative total effects).</li>
</ol>
<p>CIPMA <span class="citation">(<a href="#ref-hauff2024importance">Hauff et al., 2024</a>)</span> adds a third dimension to the classic IPMA, which I call here the ‘bottleneck’ dimension. This dimension takes into account how effective the action is from the perspective of presence of bottleneck cases according to NCA. While IPMA focuses on prioritization aimed at increasing the average effect across a group of cases, such approach may be less effective when bottlenecks are present. The bottleneck dimension introduces a complementary priority judgement. It prioritizes actions based on the goal that as many cases as possible are able to achieve a specified target level of the predicted variable. This means that for CIPMA a ‘target outcome’ must be selected. This is a specific level of the predicted variable that after action must become achievable by as many as possible cases. If the target outcome is set at a low level, the goal is to enable a base level of the outcome (e.g., mean or even lower outcome, for example corresponding to a minimum level that is achieved by 50 or 75 percent of the cases). If the target outcome is set at a high level, the goal is to enable high level of the outcome (e.g., corresponding to a minimum level that is only achieved by about 25 or 10 percent of the cases).</p>
<p>NCA estimates the minimum required score of a predictor variable that is needed for being able to achieve the target level of the predicted variable. The bottlenecks dimension in CIPMA is the <em>number or percentage of bottleneck cases</em> of the predictor variables. For a given predictor variable, bottleneck cases are cases where the predictor variable score is lower than the minimum required score to make the target outcome level achievable. This information can be obtained from NCA’s bottleneck table produced in step 4b. The CIPMA plot integrates three dimensions: Importance on the horizontal axis, Performance on the vertical axis, and Bottlenecks represented by the size of the points in the Importance-Performance plot. Each point represents a predictor variable with a given combination of Importance and Performance score. The bottlenecks dimension is represented by the size of the points.</p>
<p>When prioritization is based on the results from NCA and SEM, the <em>ceteris paribus</em> assumption of SEM applies such that only one predictor variable can be selected for change, if this change is (also) based on SEM results. CIPMA suggests that the best choice is the predictor with the largest Importance score and lowest Performance score (according to SEM), and the largest number of bottleneck cases (according to NCA). Specifically, <span class="citation">Hauff et al. (<a href="#ref-hauff2024importance">2024</a>)</span> suggest that priority action based on SEM results should focus predictors located in the lower-right quadrant of the CIPMA plot -implicitly assuming that the total effects are positive-, while priority action based on NCA can focus on any of the quadrants.</p>
<p>Therefore, the practical meaning of CIPMA is that action priority should be given to the predictor variable with:</p>
<ol style="list-style-type: decimal">
<li>High level of Importance, and low level of Performance (points in the lower right corner).</li>
<li>High number or percentage of bottleneck cases (large points) for the significant necessary conditions.</li>
</ol>
<p>Note that in IPMA and CIPMA all predictor variables that are hypothesized in the SEM model are usually shown in the plots, even if the total effect is statistically non-significant<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>. In contrast, a non-significant necessary condition is not included in CIPMA. Such condition has the standard point size illustrating that the predictor should not get priority from the perspective of necessity.</p>
<p>I introduce the ‘Bottlenecks, Importance, Performance Map Analysis’ (BIPMA) as an adaptation and replacement of CIPMA: BIPMA adapts the cIPMA in three ways: for the bottleneck dimension it considers only <em>single</em> bottleneck cases, it excludes also non-significant SEM results, and it handles <em>negative</em> total effects by explicitly using the absolute value of SEM’s total effect, and negative ‘directions’ of necessity by specifying and analysing the expected empty corner in the <span class="math inline">\(XY\)</span> plot which may be different than the upper-left corner.</p>
<p>The bottlenecks dimension in BIPMA differs from the bottlenecks dimension in CIPMA. Rather than prioritizing the predictor with the largest number or percentage of bottleneck cases, it prioritizes the predictor with the largest number or percentage of <em>single</em> bottleneck cases. Single bottleneck cases are cases that are a bottleneck in only one predictor, and not in multiple predictors. An action on a single predictor is only effective if the bottleneck case is not a bottleneck for other predictors. Normally, a substantial part of the bottleneck cases for a given predictor are also bottlenecks for another predictor. This means that an action on the selected predictor to resolve a bottleneck case, will only be effective for the single bottlenecks cases of this predictor. Therefore, BIPMA uses the number or percentage of single bottleneck cases for a given predictor variable as the bottlenecks dimension of IPMA. When single bottleneck cases are resolved, these cases have the possibility to achieve the target outcome. When multiple bottleneck cases are resolved for a given predictor, these cases remain a bottleneck case for another condition, such that the goal of making the target outcome possible is not achieved for these cases.</p>
<p>A second adaptation compared to CIPMA (and IPMA) is that BIPMA only considers predictor variables for practical action that have a statistically significant total effect on the predicted variable. The reason is threefold. First, only a change of the value of a significant predictor variable will result in a change of the value of the predicted variable; a non-significant total effect suggests that the observed effect is compatible with no effect (Importance = 0). Since, IPMA, CIPMA and BIPMA are all tools for evidence-based practical action, the non-significance of an empirical finding should be taken into account. Second, since CIPMA does not include non-significant necessary conditions<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>, it is logical for compatibility that the requirement of statistical significance also applies to the total effect. Third, <span class="citation">Richter, Schubring, et al. (<a href="#ref-richter2020predictors">2020</a>)</span> and <span class="citation">Richter, Hauff, Ringle, et al. (<a href="#ref-richter2023apply">2023</a>)</span> distinguish different scenarios for practical action depending on the (non-)significance of both the NCA results and the SEM results. The BIPMA plot aims to inform practice as closely as possible in line with the empirical results. Therefore BIPMA diplays the four possible combinations of statistical (non-)significance of SEM and NCA results using different point colors in the Importance-Performance-plot:</p>
<ul>
<li><p>White point: the total effect and the necessity effect are both significant. The size of the point reflects the bottleneck dimension.</p></li>
<li><p>Black point: the total effect is significant and the necessity effect is non-significant. The black point has a standard size.</p></li>
<li><p>Grey point: the total effect is non-significant and the necessity effect is significant. Since the total effect is compatible with no effect, the point is moved on the horizontal axis to Importance = 0. The size of the point reflects the bottleneck dimension.</p></li>
<li><p>No point: the total effect is non-significant and the necessity effect is non-significant. The point is removed from the plot as it does not provide information for practical action.</p></li>
</ul>
<p>A final adaptation is that BIPMA also handles different relationship directions between predictor variable and predicted variable. The common situation in SEM is that the predictor variable has a positive (average) effect on the predicted variable, and in NCA is that a high level of the predictor variable is necessary for a high level of the predicted variable. BIPMA also handles predictor variables with hypothesized and observed negative total average effect on the predicted variable. For example, <span class="citation">Mwesiumo (<a href="#ref-mwesiumo2025identifying">in press</a>)</span> added a negative total effect for one of the predictor variable on the negative side of CIPMA’s Importance-axis. Since this is inconsistent with the advice <span class="citation">(<a href="#ref-hauff2024importance">Hauff et al., 2024</a>)</span> that priority should be to points in the lower-right corner of CIPMA, BIPMA explicitly uses the <em>absolute</em> total effect as Importance score, such that importance scores of positive total effects and negative total effect are comparable and priority should be given to points in the lower right corner independent of the sign of the total effect. The BIPMA plot identifies an Importance score that is based on a negative total effect by adding ‘-inv’ to the name of the predictor, indicating that this predictor has an inverse effect on the predicted variable. While an <em>increase</em> of the predictor variable with a positive total effect will increase the predicted variable, a <em>decrease</em> of the predictor variable with a negative total effect will increase the predicted variable. BIPMA also handles different necessity ‘directions’. For NCA the default necessity ‘direction’ is high-high, meaning that a high level of <span class="math inline">\(X\)</span> is necessary for a high level of <span class="math inline">\(Y\)</span>. The other ‘directions’ are low-high, high-low, or low-low, suggesting that low <span class="math inline">\(X\)</span> is necessary for high <span class="math inline">\(Y\)</span>, high <span class="math inline">\(X\)</span> is necessary for low <span class="math inline">\(Y\)</span>, or low <span class="math inline">\(X\)</span> is necessary for low <span class="math inline">\(Y\)</span>, respectively. This implies that the expected empty corner of the <span class="math inline">\(XY\)</span> plot is not upper-left, but that another corner of the <span class="math inline">\(XY\)</span> plot is expected to be empty and should be analysed. For example, an expected and observed empty corner is the upper-right corner (low <span class="math inline">\(X\)</span> is necessary for high <span class="math inline">\(Y\)</span>) implies that for resolving bottleneck cases the predicted variable must decrease, rather than increase.</p>
<p>While taking these adaptations into account, the practical meaning of BIPMA is that action priority should be given to predictor variables with:</p>
<ol style="list-style-type: decimal">
<li>A statistically significant and high level of Importance (absolute total effect) and low level of Performance (points in the lower right corner of the Importance-Performance plot).</li>
<li>High number or percentage of <em>single</em> bottleneck cases for significant necessary conditions (large points).</li>
</ol>
<p>One of the goals of BIPMA is to identify predictor variables that should be prioritized for action using these two criteria. Several prioritization approaches and corresponding ways to evaluate the BIPMA plot can be used to combine these criteria. Assuming a positive direction for the average effect and a high-high direction for the necessity effect these strategies can be formulated as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Enable a target outcome. This approach only considers NCA results. It is feasible when SEM results do not give a clear preference for predictors to be changed (e.g., no non-significant points in the bottom-right corner of BIPMA). Since the <em>ceteris paribus</em> assumption does not limit NCA, multiple predictor variables can be selected for an action. This approach implies that the goal of the intervention is to unlock high target score by ensuring that the conditions have no bottleneck cases. For example, if the target outcome is something desirable and <span class="math inline">\(X\)</span> is necessary for high <span class="math inline">\(Y\)</span>, the target can be set at a high level that is achieved by not more than 25% or 10% percent of the cases (the best performing cases). The intervention then consists of ensuring that most bottleneck cases are resolved by increasing the values of the conditions with bottleneck cases. The approach is also feasible when the goal is to enable a certain minimum level of the outcome for all cases. The target outcome can for example be set at a minimum level that is achieved by more than 50% or 75% of the cases.</p></li>
<li><p>Improve the average outcome. This approach only considers the SEM results. It is feasible when NCA results show that none of the conditions are necessary or have only a small number of bottleneck cases (e.g., less than 10%). Only one predictor variable can be selected for action at once given the <em>ceteris paribus</em> requirement. For selecting a second predictor, evidence-based action requires a new SEM and BIPMA with a new dataset representing the situation after the intervention on the first predictor.</p></li>
<li><p>Improve the average outcome and enable a target outcome. This approach considers both the SEM and NCA results. Since SEM is part of the consideration, this approach requires that only one predictor is selected for evidence based action, the combined approach is most effective if the predictor with the large number of bottleneck cases (e.g., more than 10%) is in the lower right corner of the BIPMA plot.</p></li>
</ol>
<p>Since these idealized situations may not exist in practice, hybrid approaches may be considered.</p>
<!-- In BIPMA, I assume that, according to the SEM model, there is a positive average relationship between all predictor variables and the predicted variable: higher values of the predictor results in higher values of the predicted variable (on average). Similarly, I assume that, according to the NCA model, there is a high-high necessity relationship between the condition and the outcome: a high level of the condition enables a high level of the outcome. If for particular variable a negative average relationship, or a low-high, or a high-low necessity relationship is expected, the variable can be inverted to ensure all relationships are aligned as positive and high-high, -->
</div>
<div id="semrobustnesschecks" class="section level4 hasAnchor" number="4.6.1.6">
<h4><span class="header-section-number">4.6.1.6</span> Step 6: Conduct robustness checks<a href="dataanalysis.html#semrobustnesschecks" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The goal of robustness checks is to explore the sensitivity of choices made by the researcher on key results of NCA. In the context of an NCA-SEM study the following key results may be affected by researchers’ choices:</p>
<ul>
<li><p>Identification of necessary conditions based on effect size and p value.</p></li>
<li><p>Prioritization of predictors for intervention.</p></li>
</ul>
<p>As discussed in Section <a href="dataanalysis.html#robustnesschecks">4.4</a>, these key results are affected by researcher’s choices of:</p>
<ul>
<li><p>Ceiling line.</p></li>
<li><p>Threshold level of the effect size.</p></li>
<li><p>Threshold level of the p value.</p></li>
<li><p>Scope.</p></li>
<li><p>Outlier removal.</p></li>
<li><p>Target outcome.</p></li>
</ul>
<p>A robustness check consists of making another (reasonable) choice than the original choice, and studying its influence on the key results. The output of the the robustness check is the NCA robustness table. If the influence of changes of the researcher’ choices is small, the original results may be considered as robust; if, not the original results may be fragile.</p>
</div>
</div>
<div id="examplencaplssem" class="section level3 hasAnchor" number="4.6.2">
<h3><span class="header-section-number">4.6.2</span> Demonstration of combining NCA and PLS-SEM with R<a href="dataanalysis.html#examplencaplssem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this section the steps for combining NCA with PLS-SEM as shown above are demonstrated with an example. The selected example is used in four published studies where NCA is combined with PLS-SEM <span class="citation">(<a href="#ref-hauff2024importance">Hauff et al., 2024</a>; <a href="#ref-richter2020predictors">Richter, Schubring, et al., 2020</a>; <a href="#ref-richter2023apply">Richter, Hauff, Ringle, et al., 2023</a>; <a href="#ref-sarstedt2024combined">Sarstedt et al., 2024</a>)</span>. The goal of the demonstration is threefold.</p>
<ul>
<li><p>Replication of the four studies by using a different software package for PLS-SEM than the SmartPLS package that was used in the original studies. In contrast to R and its packages, the SmartPLS software is not free and includes only a basic version of NCA. However, it is more user-friendly for users who are not familiar with <code>R</code>. A quick start guideline for using NCA with <code>R</code> can be found <a href="https://www.erim.eur.nl/fileadmin/user_upload/_generated_/download/Quick_Start_Guide_NCA_4.0.0_February_2024.pdf">here</a>.</p></li>
<li><p>Show the proposed extension of CIPMA by using BIPMA for prioratizing action.</p></li>
<li><p>Show how the robustness checks can be conducted.</p></li>
</ul>
<p>The selected example evaluates an extended version of the Technology Acceptance Model (TAM) <span class="citation">(<a href="#ref-richter2020predictors">Richter, Schubring, et al., 2020</a>)</span>. Figure <a href="dataanalysis.html#fig:tamfig">4.17</a> shows the model consisting of six variables (rectangles) and 9 relationships (arrows).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tamfig"></span>
<img src="FigTAM.png" alt="The extended Technology Acceptance Model (TAM) according to @richter2020predictors." width="100%" />
<p class="caption">
Figure 4.17: The extended Technology Acceptance Model (TAM) according to <span class="citation">Richter, Schubring, et al. (<a href="#ref-richter2020predictors">2020</a>)</span>.
</p>
</div>
<p>For the demonstration, the flowchart of Figure <a href="dataanalysis.html#fig:semflowchart">4.16</a> is followed and the <code>R</code> packages <code>SEMinR</code> for conducting PLS-SEM and <code>NCA</code> for conducting NCA are used. Additional <code>R</code> code for conducting the analysis can be found in Section <a href="miscellaneous.html#additionalcode">7.4</a>.</p>
<div id="example-step-1-theorize-probabilistic-and-necessity-relationships" class="section level4 hasAnchor" number="4.6.2.1">
<h4><span class="header-section-number">4.6.2.1</span> Example Step 1: Theorize probabilistic and necessity relationships<a href="dataanalysis.html#example-step-1-theorize-probabilistic-and-necessity-relationships" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>It is assumed that the relationships shown in Figure <a href="dataanalysis.html#fig:tamfig">4.17</a> are theoretically justified from both the perspective of probabilistic sufficiency as well as from the perspective of necessity <span class="citation">(see <a href="#ref-richter2020predictors">Richter, Schubring, et al., 2020</a>)</span>. For enhancing a theoretical justification of a necessity relationship see Section <a href="theory.html#justificationnecessity">2.3</a>.</p>
</div>
<div id="example-step-2-conduct-sem" class="section level4 hasAnchor" number="4.6.2.2">
<h4><span class="header-section-number">4.6.2.2</span> Example Step 2: Conduct SEM<a href="dataanalysis.html#example-step-2-conduct-sem" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Following the four original studies that also use the example, the PLS_SEM approach is selected to estimate the SEM model. The dataset is provided by <span class="citation">(<a href="#ref-schubring2023extended">Schubring &amp; Richter, 2023</a>)</span> at <a href="https://data.mendeley.com/datasets/pd5dp3phx2/4">Mendeley Data</a>, and it is explained in <span class="citation">Richter, Hauff, Kolev, et al. (<a href="#ref-richter2023dataset">2023</a>)</span>. The helper function <code>get_indicator_data_TAM</code> imports the dataset, selects relevant columns, and changes the column names for use in <code>SEMinR</code>. The <code>R</code> code of the helper function can be found in Section <a href="miscellaneous.html#getindicatordata">7.4.4</a>.</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="dataanalysis.html#cb66-1" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;get_indicator_data_TAM.R&quot;</span>)</span>
<span id="cb66-2"><a href="dataanalysis.html#cb66-2" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">get_indicator_data_TAM</span>()</span>
<span id="cb66-3"><a href="dataanalysis.html#cb66-3" tabindex="-1"></a><span class="fu">head</span>(df, <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##   PU1 PU2 PU3 CO1 CO2 CO3 EOU1 EOU2 EOU3 EMV1 EMV2 EMV3 AD1 AD2 AD3 USE
## 1   4   3   3   3   3   3    5    5    4    4    3    3   2   2   2   2
## 2   3   1   4   3   3   4    4    4    2    4    4    3   5   4   4   3
## 3   4   4   4   3   3   4    4    4    4    4    4    4   4   4   4   3</code></pre>
<p>The original data consists of 174 rows (cases = people using e-readers) and 20 columns. The first 16 columns represent the raw indicators of the 6 variables of the TAM model. The last four columns are not considered in this demonstration and removed from the dataset. After running the helper function, the resulting dataset <code>df</code> is used as input for the SEM model. The raw indicator scores are measured with 5-point-Likert scales, except for the score for Technology use, which is measured with a 7-point-Likert scale. The variable names are PU = Perceived usefulness, CO = Compatibility, EOU = Perceived ease of use, EMV = Emotional value, AD = Adoption intention, and USE = Technology use.</p>
<p>The measurement model (using the indicator scores) and the structural model (Figure <a href="dataanalysis.html#fig:tamfig">4.17</a>) are specified and estimated with the PLS algorithm. The <code>SEMinR</code> package standardizes the raw scores and produces latent construct scores (mean = 0, sd = 1) and path coefficients and other output. The helper function <code>estimate_sem_model</code> conducts the PLS-SEM model estimation. The <code>R</code> code of the helper function be found in Section <a href="miscellaneous.html#estimatesemmodel">7.4.5</a>.</p>
<p>The summary of the results shows the standardized path coefficients and some metrics about model fit.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="dataanalysis.html#cb68-1" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;estimate_sem_model_TAM.R&quot;</span>)</span>
<span id="cb68-2"><a href="dataanalysis.html#cb68-2" tabindex="-1"></a>TAM_pls <span class="ot">&lt;-</span> <span class="fu">estimate_sem_model_TAM</span>(df)</span>
<span id="cb68-3"><a href="dataanalysis.html#cb68-3" tabindex="-1"></a><span class="fu">summary</span>(TAM_pls)</span></code></pre></div>
<pre><code>## 
## Results from  package seminr (2.3.7)
## 
## Path Coefficients:
##                       Adoption intention Technology use
## R^2                                0.539          0.420
## AdjR^2                             0.528          0.403
## Perceived usefulness               0.227          0.050
## Compatibility                      0.045          0.107
## Perceived ease of use              0.088          0.010
## Emotional value                    0.515          0.137
## Adoption intention                     .          0.437
## 
## Reliability:
##                       alpha  rhoC   AVE  rhoA
## Perceived usefulness  0.723 0.842 0.642 0.753
## Compatibility         0.858 0.914 0.779 0.859
## Perceived ease of use 0.783 0.873 0.697 0.783
## Emotional value       0.914 0.946 0.853 0.917
## Adoption intention    0.938 0.960 0.889 0.939
## Technology use        1.000 1.000 1.000 1.000
## 
## Alpha, rhoC, and rhoA should exceed 0.7 while AVE should exceed 0.5</code></pre>
<p>The results correspond to those reported in the four original publications that use the same example with the SmartPLS software.</p>
<p>In addition, the 95% confidence interval of the path coefficients can be obtained using bootstrapping. A path is significant if its 95% bootstrap confidence interval does not include zero. The helper function <code>get_significance_sem.R</code> can be used to find significant direct effects, indirect effects and total effects as follows. The <code>R</code> code of the helper function be found in Section <a href="miscellaneous.html#significancesem">7.4.6</a>.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="dataanalysis.html#cb70-1" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;get_significance_sem.R&quot;</span>)</span>
<span id="cb70-2"><a href="dataanalysis.html#cb70-2" tabindex="-1"></a>TAM_sig <span class="ot">&lt;-</span> <span class="fu">get_significance_sem</span> (<span class="at">sem =</span> TAM_pls, <span class="at">nboot =</span> <span class="dv">5000</span>) <span class="co">#5000 for final analysis</span></span>
<span id="cb70-3"><a href="dataanalysis.html#cb70-3" tabindex="-1"></a>TAM_sig</span></code></pre></div>
<pre><code>##                                            Path Direct Indirect Total
## 8  Perceived usefulness  -&gt;  Adoption intention  0.227    0.000 0.227
## 9      Perceived usefulness  -&gt;  Technology use  0.050    0.099 0.149
## 2         Compatibility  -&gt;  Adoption intention  0.045    0.000 0.045
## 3             Compatibility  -&gt;  Technology use  0.107    0.020 0.127
## 6 Perceived ease of use  -&gt;  Adoption intention  0.088    0.000 0.088
## 7     Perceived ease of use  -&gt;  Technology use  0.010    0.038 0.049
## 4       Emotional value  -&gt;  Adoption intention  0.515    0.000 0.515
## 5           Emotional value  -&gt;  Technology use  0.137    0.225 0.362
## 1        Adoption intention  -&gt;  Technology use  0.437    0.000 0.437
##   Sig_Direct Sig_Indirect Sig_Total          Predicted
## 8       TRUE        FALSE      TRUE Adoption intention
## 9      FALSE        FALSE     FALSE     Technology use
## 2      FALSE        FALSE     FALSE Adoption intention
## 3      FALSE        FALSE     FALSE     Technology use
## 6      FALSE        FALSE     FALSE Adoption intention
## 7      FALSE        FALSE     FALSE     Technology use
## 4       TRUE        FALSE      TRUE Adoption intention
## 5      FALSE         TRUE      TRUE     Technology use
## 1       TRUE        FALSE      TRUE     Technology use</code></pre>
<p>For the <em>direct</em> paths, three out of nine paths are significant: Perceived usefulness -&gt; Adoption intention (direct effect: 0.227), Emotional value -&gt; Adoption intention (direct effect: 0.515) and Adoption intention -&gt; Technology use (direct effect: 0.437).
For the <em>indirect</em> paths two out of four paths are significant: Perceived usefulness -&gt; Adoption intention -&gt; Technology use (indirect effect: 0.099) and Emotional value -&gt; Adoption intention -&gt; Technology use (indirect effect: 0.225). The combined direct and indirect paths (total effect) is significant. The total effect of the path Emotional value -&gt; Technology use combined with the path Emotional value -&gt; Adoption intentions -&gt; Technology use is 0.362.</p>
<p>These results suggest that for increasing Technology use on average, only Emotional value and Adoption intention are effective. Perceived usefulness, Compatibility and Perceived ease of use are not candidates for intervention based on the SEM results as they do not have a signigicant total effect on Technology use.</p>
</div>
<div id="example-step-3-extract-latent-variable-scores" class="section level4 hasAnchor" number="4.6.2.3">
<h4><span class="header-section-number">4.6.2.3</span> Example Step 3: Extract latent variable scores<a href="dataanalysis.html#example-step-3-extract-latent-variable-scores" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>By default, PLS-SEM model estimation produces standardized latent variable scores and this is the only option in <code>SEMinR</code> (version 2.3.4). However, unstandardized scores are preferred as input for NCA, and normalized unstandardized scores are needed for IPMA, CIPMA and BIPMA. The helper function <code>unstandardize</code> calculates the unstandardized latent variable scores from the standardized latent variable scores using procedures described in <span class="citation">(<a href="#ref-ringle2016gain">Ringle &amp; Sarstedt, 2016</a>)</span>, such that the scale of the latent variable scores correspond to the scale of the original indicator scores. The <code>R</code> code of the helper function can be found in Section <a href="miscellaneous.html#unstandardize">7.4.7</a>.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="dataanalysis.html#cb72-1" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;unstandardize.R&quot;</span>)</span>
<span id="cb72-2"><a href="dataanalysis.html#cb72-2" tabindex="-1"></a>dataset <span class="ot">&lt;-</span> <span class="fu">unstandardize</span>(TAM_pls)</span>
<span id="cb72-3"><a href="dataanalysis.html#cb72-3" tabindex="-1"></a><span class="fu">head</span>(dataset, <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##   Perceived usefulness Compatibility Perceived ease of use Emotional value
## 1             3.276582      3.000000              4.676176        3.322971
## 2             2.668901      3.336436              3.352351        3.663039
## 3             4.000000      3.336436              4.000000        4.000000
##   Adoption intention Technology use
## 1           2.000000              2
## 2           4.329378              3
## 3           4.000000              3</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="dataanalysis.html#cb74-1" tabindex="-1"></a><span class="fu">data.frame</span> (<span class="at">Mean =</span> <span class="fu">colMeans</span>(dataset),</span>
<span id="cb74-2"><a href="dataanalysis.html#cb74-2" tabindex="-1"></a>            <span class="at">Min =</span> <span class="fu">apply</span>(dataset, <span class="dv">2</span>, min),</span>
<span id="cb74-3"><a href="dataanalysis.html#cb74-3" tabindex="-1"></a>            <span class="at">Max =</span> <span class="fu">apply</span>(dataset, <span class="dv">2</span>, max)</span>
<span id="cb74-4"><a href="dataanalysis.html#cb74-4" tabindex="-1"></a>            )</span></code></pre></div>
<pre><code>##                           Mean      Min Max
## Perceived usefulness  3.569914 1.000000   5
## Compatibility         3.462276 1.000000   5
## Perceived ease of use 4.025616 1.674851   5
## Emotional value       3.806854 1.000000   5
## Adoption intention    3.881627 1.000000   5
## Technology use        3.982759 1.000000   7</code></pre>
<p>The resulting dataset with unstandardized latent variable scores is called <code>dataset</code>. The variables are now interpretable according to the Likert scales that were used to measure its raw indicators. The results show that minimum and maximum latent variable <em>scores</em> correspond to the minimum and maximum values of the Likert <em>scale values</em>. There is one exception: the minimum observed latent variable score for Perceived ease of use is 1.67 whereas the minimum value of the scale is 1. Apparently, none of the 174 cases (persons) scored a value 1 on all three indicators of this latent variable.</p>
<p>The unstandardized latent variable scores can be normalized to obtain normalized unstandardized latent variable scores. Normalization is essential if the predictor variables do not have the same scale values (e.g., one predictor variable is measured with a 1-5-Likert scale while another predictor variable is measured with a 1-7-Likert scale). If the same scale is used for all predictor variables, it is preferred not to normalize the scales and to keep the unstandardized latent variables scores, such that the results are interpretable according to the Likert scale values.</p>
<p>Data can be min-max normalized using the helper function <code>normalize</code>. The input arguments for this function are the data, the theoretical minimum and maximum values of the scale (the observed minimum or maximum values might be different), and the range of the new scale (e.g., 0-1 or 0-100). For example, (c)IPMA commonly uses a 0-100 normalization of the unstandardized latent variable scores. The <code>R</code> code of the helper function can be found in Section <a href="miscellaneous.html#normalize">7.4.8</a>.</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="dataanalysis.html#cb76-1" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;normalize.R&quot;</span>)</span>
<span id="cb76-2"><a href="dataanalysis.html#cb76-2" tabindex="-1"></a>data <span class="ot">&lt;-</span> dataset</span>
<span id="cb76-3"><a href="dataanalysis.html#cb76-3" tabindex="-1"></a>theoretical_min <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb76-4"><a href="dataanalysis.html#cb76-4" tabindex="-1"></a>theoretical_max <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">7</span>)</span>
<span id="cb76-5"><a href="dataanalysis.html#cb76-5" tabindex="-1"></a>scale <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">100</span>) <span class="co">#percentages</span></span>
<span id="cb76-6"><a href="dataanalysis.html#cb76-6" tabindex="-1"></a>dataset1 <span class="ot">&lt;-</span> <span class="fu">min_max_normalize</span> (data, <span class="at">theoretical_min =</span> theoretical_min, <span class="at">theoretical_max =</span> theoretical_max, <span class="at">scale =</span> scale)</span>
<span id="cb76-7"><a href="dataanalysis.html#cb76-7" tabindex="-1"></a><span class="fu">head</span>(dataset1, <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##   Perceived usefulness Compatibility Perceived ease of use Emotional value
## 1             56.91456      50.00000              91.90439        58.07427
## 2             41.72252      58.41091              58.80878        66.57599
## 3             75.00000      58.41091              75.00000        75.00000
##   Adoption intention Technology use
## 1           25.00000       16.66667
## 2           83.23446       33.33333
## 3           75.00000       33.33333</code></pre>
<p>The resulting dataset with 0-100 normalized unstandardized latent variable scores is called <code>dataset1</code>. The variable scores can be interpreted as percentages of the range of the scale. For example, the midpoint 3 of a non-normalized unstandardized 1-5-Likert scale becomes 50 after 0-100 normalization. Note that for the illustrative example normalization is not essential for conducting IPMA, CIPMA or BIPMA because the five predictor variables have the same scale values (1-5-Likert scales).</p>
<p>Since the results of NCA are insensitive for linear transformations, the results are the same for standardized, unstandardized, normalized or non-normalized scores. Unstandardized (normalized or non-normalized) latent variable scores are the preferred input for NCA because of interpretability. The reason is that in contrast to SEM where a relationship is describes in terms of a change of <span class="math inline">\(X\)</span> producing a change of <span class="math inline">\(Y\)</span> (e.g., more <span class="math inline">\(X\)</span> produces more <span class="math inline">\(Y\)</span>), NCA describes a relationship in terms of the necessity of a <em>level</em> of <span class="math inline">\(X\)</span> for a <em>level</em> of <span class="math inline">\(Y\)</span> (level <span class="math inline">\(X\)</span> is necessary for level <span class="math inline">\(Y\)</span>). By using interpretable levels linked to the original (unstandardized) scales, NCA results become more insightful.</p>
</div>
<div id="example-step-4-conduct-nca" class="section level4 hasAnchor" number="4.6.2.4">
<h4><span class="header-section-number">4.6.2.4</span> Example Step 4: Conduct NCA<a href="dataanalysis.html#example-step-4-conduct-nca" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To estimate the necessity of the 9 relationships in the TAM model, 9 necessity analyses are done to obtain necessity effect sizes and p values. These analyses are grouped into two multiple NCA’s: one for the outcome Adoption intention (with four conditions Perceived Usefulness, Compatibility, Perceived ease of use, Emotional value), and one for the outcome Technology use (with five conditions (Perceived usefulness, Compatibility, Perceived ease of use, Emotional value, Adoption intention). The remainder of this demonstration focuses on the outcome Technology use, thus only five necessity relationships are analysed.</p>
<p>In the original four studies that use the example, the researchers make following choices for the NCA analysis:</p>
<ul>
<li><p>Ceiling line = CE-FDH.</p></li>
<li><p>Effect size threshold level = 0.10.</p></li>
<li><p>p value threshold level = 0.05.</p></li>
<li><p>Scope: empirical scope.</p></li>
<li><p>Outlier removal: none.</p></li>
<li><p>Target outcome = 85% <span class="citation">(only in <a href="#ref-hauff2024importance">Hauff et al., 2024</a>; <a href="#ref-sarstedt2024combined">Sarstedt et al., 2024</a>)</span>.</p></li>
</ul>
<p>For this demonstration the same choices for the NCA analysis are made for the primary analysis (and different choices for the robustness checks).</p>
<p>The original studies use standardized scores <span class="citation">(<a href="#ref-richter2020predictors">Richter, Schubring, et al., 2020</a>)</span>, non-normalized unstandardized scores <span class="citation">(<a href="#ref-richter2023apply">Richter, Hauff, Ringle, et al., 2023</a>)</span>, or 0-100 normalized unstandardized scores <span class="citation">(<a href="#ref-hauff2024importance">Hauff et al., 2024</a>; <a href="#ref-sarstedt2024combined">Sarstedt et al., 2024</a>)</span> as input for NCA. For this demonstration first the preferred scores from NCA perspective are used as input data: unstandardized latent variable scores without normalization (because all indicator scales of the conditions use the same Likert scales).</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="dataanalysis.html#cb78-1" tabindex="-1"></a><span class="fu">library</span>(NCA)</span>
<span id="cb78-2"><a href="dataanalysis.html#cb78-2" tabindex="-1"></a><span class="co"># Multiple NCA for Technology use</span></span>
<span id="cb78-3"><a href="dataanalysis.html#cb78-3" tabindex="-1"></a>model1.technology <span class="ot">&lt;-</span> <span class="fu">nca_analysis</span>(dataset, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">6</span>, <span class="at">ceilings =</span> <span class="st">&quot;ce_fdh&quot;</span>, <span class="at">test.rep =</span> <span class="dv">10000</span>) <span class="co">#10000 for final analysis</span></span></code></pre></div>
<pre><code>## Setting up parallelization, this might take a few seconds...                                                               Do test for  :  ce_fdh - Perceived usefulnessDone test for:  ce_fdh - Perceived usefulness       
## Do test for  :  ce_fdh - CompatibilityDone test for:  ce_fdh - Compatibility       
## Do test for  :  ce_fdh - Perceived ease of useDone test for:  ce_fdh - Perceived ease of use       
## Do test for  :  ce_fdh - Emotional valueDone test for:  ce_fdh - Emotional value       
## Do test for  :  ce_fdh - Adoption intentionDone test for:  ce_fdh - Adoption intention</code></pre>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="dataanalysis.html#cb80-1" tabindex="-1"></a>model1.technology</span></code></pre></div>
<pre><code>## 
## ---------------------------------------------------------------------------</code></pre>
<pre><code>##                       ce_fdh p    
## Perceived usefulness  0.24   0.001
## Compatibility         0.21   0.000
## Perceived ease of use 0.24   0.015
## Emotional value       0.33   0.000
## Adoption intention    0.29   0.001
## ---------------------------------------------------------------------------</code></pre>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="dataanalysis.html#cb83-1" tabindex="-1"></a><span class="fu">nca_output</span> (model1.technology, <span class="at">summaries =</span> <span class="cn">FALSE</span>)</span>
<span id="cb83-2"><a href="dataanalysis.html#cb83-2" tabindex="-1"></a></span>
<span id="cb83-3"><a href="dataanalysis.html#cb83-3" tabindex="-1"></a><span class="do">###not run###</span></span>
<span id="cb83-4"><a href="dataanalysis.html#cb83-4" tabindex="-1"></a><span class="co"># Multiple NCA for Adoption intention</span></span>
<span id="cb83-5"><a href="dataanalysis.html#cb83-5" tabindex="-1"></a><span class="co">#model1.adoption &lt;- nca_analysis(dataset, 1:5, 6, ceilings = &quot;ce_fdh&quot;, test.rep = 10000)</span></span>
<span id="cb83-6"><a href="dataanalysis.html#cb83-6" tabindex="-1"></a><span class="co">#model1.adoption</span></span>
<span id="cb83-7"><a href="dataanalysis.html#cb83-7" tabindex="-1"></a><span class="co">#nca_output (model1.adoption, summaries = FALSE)</span></span></code></pre></div>
<p>The results show NCA’s effect size and <span class="math inline">\(p\)</span> value of the five conditions for Technology use. The results correspond to those reported in the four original studies using the SmartPLS software. It can be concluded that the five conditions are necessary conditions for Technology use because the three criteria for identifying necessity in kind are met:</p>
<ol style="list-style-type: decimal">
<li>A necessity hypothesis is formulated and theoretically justified (For the purpose of this demonstration this requirement is assumed to hold).<br />
</li>
<li>The effect size is relatively large (<span class="math inline">\(d \geq 0.10\)</span>).</li>
<li>The <span class="math inline">\(p\)</span> value is relatively small (<span class="math inline">\(p \leq 0.05\)</span>).</li>
</ol>
<p>This means that the analysis can continue with the bottleneck table that includes all five conditions for analyzing ‘necessity in degree’. This analysis gives information about the minimum level of a condition that is necessary for the target level of the outcome. It also informs if a selected target outcome level is achievable, given the observed levels of the conditions. If a case has a value of a condition below the minimum required level, this case is a ‘bottleneck case’ for that condition. If the case has a condition value above the minimum required level, the case is not a bottleneck case for this condition, but could be a bottleneck case for another conditions. Only if for all conditions the values are above the threshold levels, the case is not a bottleneck case and the target outcome level becomes possible. Only when all condition values exceed their respective threshold levels, the case is not a bottleneck case, making the target outcome level achievable.</p>
<p>The use of non-normalized unstandardized latent variable scores and of ‘actual values’ in the bottleneck table ensures a direct link between the values in the bottleneck table and the values of the Likert scales that were used for measuring the indicator scores. This means that in NCA’s <code>nca_analysis</code> function the values of conditions in the bottleneck table must be must specified as ‘actual’ using the argument <code>bottleneck.x = 'actual'</code>. Since the outcome variable Technology use has 7 distinct levels, the steps in the bottleneck table preferably corresponds to these levels of the outcome. This can be done with the argument <code>steps</code> which can specify these 7 levels.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="dataanalysis.html#cb84-1" tabindex="-1"></a><span class="fu">library</span>(NCA)</span>
<span id="cb84-2"><a href="dataanalysis.html#cb84-2" tabindex="-1"></a><span class="co"># Arguments for the bottleneck table</span></span>
<span id="cb84-3"><a href="dataanalysis.html#cb84-3" tabindex="-1"></a>bottleneck.y <span class="ot">=</span> <span class="st">&quot;actual&quot;</span></span>
<span id="cb84-4"><a href="dataanalysis.html#cb84-4" tabindex="-1"></a>bottleneck.x <span class="ot">=</span> <span class="st">&quot;actual&quot;</span></span>
<span id="cb84-5"><a href="dataanalysis.html#cb84-5" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">1</span>)</span>
<span id="cb84-6"><a href="dataanalysis.html#cb84-6" tabindex="-1"></a></span>
<span id="cb84-7"><a href="dataanalysis.html#cb84-7" tabindex="-1"></a><span class="co"># Multiple NCA for Technology use </span></span>
<span id="cb84-8"><a href="dataanalysis.html#cb84-8" tabindex="-1"></a>model2.technology <span class="ot">&lt;-</span> <span class="fu">nca_analysis</span>(dataset,<span class="co"># unstandardized (non-normalized) latent variable scores</span></span>
<span id="cb84-9"><a href="dataanalysis.html#cb84-9" tabindex="-1"></a>                                  <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="co"># five conditions</span></span>
<span id="cb84-10"><a href="dataanalysis.html#cb84-10" tabindex="-1"></a>                                  <span class="dv">6</span>, <span class="co"># outcome</span></span>
<span id="cb84-11"><a href="dataanalysis.html#cb84-11" tabindex="-1"></a>                                  <span class="at">ceilings =</span> <span class="st">&quot;ce_fdh&quot;</span>,</span>
<span id="cb84-12"><a href="dataanalysis.html#cb84-12" tabindex="-1"></a>                                  <span class="at">bottleneck.x =</span> bottleneck.x,</span>
<span id="cb84-13"><a href="dataanalysis.html#cb84-13" tabindex="-1"></a>                                  <span class="at">bottleneck.y =</span> bottleneck.y,</span>
<span id="cb84-14"><a href="dataanalysis.html#cb84-14" tabindex="-1"></a>                                  <span class="at">steps =</span> steps)</span>
<span id="cb84-15"><a href="dataanalysis.html#cb84-15" tabindex="-1"></a><span class="fu">nca_output</span> (model2.technology, <span class="at">bottlenecks =</span> <span class="cn">TRUE</span>, <span class="at">summaries =</span> <span class="cn">FALSE</span>, <span class="at">plots =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
## ---------------------------------------------------------------------------</code></pre>
<pre><code>## Bottleneck CE-FDH (cutoff = 0)</code></pre>
<pre><code>## Y Technology use        (actual)</code></pre>
<pre><code>## 1 Perceived usefulness  (actual)</code></pre>
<pre><code>## 2 Compatibility         (actual)</code></pre>
<pre><code>## 3 Perceived ease of use (actual)</code></pre>
<pre><code>## 4 Emotional value       (actual)</code></pre>
<pre><code>## 5 Adoption intention    (actual)</code></pre>
<pre><code>## ---------------------------------------------------------------------------
## Y      1     2     3     4     5    
## 1     NN    NN    NN    NN    NN   
## 2     NN    NN    2.015 NN    NN   
## 3     NN    NN    2.015 NN    NN   
## 4     1.628 2.021 2.339 2.986 2.353
## 5     1.628 2.348 2.339 2.986 2.353
## 6     2.925 2.348 2.355 2.986 2.353
## 7     3.648 2.348 3.676 2.986 4.000</code></pre>
<pre><code>## </code></pre>
<p>The outcome variable Technology use is the perceived frequency of utilizing an e-book. The 7 anchor points are 1 = never, 2 = seldom; 3 = several times a month; 4 = once a week; 5 = several times a week; 6 = daily; 7 = several times daily. The condition variables are measured on a 5 point disagree-agree Likert scale where the anchor points range from 1 = strongly disagree to 5 = agree fully. In the original studies (and here) it is assumed that these Likert scales are interval scales, meaning the distances between anchor points are treated as being equal. This assumption facilitates quantitative analysis of the data, although it is often a strong assumption.</p>
<p>The bottleneck table can be evaluated row-wise. It shows that for a given target outcome level of Technology use (first column), the conditions must meet a certain minimum level (next columns). For example, for a level of 4 of Technology use (‘once a week’), it is necessary to have level 1.628 of Perceived usefulness, and for level 6 of Technology use the Perceived usefulness must be at least 2.925.</p>
<p>The bottleneck tables that are used by <span class="citation">Hauff et al. (<a href="#ref-hauff2024importance">2024</a>)</span> and <span class="citation">Sarstedt et al. (<a href="#ref-sarstedt2024combined">2024</a>)</span> have a large number of steps. They used the 0-100 normalized unstandardized latent variable. Their bottleneck analyses use steps of 5% Technology use, starting from 0% = original level 1 to 100% = original level 7. For the purpose of CIPMA, ‘actual’ values for the outcome are selected (because the input data are already percentage of range) for the outcome and ‘percentile’ values for the conditions. Their analysis is replicated as follows:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="dataanalysis.html#cb95-1" tabindex="-1"></a><span class="fu">library</span>(NCA)</span>
<span id="cb95-2"><a href="dataanalysis.html#cb95-2" tabindex="-1"></a><span class="co"># Arguments for the bottleneck table</span></span>
<span id="cb95-3"><a href="dataanalysis.html#cb95-3" tabindex="-1"></a>bottleneck.y <span class="ot">=</span> <span class="st">&quot;actual&quot;</span></span>
<span id="cb95-4"><a href="dataanalysis.html#cb95-4" tabindex="-1"></a>bottleneck.x <span class="ot">=</span> <span class="st">&quot;percentile&quot;</span></span>
<span id="cb95-5"><a href="dataanalysis.html#cb95-5" tabindex="-1"></a>steps<span class="ot">=</span><span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">100</span>, <span class="dv">5</span>)</span>
<span id="cb95-6"><a href="dataanalysis.html#cb95-6" tabindex="-1"></a>test.rep <span class="ot">=</span> <span class="dv">10000</span> <span class="co">#10000 for final analysis</span></span>
<span id="cb95-7"><a href="dataanalysis.html#cb95-7" tabindex="-1"></a><span class="co"># Multiple NCA for Technology use </span></span>
<span id="cb95-8"><a href="dataanalysis.html#cb95-8" tabindex="-1"></a>model3.technology <span class="ot">&lt;-</span> <span class="fu">nca_analysis</span>(dataset1, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">6</span>, <span class="at">ceilings =</span> <span class="st">&quot;ce_fdh&quot;</span>, <span class="at">bottleneck.x =</span> bottleneck.x , <span class="at">bottleneck.y =</span> bottleneck.y, <span class="at">steps =</span> steps, <span class="at">test.rep =</span> test.rep)</span></code></pre></div>
<pre><code>## Setting up parallelization, this might take a few seconds...                                                               Do test for  :  ce_fdh - Perceived usefulnessDone test for:  ce_fdh - Perceived usefulness       
## Do test for  :  ce_fdh - CompatibilityDone test for:  ce_fdh - Compatibility       
## Do test for  :  ce_fdh - Perceived ease of useDone test for:  ce_fdh - Perceived ease of use       
## Do test for  :  ce_fdh - Emotional valueDone test for:  ce_fdh - Emotional value       
## Do test for  :  ce_fdh - Adoption intentionDone test for:  ce_fdh - Adoption intention</code></pre>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="dataanalysis.html#cb97-1" tabindex="-1"></a><span class="fu">nca_output</span> (model3.technology, <span class="at">bottlenecks =</span> <span class="cn">TRUE</span>, <span class="at">summaries =</span> <span class="cn">FALSE</span>, <span class="at">plots =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
## ---------------------------------------------------------------------------</code></pre>
<pre><code>## Bottleneck CE-FDH (cutoff = 0)</code></pre>
<pre><code>## Y Technology use        (actual)</code></pre>
<pre><code>## 1 Perceived usefulness  (percentile)</code></pre>
<pre><code>## 2 Compatibility         (percentile)</code></pre>
<pre><code>## 3 Perceived ease of use (percentile)</code></pre>
<pre><code>## 4 Emotional value       (percentile)</code></pre>
<pre><code>## 5 Adoption intention    (percentile)</code></pre>
<pre><code>## ---------------------------------------------------------------------------
## Y        1         2        3         4        5        
## 0       NN (0)    NN (0)   NN (0)    NN (0)   NN (0)   
## 5       NN (0)    NN (0)   0.6 (1)   NN (0)   NN (0)   
## 10      NN (0)    NN (0)   0.6 (1)   NN (0)   NN (0)   
## 15      NN (0)    NN (0)   0.6 (1)   NN (0)   NN (0)   
## 20      NN (0)    NN (0)   0.6 (1)   NN (0)   NN (0)   
## 25      NN (0)    NN (0)   0.6 (1)   NN (0)   NN (0)   
## 30      NN (0)    NN (0)   0.6 (1)   NN (0)   NN (0)   
## 35      1.7 (3)   5.7 (10) 1.1 (2)   5.7 (10) 4.6 (8)  
## 40      1.7 (3)   5.7 (10) 1.1 (2)   5.7 (10) 4.6 (8)  
## 45      1.7 (3)   5.7 (10) 1.1 (2)   5.7 (10) 4.6 (8)  
## 50      1.7 (3)   5.7 (10) 1.1 (2)   5.7 (10) 4.6 (8)  
## 55      1.7 (3)   8.6 (15) 1.1 (2)   5.7 (10) 4.6 (8)  
## 60      1.7 (3)   8.6 (15) 1.1 (2)   5.7 (10) 4.6 (8)  
## 65      1.7 (3)   8.6 (15) 1.1 (2)   5.7 (10) 4.6 (8)  
## 70      17.2 (30) 8.6 (15) 2.9 (5)   5.7 (10) 4.6 (8)  
## 75      17.2 (30) 8.6 (15) 2.9 (5)   5.7 (10) 4.6 (8)  
## 80      17.2 (30) 8.6 (15) 2.9 (5)   5.7 (10) 4.6 (8)  
## 85      47.1 (82) 8.6 (15) 28.7 (50) 5.7 (10) 39.1 (68)
## 90      47.1 (82) 8.6 (15) 28.7 (50) 5.7 (10) 39.1 (68)
## 95      47.1 (82) 8.6 (15) 28.7 (50) 5.7 (10) 39.1 (68)
## 100     47.1 (82) 8.6 (15) 28.7 (50) 5.7 (10) 39.1 (68)</code></pre>
<pre><code>## </code></pre>
<p>In this version of the bottleneck table, the outcome is expressed as actual values (here the 0-100% normalized values) and the conditions as percentiles. The percentile value corresponds to the <em>percentage</em> of cases that are unable to achieve the selected target level of the outcome. The number between brackets refers to the <em>number</em> of cases that were unable to meet the required level of the condition for the given target level of the outcome. For example, for the target level of Technology use of 85%, 47.1% of cases (82 cases) were unable to achieve the required level for Perceived usefulness. This means that these cases will not have a level of 85% Technology use. A case that is not able to achieve a target outcome because the required level of the necessary condition is not met is a <em>bottleneck case</em>.</p>
<p>The level of 85% outcome on a 0-100 normalized scale corresponds to level 6.1 on the original 1-7-Likert scale. A value of 6 on the Likert scale (daily use of the e-reader) corresponds to 83.33% on the 0-100 normalized scale. It shows that although 0-100 normalization is common in the context of IPMA the link with the original scales are obscured.</p>
<p>The percentage of bottleneck cases for a given condition and target outcome can be extracted from the the bottleneck table if percentiles were used as values for the conditions by using the helper function <code>get_bottleneck_cases</code>. The <code>R</code> code of the helper function be found in Section <a href="miscellaneous.html#getbottleneckcases">7.4.9</a>.</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="dataanalysis.html#cb108-1" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;get_bottleneck_cases.R&quot;</span>)</span>
<span id="cb108-2"><a href="dataanalysis.html#cb108-2" tabindex="-1"></a><span class="co"># Multiple NCA for Technology use </span></span>
<span id="cb108-3"><a href="dataanalysis.html#cb108-3" tabindex="-1"></a>data <span class="ot">&lt;-</span>  dataset1</span>
<span id="cb108-4"><a href="dataanalysis.html#cb108-4" tabindex="-1"></a>predicted <span class="ot">&lt;-</span> <span class="st">&quot;Technology use&quot;</span></span>
<span id="cb108-5"><a href="dataanalysis.html#cb108-5" tabindex="-1"></a>predictors <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="st">&quot;Perceived usefulness&quot;</span>, </span>
<span id="cb108-6"><a href="dataanalysis.html#cb108-6" tabindex="-1"></a>                 <span class="st">&quot;Compatibility&quot;</span>,</span>
<span id="cb108-7"><a href="dataanalysis.html#cb108-7" tabindex="-1"></a>                 <span class="st">&quot;Perceived ease of use&quot;</span>,</span>
<span id="cb108-8"><a href="dataanalysis.html#cb108-8" tabindex="-1"></a>                 <span class="st">&quot;Emotional value&quot;</span>,</span>
<span id="cb108-9"><a href="dataanalysis.html#cb108-9" tabindex="-1"></a>                 <span class="st">&quot;Adoption intention&quot;</span>)</span>
<span id="cb108-10"><a href="dataanalysis.html#cb108-10" tabindex="-1"></a>corner <span class="ot">=</span> <span class="dv">1</span> <span class="co"># default expected empty space; if needed specify for each condition, e.g. corner = c(1,2,1)</span></span>
<span id="cb108-11"><a href="dataanalysis.html#cb108-11" tabindex="-1"></a>target_outcome <span class="ot">&lt;-</span> <span class="dv">85</span></span>
<span id="cb108-12"><a href="dataanalysis.html#cb108-12" tabindex="-1"></a>ceiling <span class="ot">&lt;-</span> <span class="st">&quot;ce_fdh&quot;</span></span>
<span id="cb108-13"><a href="dataanalysis.html#cb108-13" tabindex="-1"></a>bottlenecks_technology <span class="ot">&lt;-</span> <span class="fu">get_bottleneck_cases</span>(<span class="at">data =</span> data, <span class="at">conditions =</span> predictors, <span class="at">outcome =</span> predicted, <span class="at">corner =</span> corner, <span class="at">target_outcome =</span> target_outcome, <span class="at">ceiling =</span> ceiling)</span>
<span id="cb108-14"><a href="dataanalysis.html#cb108-14" tabindex="-1"></a>bottlenecks_technology</span></code></pre></div>
<pre><code>## $bottleneck_cases_per
##                       Bottlenecks (Y = 85)
## Perceived usefulness             47.126437
## Compatibility                     8.620690
## Perceived ease of use            28.735632
## Emotional value                   5.747126
## Adoption intention               39.080460
## 
## $bottleneck_cases_num
##                       Bottlenecks (Y = 85)
## Perceived usefulness                    82
## Compatibility                           15
## Perceived ease of use                   50
## Emotional value                         10
## Adoption intention                      68</code></pre>
<p>These numbers correspond the the number in row Y = 85 of the bottleneck table where the values of the conditions are expressed in percentiles. The percentage of bottleneck cases is used as input to the CIPMA.</p>
</div>
<div id="example-step-5-produce-bipma" class="section level4 hasAnchor" number="4.6.2.5">
<h4><span class="header-section-number">4.6.2.5</span> Example Step 5: Produce BIPMA<a href="dataanalysis.html#example-step-5-produce-bipma" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Before producing the new BIPMA (see Section <a href="dataanalysis.html#producebipma">4.6.1.5</a>), this demonstration first produces IPMA and CIPMA.</p>
<p>For producing the classic IPMA Importance and Performance scores are extracted from the SEM results (steps 2 and 3). The Importance score of each predictor variable corresponds to the total effect (path coefficients) on the predicted variable (step 2). The Performance score of each predictor variable is the mean of the 0-100 normalized unstandardized variable score (step 3). The helper function <code>get_ipma_df</code> can be used for extracting these values from the SEM results. The <code>R</code> code of the helper function be found in Section <a href="miscellaneous.html#getipmadf">7.4.10</a>.</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="dataanalysis.html#cb110-1" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;get_ipma_df.R&quot;</span>)</span>
<span id="cb110-2"><a href="dataanalysis.html#cb110-2" tabindex="-1"></a>data <span class="ot">&lt;-</span> dataset1 <span class="co"># 0-100 normalized unstandardized</span></span>
<span id="cb110-3"><a href="dataanalysis.html#cb110-3" tabindex="-1"></a>sem <span class="ot">&lt;-</span> TAM_pls</span>
<span id="cb110-4"><a href="dataanalysis.html#cb110-4" tabindex="-1"></a><span class="co"># Multiple NCA for Technology use</span></span>
<span id="cb110-5"><a href="dataanalysis.html#cb110-5" tabindex="-1"></a>predicted <span class="ot">&lt;-</span> <span class="st">&quot;Technology use&quot;</span></span>
<span id="cb110-6"><a href="dataanalysis.html#cb110-6" tabindex="-1"></a>predictors <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="st">&quot;Perceived usefulness&quot;</span>, </span>
<span id="cb110-7"><a href="dataanalysis.html#cb110-7" tabindex="-1"></a>                 <span class="st">&quot;Compatibility&quot;</span>,</span>
<span id="cb110-8"><a href="dataanalysis.html#cb110-8" tabindex="-1"></a>                 <span class="st">&quot;Perceived ease of use&quot;</span>,</span>
<span id="cb110-9"><a href="dataanalysis.html#cb110-9" tabindex="-1"></a>                 <span class="st">&quot;Emotional value&quot;</span>,</span>
<span id="cb110-10"><a href="dataanalysis.html#cb110-10" tabindex="-1"></a>                 <span class="st">&quot;Adoption intention&quot;</span>)</span>
<span id="cb110-11"><a href="dataanalysis.html#cb110-11" tabindex="-1"></a>IPMA_df_technology <span class="ot">&lt;-</span> <span class="fu">get_ipma_df</span>(<span class="at">data =</span> data, <span class="at">sem =</span> sem, <span class="at">predictors =</span> predictors, <span class="at">predicted =</span> predicted)</span>
<span id="cb110-12"><a href="dataanalysis.html#cb110-12" tabindex="-1"></a>IPMA_df_technology</span></code></pre></div>
<pre><code>##               predictor Importance Performance
## 1  Perceived usefulness 0.14921041    64.24785
## 2         Compatibility 0.12699788    61.55690
## 3 Perceived ease of use 0.04863022    75.64040
## 4       Emotional value 0.36169649    70.17135
## 5    Adoption intention 0.43705233    72.04067</code></pre>
<p>The IPMA is produced by mapping the predictor variables on a 2 x 2 plot with the horizontal axis representing Importance and the vertical axis Performance. This can be done with the helper function <code>get_ipma_plot</code>, which <code>R</code> code can be found in Section <a href="miscellaneous.html#getipmaplot">7.4.11</a>.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="dataanalysis.html#cb112-1" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;get_ipma_plot.R&quot;</span>)</span>
<span id="cb112-2"><a href="dataanalysis.html#cb112-2" tabindex="-1"></a><span class="co"># Multiple NCA for Technology use</span></span>
<span id="cb112-3"><a href="dataanalysis.html#cb112-3" tabindex="-1"></a>ipma_df <span class="ot">&lt;-</span> IPMA_df_technology </span>
<span id="cb112-4"><a href="dataanalysis.html#cb112-4" tabindex="-1"></a>x_range <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.6</span>) <span class="co"># range of the Importance axis</span></span>
<span id="cb112-5"><a href="dataanalysis.html#cb112-5" tabindex="-1"></a>y_range <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">100</span>) <span class="co"># range of the Performance axis</span></span>
<span id="cb112-6"><a href="dataanalysis.html#cb112-6" tabindex="-1"></a>IPMA_plot_technology <span class="ot">&lt;-</span> <span class="fu">get_ipma_plot</span>(<span class="at">ipma_df =</span> ipma_df, <span class="at">x_range =</span> x_range, <span class="at">y_range =</span> y_range) </span></code></pre></div>
<p>The results for Technology use are shown in Figure <a href="dataanalysis.html#fig:ipma">4.18</a>. Although the SEM results show that Compatibility and Perceived ease of use have no significant effect on Technology use, the plot includes the points for all predictors. The reason is that this choice was made in the publications that previously used this example.</p>
<p>According to IPMA, priority of action should be given to a predictor with high Importance and low Performance scores. From the two predictors with the highest Importance (Emotional value and Adoption intention), Emotional value has the lowest Performance score and could be selected to prioritize action. This action should result in an increase of its current Performance score (mean score of the latent variable), which is somewhat below 75%, to a higher score.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ipma"></span>
<img src="ipma85.png" alt="Classic Importance Performance Map Analysis (IPMA) for the outcome Technology use." width="100%" />
<p class="caption">
Figure 4.18: Classic Importance Performance Map Analysis (IPMA) for the outcome Technology use.
</p>
</div>
<p>CIPMA adds the bottleneck dimension to IPMA. In selecting the priority predictor, CIPMA not only considers the Importance and Performance scores of the predictor, but also the percentage of bottleneck cases of the predictor: the percentage of cases that are unable to achieve a particular target outcome level. As shown above, the percentage of bottleneck cases per predictor can be obtained with the the helper function <code>get_bottleneck_cases</code>. For producing CIPMA the IPMA dataset with Importance and Performance scores is extended with the percentage of bottleneck cases to get the CIPMA dataset. The function <code>get_cipma_df</code> is used for this; the <code>R</code> code of the helper function be found in Section <a href="miscellaneous.html#getcipmadf">7.4.12</a>. Note that the output includes the column ‘Necessity’ that indicates of the predictor is necessary or not given the selected threshold values for the effect size <span class="math inline">\(d\)</span> and the <span class="math inline">\(p\)</span> value. These predictors should not show up in the bottleneck table and therefore should not be part of the bottleneck dimension of CIPMA; Therefore, in the <code>get_cipma_df</code> function a standard point size as in IPMA is given to such predictor.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="dataanalysis.html#cb113-1" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;get_cipma_df.R&quot;</span>)</span>
<span id="cb113-2"><a href="dataanalysis.html#cb113-2" tabindex="-1"></a><span class="co"># Multiple NCA for Technology use</span></span>
<span id="cb113-3"><a href="dataanalysis.html#cb113-3" tabindex="-1"></a><span class="co"># Identify predictors that are necessary </span></span>
<span id="cb113-4"><a href="dataanalysis.html#cb113-4" tabindex="-1"></a>d_threshold <span class="ot">&lt;-</span> <span class="fl">0.1</span> </span>
<span id="cb113-5"><a href="dataanalysis.html#cb113-5" tabindex="-1"></a>p_threshold <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb113-6"><a href="dataanalysis.html#cb113-6" tabindex="-1"></a>model <span class="ot">&lt;-</span> model3.technology</span>
<span id="cb113-7"><a href="dataanalysis.html#cb113-7" tabindex="-1"></a>effect_size <span class="ot">&lt;-</span> <span class="fu">sapply</span>(predictors, <span class="cf">function</span>(p) model<span class="sc">$</span>summaries[[p]][[<span class="dv">2</span>]][[<span class="dv">2</span>]])</span>
<span id="cb113-8"><a href="dataanalysis.html#cb113-8" tabindex="-1"></a>p_value <span class="ot">&lt;-</span> <span class="fu">sapply</span>(predictors, <span class="cf">function</span>(p) model<span class="sc">$</span>summaries[[p]][[<span class="dv">2</span>]][[<span class="dv">6</span>]])</span>
<span id="cb113-9"><a href="dataanalysis.html#cb113-9" tabindex="-1"></a>necessity <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(effect_size <span class="sc">&gt;=</span> d_threshold <span class="sc">&amp;</span> p_value <span class="sc">&lt;=</span> p_threshold, <span class="st">&quot;yes&quot;</span>, <span class="st">&quot;no&quot;</span>)</span>
<span id="cb113-10"><a href="dataanalysis.html#cb113-10" tabindex="-1"></a> </span>
<span id="cb113-11"><a href="dataanalysis.html#cb113-11" tabindex="-1"></a>ipma_df <span class="ot">&lt;-</span> IPMA_df_technology</span>
<span id="cb113-12"><a href="dataanalysis.html#cb113-12" tabindex="-1"></a>bottlenecks <span class="ot">&lt;-</span> bottlenecks_technology</span>
<span id="cb113-13"><a href="dataanalysis.html#cb113-13" tabindex="-1"></a>CIPMA_df_technology <span class="ot">&lt;-</span> <span class="fu">get_cipma_df</span>(<span class="at">ipma_df =</span> ipma_df, <span class="at">bottlenecks =</span> bottlenecks, <span class="at">necessity =</span> necessity)</span>
<span id="cb113-14"><a href="dataanalysis.html#cb113-14" tabindex="-1"></a>CIPMA_df_technology</span></code></pre></div>
<pre><code>##               predictor Importance Performance Bottleneck_cases_per
## 1  Perceived usefulness 0.14921041    64.24785            47.126437
## 2         Compatibility 0.12699788    61.55690             8.620690
## 3 Perceived ease of use 0.04863022    75.64040            28.735632
## 4       Emotional value 0.36169649    70.17135             5.747126
## 5    Adoption intention 0.43705233    72.04067            39.080460
##   Bottleneck_cases_num Necessity              Predictor_with_cases
## 1                   82       yes  Perceived usefulness (47%, n=82)
## 2                   15       yes          Compatibility (9%, n=15)
## 3                   50       yes Perceived ease of use (29%, n=50)
## 4                   10       yes        Emotional value (6%, n=10)
## 5                   68       yes    Adoption intention (39%, n=68)</code></pre>
<p>Now the CIPMA plot can be produced with the helper function <code>get_cipma_plot</code>, which <code>R</code> code can be found in Section <a href="miscellaneous.html#getcipmaplot">7.4.13</a>.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="dataanalysis.html#cb115-1" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;get_cipma_plot.R&quot;</span>)</span>
<span id="cb115-2"><a href="dataanalysis.html#cb115-2" tabindex="-1"></a><span class="co"># Multiple NCA for Technology use</span></span>
<span id="cb115-3"><a href="dataanalysis.html#cb115-3" tabindex="-1"></a>cipma_df <span class="ot">&lt;-</span> CIPMA_df_technology </span>
<span id="cb115-4"><a href="dataanalysis.html#cb115-4" tabindex="-1"></a>x_range <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.6</span>)</span>
<span id="cb115-5"><a href="dataanalysis.html#cb115-5" tabindex="-1"></a>y_range <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">100</span>)</span>
<span id="cb115-6"><a href="dataanalysis.html#cb115-6" tabindex="-1"></a>size_limits <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">100</span>)</span>
<span id="cb115-7"><a href="dataanalysis.html#cb115-7" tabindex="-1"></a>size_range <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="dv">50</span>) <span class="co"># the size of the bulbs</span></span>
<span id="cb115-8"><a href="dataanalysis.html#cb115-8" tabindex="-1"></a>name_plot <span class="ot">&lt;-</span> <span class="st">&quot;Original&quot;</span> </span>
<span id="cb115-9"><a href="dataanalysis.html#cb115-9" tabindex="-1"></a>cIPMA_plot_technology <span class="ot">&lt;-</span> <span class="fu">get_cipma_plot</span>(<span class="at">cipma_df =</span> cipma_df,</span>
<span id="cb115-10"><a href="dataanalysis.html#cb115-10" tabindex="-1"></a>                                        <span class="at">x_range =</span> x_range,</span>
<span id="cb115-11"><a href="dataanalysis.html#cb115-11" tabindex="-1"></a>                                        <span class="at">y_range =</span> y_range,</span>
<span id="cb115-12"><a href="dataanalysis.html#cb115-12" tabindex="-1"></a>                                        <span class="at">size_limits =</span> size_limits,</span>
<span id="cb115-13"><a href="dataanalysis.html#cb115-13" tabindex="-1"></a>                                        <span class="at">size_range =</span> size_range)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cipma"></span>
<img src="cipma85.png" alt="Combined Impotance Performance Map Analysis (CIPMA) for the outcome Technology use. The size of the dots is an indication of the number of cases that cannot achieve the target outcome of 85% of maximum outcome." width="100%" />
<p class="caption">
Figure 4.19: Combined Impotance Performance Map Analysis (CIPMA) for the outcome Technology use. The size of the dots is an indication of the number of cases that cannot achieve the target outcome of 85% of maximum outcome.
</p>
</div>
<p>The results are shown in Figure <a href="dataanalysis.html#fig:cipma">4.19</a>, which corresponds to the CIPMA plots in <span class="citation">Hauff et al. (<a href="#ref-hauff2024importance">2024</a>)</span> and <span class="citation">Sarstedt et al. (<a href="#ref-sarstedt2024combined">2024</a>)</span>. The IPMA plot is extended with points sizes that depend on the number or percentage of bottleneck cases. Since all predictors are necessary, each point size is relevant. The percentage and number of bottleneck cases are between brackets. The NCA results show large differences in percentage and number of bottleneck cases between the five conditions. The order from high to low percentages is: Perceived usefulness, Adoption intention, Perceived ease of use, Compatibility and Emotional value. Perceived usefulness has 47% bottleneck cases, whereas Emotional value has only 6%. This means that from the perspective of NCA Perceived usefulness is a more relevant than emotional value. Successful interventions on a single condition (with the goal that bring all bottleneck cases above the threshold level) will reduce more bottleneck cases when the intervention focuses on Perceived usefulness, rather than on emotional value. Note that such intervention to eliminate bottlenecks does not guarantee that the target outcome level (85%) will be achieved: a necessary condition for an outcome is not a sufficient condition for it. Additionally, cases may be bottlenecks in multiple conditions. Note also the relevance of a necessary condition in terms of <em>effect size</em> may differ from the relevance of a necessary condition in terms of <em>number of bottleneck cases</em>. The first refers to the magnitude of the constraining role of the ceiling line (the phenomenon), whereas the second refers to distribution of cases below the ceiling (the size of a group of cases not able to ‘escape’ from the constraint). For emotional value the effect size is largest (0.33) but the percentage of bottleneck cases the lowest (6%).</p>
<p>The BIPMA extends the CIPMA by considering only single bottleneck cases per predictor as explained in Section <a href="dataanalysis.html#producebipma">4.6.1.5</a>. The number of single bottleneck cases can be extracted with the helper function <code>get_single_bottleneck_cases</code>. The <code>R</code> code of the helper function be found in Section <a href="miscellaneous.html#getsinglebottleneckcases">7.4.14</a>.</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="dataanalysis.html#cb116-1" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;get_single_bottleneck_cases.R&quot;</span>)</span>
<span id="cb116-2"><a href="dataanalysis.html#cb116-2" tabindex="-1"></a>data <span class="ot">&lt;-</span> dataset1</span>
<span id="cb116-3"><a href="dataanalysis.html#cb116-3" tabindex="-1"></a>ceilings <span class="ot">=</span> <span class="st">&quot;ce_fdh&quot;</span></span>
<span id="cb116-4"><a href="dataanalysis.html#cb116-4" tabindex="-1"></a>target_outcome <span class="ot">&lt;-</span> <span class="dv">85</span></span>
<span id="cb116-5"><a href="dataanalysis.html#cb116-5" tabindex="-1"></a><span class="co"># Multiple NCA for Technology use</span></span>
<span id="cb116-6"><a href="dataanalysis.html#cb116-6" tabindex="-1"></a>predicted <span class="ot">&lt;-</span> <span class="st">&quot;Technology use&quot;</span></span>
<span id="cb116-7"><a href="dataanalysis.html#cb116-7" tabindex="-1"></a>predictors <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="st">&quot;Perceived usefulness&quot;</span>, </span>
<span id="cb116-8"><a href="dataanalysis.html#cb116-8" tabindex="-1"></a>                 <span class="st">&quot;Compatibility&quot;</span>,</span>
<span id="cb116-9"><a href="dataanalysis.html#cb116-9" tabindex="-1"></a>                 <span class="st">&quot;Perceived ease of use&quot;</span>,</span>
<span id="cb116-10"><a href="dataanalysis.html#cb116-10" tabindex="-1"></a>                 <span class="st">&quot;Emotional value&quot;</span>,</span>
<span id="cb116-11"><a href="dataanalysis.html#cb116-11" tabindex="-1"></a>                 <span class="st">&quot;Adoption intention&quot;</span>)</span>
<span id="cb116-12"><a href="dataanalysis.html#cb116-12" tabindex="-1"></a>corner <span class="ot">=</span> <span class="dv">1</span> <span class="co"># default expected empty space; if needed specify for each condition, e.g. corner = c(1,2,1)</span></span>
<span id="cb116-13"><a href="dataanalysis.html#cb116-13" tabindex="-1"></a>single_bottlenecks_technology <span class="ot">&lt;-</span> <span class="fu">get_single_bottleneck_cases</span>(data, <span class="at">conditions =</span> predictors, <span class="at">outcome =</span> predicted, <span class="at">corner =</span> corner, <span class="at">target_outcome =</span> target_outcome, <span class="at">ceiling =</span> ceilings)</span>
<span id="cb116-14"><a href="dataanalysis.html#cb116-14" tabindex="-1"></a>single_bottlenecks_technology</span></code></pre></div>
<pre><code>## $single_bottleneck_cases_per
##                       Bottlenecks (Y = 85)
## Perceived usefulness            14.9425287
## Compatibility                    0.5747126
## Perceived ease of use            4.0229885
## Emotional value                  0.0000000
## Adoption intention               8.0459770
## 
## $single_bottleneck_cases_num
##                       Bottlenecks (Y = 85)
## Perceived usefulness                    26
## Compatibility                            1
## Perceived ease of use                    7
## Emotional value                          0
## Adoption intention                      14</code></pre>
<p>Next, the significant predictor variables for the predicted variable must be identified which can be done as follows:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="dataanalysis.html#cb118-1" tabindex="-1"></a>sem_sig <span class="ot">&lt;-</span> TAM_sig</span>
<span id="cb118-2"><a href="dataanalysis.html#cb118-2" tabindex="-1"></a>for_select_predicted <span class="ot">&lt;-</span> sem_sig[sem_sig<span class="sc">$</span>Predicted <span class="sc">==</span> predicted, ]</span>
<span id="cb118-3"><a href="dataanalysis.html#cb118-3" tabindex="-1"></a>sufficiency <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(for_select_predicted<span class="sc">$</span>Sig_Total, <span class="st">&quot;yes&quot;</span>, <span class="st">&quot;no&quot;</span>)</span>
<span id="cb118-4"><a href="dataanalysis.html#cb118-4" tabindex="-1"></a><span class="fu">names</span>(sufficiency) <span class="ot">&lt;-</span> predictors</span></code></pre></div>
<p>Subsequently, the BIPMA dataset with Bottlenecks (single bottlenecks), Importance and Performance scores can be obtained with the helper function <code>get_bipma_df</code>; the <code>R</code> code of the helper function be found in Section <a href="miscellaneous.html#getbipmadf">7.4.15</a>.</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="dataanalysis.html#cb119-1" tabindex="-1"></a><span class="co"># Function to create a BIPMA dataset with Importance, Performance, and Bottlenecks (percentage of SINGLE bottleneck cases)</span></span>
<span id="cb119-2"><a href="dataanalysis.html#cb119-2" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;get_bipma_df.R&quot;</span>)</span>
<span id="cb119-3"><a href="dataanalysis.html#cb119-3" tabindex="-1"></a><span class="co"># Multiple NCA for Technology use</span></span>
<span id="cb119-4"><a href="dataanalysis.html#cb119-4" tabindex="-1"></a>ipma_df <span class="ot">&lt;-</span> IPMA_df_technology</span>
<span id="cb119-5"><a href="dataanalysis.html#cb119-5" tabindex="-1"></a>single_bottlenecks <span class="ot">&lt;-</span> single_bottlenecks_technology</span>
<span id="cb119-6"><a href="dataanalysis.html#cb119-6" tabindex="-1"></a>BIPMA_df_technology <span class="ot">&lt;-</span> <span class="fu">get_bipma_df</span>(<span class="at">ipma_df =</span> ipma_df, <span class="at">single_bottlenecks=</span>single_bottlenecks, <span class="at">necessity =</span> necessity, <span class="at">sufficiency =</span> sufficiency)</span>
<span id="cb119-7"><a href="dataanalysis.html#cb119-7" tabindex="-1"></a>BIPMA_df_technology</span></code></pre></div>
<pre><code>##               predictor Importance Performance Single_bottleneck_cases_per
## 1  Perceived usefulness 0.14921041    64.24785                  14.9425287
## 2         Compatibility 0.12699788    61.55690                   0.5747126
## 3 Perceived ease of use 0.04863022    75.64040                   4.0229885
## 4       Emotional value 0.36169649    70.17135                   0.0000000
## 5    Adoption intention 0.43705233    72.04067                   8.0459770
##   Single_bottleneck_cases_num Necessity Sufficiency
## 1                          26       yes          no
## 2                           1       yes          no
## 3                           7       yes          no
## 4                           0       yes         yes
## 5                          14       yes         yes
##        Predictor_with_single_cases
## 1 Perceived usefulness (15%, n=26)
## 2          Compatibility (1%, n=1)
## 3  Perceived ease of use (4%, n=7)
## 4        Emotional value (0%, n=0)
## 5    Adoption intention (8%, n=14)</code></pre>
<p>Now the BIPMA can be created with the helper function <code>get_bipma_plot</code>, which <code>R</code> code can be found in Section <a href="miscellaneous.html#getbipmaplot">7.4.16</a>.</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="dataanalysis.html#cb121-1" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;get_bipma_plot.R&quot;</span>)</span>
<span id="cb121-2"><a href="dataanalysis.html#cb121-2" tabindex="-1"></a><span class="co">#Multiple NCA for Technology use</span></span>
<span id="cb121-3"><a href="dataanalysis.html#cb121-3" tabindex="-1"></a>bipma_df <span class="ot">&lt;-</span> BIPMA_df_technology </span>
<span id="cb121-4"><a href="dataanalysis.html#cb121-4" tabindex="-1"></a>x_range <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.6</span>)</span>
<span id="cb121-5"><a href="dataanalysis.html#cb121-5" tabindex="-1"></a>y_range <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">100</span>)</span>
<span id="cb121-6"><a href="dataanalysis.html#cb121-6" tabindex="-1"></a>size_limits <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">100</span>)</span>
<span id="cb121-7"><a href="dataanalysis.html#cb121-7" tabindex="-1"></a>size_range <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="dv">50</span>) <span class="co"># the size of the bulbs</span></span>
<span id="cb121-8"><a href="dataanalysis.html#cb121-8" tabindex="-1"></a>BIPMA_plot_technology <span class="ot">&lt;-</span> <span class="fu">get_bipma_plot</span>(<span class="at">bipma_df =</span> bipma_df, <span class="at">x_range =</span> x_range, <span class="at">y_range =</span> y_range, <span class="at">size_limits =</span> size_limits, <span class="at">size_range =</span> size_range)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bipma"></span>
<img src="bipma85.png" alt="Bottleneck Importance Performance Map Analysis (BIPMA) for the outcome Technology use. The size of the dots is an indication of the number of single bottleneck cases that cannot achieve the target outcome of 85% of maximum outcome. Grey dots:  Non-significant average effect according to SEM (Importance score compatible with 0). Black dots: No significant necessity effect according to NCA. Conditions that are non-significant according to both NCA and SEM are not shown." width="100%" />
<p class="caption">
Figure 4.20: Bottleneck Importance Performance Map Analysis (BIPMA) for the outcome Technology use. The size of the dots is an indication of the number of single bottleneck cases that cannot achieve the target outcome of 85% of maximum outcome. Grey dots: Non-significant average effect according to SEM (Importance score compatible with 0). Black dots: No significant necessity effect according to NCA. Conditions that are non-significant according to both NCA and SEM are not shown.
</p>
</div>
<p>The results are shown in Figure <a href="dataanalysis.html#fig:bipma">4.20</a>. For each condition the percentage and number of <em>single</em> bottleneck cases is given between brackets. The results again show large differences in the percentage and number of single bottleneck cases between the five conditions. Also the <em>order</em> from high to low percentages is the same as in CIPMA. However, the number of percentages in BIPMA are considerably lower than in CIPMA. Perceived usefulness has most single bottleneck cases (15%, n=26), whereas Emotional value has none. This means that, in contrast to the conclusion from CIPMA, emotional value is not a relevant predictor for an action based on NCA. Even if the bottlenecks for this predictor are eliminated, the outcome is not achievable because still bottlenecks of other conditions are active. Successful group interventions on a single predictor (with the goal to bring all bottleneck cases above the threshold level) could focus on Perceived usefulness, which has almost twice an many single bottlenecks than Adoption intention. Perceived usefulness, Compatibility and Perceived ease of use are non-significant results according to SEM (no average effects on Technology use). Predictors hat are necessary from the perspective of NCA, but are non-significant predictors from the perspective of SEM, are placed on the Importance axis at <span class="math inline">\(x = 0\)</span> and the corresponding points are shown in grey. Predictors that are significant from the perspective of SEM but non-significant from the perspective of NCA are shown as small black points, but none of the conditions in this BIBMA plot were non-significant from the perspective of NCA. Predictors that are non-significant from the perspective of both SEM and NCA are not included in the BIPMA plot.</p>
<p>For selecting a proper intervention strategy based on the BIPMA results see Section <a href="dataanalysis.html#producebipma">4.6.1.5</a>.</p>
</div>
<div id="example-step-6-conduct-robustness-checks" class="section level4 hasAnchor" number="4.6.2.6">
<h4><span class="header-section-number">4.6.2.6</span> Example Step 6: Conduct robustness checks<a href="dataanalysis.html#example-step-6-conduct-robustness-checks" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For the NCA part of a study that combines NCA with (PLS-)SEM, several robustness checks can be done (see Section <a href="dataanalysis.html#semrobustnesschecks">4.6.1.6</a>). For this demonstration eight checks are selected (Table <a href="dataanalysis.html#tab:examplerobustnesschecks">4.2</a>). In each check one choice is changed and compared with the original results, and it is evaluated if the conclusion regarding necessity is changed.</p>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:100%; overflow-x: scroll; width:100%; ">
<table style="width:30%; font-size: 9px; width: auto !important; margin-left: auto; margin-right: auto; font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;" class="table lightable-paper">
<caption style="font-size: initial !important;">
<span id="tab:examplerobustnesschecks">Table 4.2: </span>Selected robustness checks. The black elements are changed compared to the original
</caption>
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Robustness check
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Original
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Ceiling change
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
d threshold change
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
p threshold change
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Scope change
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Single outlier removal
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Multiple outlier removal
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Target lower
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Target higher
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Ceiling line
</td>
<td style="text-align:right;">
CE-FDH
</td>
<td style="text-align:right;">
<span style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: black !important;">CR-FDH</span>
</td>
<td style="text-align:right;">
CE-FDH
</td>
<td style="text-align:right;">
CE-FDH
</td>
<td style="text-align:right;">
CE-FDH
</td>
<td style="text-align:right;">
CE-FDH
</td>
<td style="text-align:right;">
CE-FDH
</td>
<td style="text-align:right;">
CE-FDH
</td>
<td style="text-align:right;">
CE-FDH
</td>
</tr>
<tr>
<td style="text-align:left;">
Threshold level of the effect size
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
<span style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: black !important;">0.20</span>
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
0.10
</td>
</tr>
<tr>
<td style="text-align:left;">
Threshold level of the p value
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
<span style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: black !important;">0.01</span>
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
</tr>
<tr>
<td style="text-align:left;">
Scope
</td>
<td style="text-align:right;">
empirical
</td>
<td style="text-align:right;">
empirical
</td>
<td style="text-align:right;">
empirical
</td>
<td style="text-align:right;">
empirical
</td>
<td style="text-align:right;">
<span style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: black !important;">theoretical</span>
</td>
<td style="text-align:right;">
empirical
</td>
<td style="text-align:right;">
empirical
</td>
<td style="text-align:right;">
empirical
</td>
<td style="text-align:right;">
empirical
</td>
</tr>
<tr>
<td style="text-align:left;">
Outlier removal
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
<span style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: black !important;">yes, single</span>
</td>
<td style="text-align:right;">
<span style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: black !important;">yes, multiple</span>
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
no
</td>
</tr>
<tr>
<td style="text-align:left;">
Target outcome
</td>
<td style="text-align:right;">
85
</td>
<td style="text-align:right;">
85
</td>
<td style="text-align:right;">
85
</td>
<td style="text-align:right;">
85
</td>
<td style="text-align:right;">
85
</td>
<td style="text-align:right;">
85
</td>
<td style="text-align:right;">
85
</td>
<td style="text-align:right;">
<span style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: black !important;">80</span>
</td>
<td style="text-align:right;">
<span style="     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: black !important;">90</span>
</td>
</tr>
</tbody>
</table>
</div>
<p>The effect of changing several researcher’s choices regarding necessity is shown in the NCA robustness table (Table <a href="dataanalysis.html#tab:robustcheckssem">4.3</a>). This table is produced with the integrated function <code>ncasem_example</code>that includes all previous helper functions as well as the robustness check. The code can be found in Section <a href="miscellaneous.html#ncasemexample">7.4.18</a>.
<br></p>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:450px; overflow-x: scroll; width:100%; ">
<table style="width:30%; font-size: 11px; width: auto !important; margin-left: auto; margin-right: auto; font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;" class="table lightable-paper">
<caption style="font-size: initial !important;">
<span id="tab:robustcheckssem">Table 4.3: </span>‘NCA robustness table’ with the results of the robustness checks
</caption>
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;border-bottom: 2px solid black;">
Robustness check
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;border-bottom: 2px solid black;">
Effect size
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;border-bottom: 2px solid black;">
p value
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;border-bottom: 2px solid black;">
Necessity
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;border-bottom: 2px solid black;">
Single bottlenecks(%)
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;border-bottom: 2px solid black;">
Single bottlenecks(#)
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;font-weight: bold;border-bottom: 2px solid black;">
Priority
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
Perceived usefulness
</td>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Original
</td>
<td style="text-align:left;">
0.24
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
14.9
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Ceiling change
</td>
<td style="text-align:left;">
0.19
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
5.2
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
d value change
</td>
<td style="text-align:left;">
0.24
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
14.9
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
p value change
</td>
<td style="text-align:left;">
0.24
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
14.9
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Scope change
</td>
<td style="text-align:left;">
0.24
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
14.9
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Single outlier removal
</td>
<td style="text-align:left;">
0.30
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
6.5
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Multiple outlier removal
</td>
<td style="text-align:left;">
0.29
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
6.6
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Target lower
</td>
<td style="text-align:left;">
0.24
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
10.3
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;border-bottom: 2px solid black;">
Target higher
</td>
<td style="text-align:left;border-bottom: 2px solid black;">
0.24
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
0.001
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
yes
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
14.9
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
26
</td>
<td style="text-align:left;border-bottom: 2px solid black;">
1
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
Compatibility
</td>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Original
</td>
<td style="text-align:left;">
0.21
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
0.6
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
Ceiling change
</td>
<td style="text-align:left;">
0.15
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
2.3
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
d value change
</td>
<td style="text-align:left;">
0.21
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
0.6
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
p value change
</td>
<td style="text-align:left;">
0.21
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
0.6
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
Scope change
</td>
<td style="text-align:left;">
0.21
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
0.6
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
Single outlier removal
</td>
<td style="text-align:left;">
0.28
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
1.2
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
Multiple outlier removal
</td>
<td style="text-align:left;">
0.29
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
1.2
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
Target lower
</td>
<td style="text-align:left;">
0.21
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
1.1
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
3.5
</td>
</tr>
<tr>
<td style="text-align:left;border-bottom: 2px solid black;">
Target higher
</td>
<td style="text-align:left;border-bottom: 2px solid black;">
0.21
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
0.000
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
yes
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
0.6
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
1
</td>
<td style="text-align:left;border-bottom: 2px solid black;">
4
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
Perceived ease of use
</td>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Original
</td>
<td style="text-align:left;">
0.24
</td>
<td style="text-align:right;">
0.015
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
Ceiling change
</td>
<td style="text-align:left;">
0.20
</td>
<td style="text-align:right;">
0.013
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
1.7
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
d value change
</td>
<td style="text-align:left;">
0.24
</td>
<td style="text-align:right;">
0.015
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
p value change
</td>
<td style="text-align:left;">
0.24
</td>
<td style="text-align:right;">
0.015
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
Scope change
</td>
<td style="text-align:left;">
0.36
</td>
<td style="text-align:right;">
0.015
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
Single outlier removal
</td>
<td style="text-align:left;">
0.18
</td>
<td style="text-align:right;">
0.047
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
Multiple outlier removal
</td>
<td style="text-align:left;">
0.13
</td>
<td style="text-align:right;">
0.051
</td>
<td style="text-align:right;">
no
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
Target lower
</td>
<td style="text-align:left;">
0.24
</td>
<td style="text-align:right;">
0.015
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
0.6
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;border-bottom: 2px solid black;">
Target higher
</td>
<td style="text-align:left;border-bottom: 2px solid black;">
0.24
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
0.015
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
yes
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
4
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
7
</td>
<td style="text-align:left;border-bottom: 2px solid black;">
3
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
Emotional value
</td>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Original
</td>
<td style="text-align:left;">
0.33
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
Ceiling change
</td>
<td style="text-align:left;">
0.17
</td>
<td style="text-align:right;">
0.020
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
d value change
</td>
<td style="text-align:left;">
0.33
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
p value change
</td>
<td style="text-align:left;">
0.33
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
Scope change
</td>
<td style="text-align:left;">
0.33
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
Single outlier removal
</td>
<td style="text-align:left;">
0.44
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
2.4
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
Multiple outlier removal
</td>
<td style="text-align:left;">
0.44
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
2.4
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
Target lower
</td>
<td style="text-align:left;">
0.33
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
1.1
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
3.5
</td>
</tr>
<tr>
<td style="text-align:left;border-bottom: 2px solid black;">
Target higher
</td>
<td style="text-align:left;border-bottom: 2px solid black;">
0.33
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
0.000
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
yes
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
0
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
0
</td>
<td style="text-align:left;border-bottom: 2px solid black;">
5
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
Adoption intention
</td>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:right;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
<td style="text-align:left;font-weight: bold;background-color: rgba(240, 240, 240, 255) !important;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Original
</td>
<td style="text-align:left;">
0.29
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
Ceiling change
</td>
<td style="text-align:left;">
0.20
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
5.7
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
d value change
</td>
<td style="text-align:left;">
0.29
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
p value change
</td>
<td style="text-align:left;">
0.29
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
Scope change
</td>
<td style="text-align:left;">
0.29
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
Single outlier removal
</td>
<td style="text-align:left;">
0.38
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
5.3
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
Multiple outlier removal
</td>
<td style="text-align:left;">
0.42
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
5.4
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
Target lower
</td>
<td style="text-align:left;">
0.29
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
yes
</td>
<td style="text-align:right;">
1.7
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;border-bottom: 2px solid black;">
Target higher
</td>
<td style="text-align:left;border-bottom: 2px solid black;">
0.29
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
0.000
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
yes
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
8
</td>
<td style="text-align:right;border-bottom: 2px solid black;">
14
</td>
<td style="text-align:left;border-bottom: 2px solid black;">
2
</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<p>Without discussing details, the general results of the NCA robustness table (Table <a href="dataanalysis.html#tab:robustcheckssem">4.3</a>) are as follows. The results for Perceived usefulness are robust with respect to the conclusion about necessity in kind. For necessity in degree only a change of ceiling line from CE-FDH to CR-FDH resulted in a different priority level (from first to second). Most single bottleneck cases can be found for this predictor. Generally, the original results for this predictor can be considered as robust. The same conclusion applies to Compatibility. The original conclusion about necessity in kind is stable and for all checks the priority level for action remains low. However, the results of Perceived ease of use are more variable. For example, the statistical significance of the original finding and therefore the conclusion of necessity is somewhat fragile. Also the number of bottleneck cases changes from 7 to 1 and is sensitive to small changes of the selected target level. The results for Emotional value and Adoption intention are relatively robust.</p>
<p>Note that the NCA robustness table is a tool for better understanding and communicating the credibility of the original results. The findings from the checks largely depend the the selected parameters for the checks. No hard rules exist to decide about the robustness or fragility of the results as this is a judgement by the researcher and others.</p>
<!-- ##### Choice of ceiling line -->
<!-- In the first robustness check, the originally selected ceiling line (CE-FDH) is changed towards the CR-FDH ceiling line. This line could have been selected as well if a linear assumption is made about the ceiling.  The effect of this change is shown in Table \@ref(tab:robustcheckssem). It turns out that the effect sizes of several predictors are somewhat smaller, but that they remain well above the original threshold of 0.1. The p values become somewhat larger but remain under the original threshold level of 0.05. These results  suggests that the results regarding necessity in kind are robust with respect to change of ceiling line. -->
<!-- ``` {r, echo=FALSE, eval = FALSE} -->
<!-- library(NCA) -->
<!-- # Original analysis -->
<!-- # General arguments -->
<!-- data <- dataset1 -->
<!-- ceilings = "ce_fdh" -->
<!-- test.rep = 10000 #set the number of permutations for estimating the p value -->
<!-- # Arguments for the bottleneck table -->
<!-- bottleneck.y = "actual" -->
<!-- bottleneck.x = "percentile" -->
<!-- steps=seq(0, 100, 5) -->
<!-- # Multiple NCA for Technology use with unstandardized latent variable scores -->
<!-- model_Original.technology <- nca_analysis(data, 1:5, 6, ceilings = ceilings, bottleneck.x = bottleneck.x , bottleneck.y = bottleneck.y, steps = steps, test.rep = test.rep) -->
<!-- # effect size and p value -->
<!-- model_Original.technology -->
<!-- # Bottlenecks -->
<!-- model <- model_Original.technology  -->
<!-- target.Y <- 85 -->
<!-- bottlenecks_technology <- get_bottleneck_cases(model, target.Y) -->
<!-- bottlenecks_technology -->
<!-- # Ceiling change: CR-FDH  -->
<!-- # General arguments -->
<!-- data <- dataset1 -->
<!-- ceilings = "cr_fdh" -->
<!-- test.rep = 10000 #set the number of permutations for estimating the p value -->
<!-- # Arguments for the bottleneck table -->
<!-- bottleneck.y = "actual" -->
<!-- bottleneck.x = "percentile" -->
<!-- steps=seq(0, 100, 5) -->
<!-- # Multiple NCA for Technology use with unstandardized latent variable scores -->
<!-- model_CR.technology <- nca_analysis(data, 1:5, 6, ceilings = ceilings, bottleneck.x = bottleneck.x , bottleneck.y = bottleneck.y, steps = steps, test.rep = test.rep) -->
<!-- # effect size and p value -->
<!-- model_CR.technology -->
<!-- # Bottlenecks -->
<!-- model <- model_CR.technology  -->
<!-- target.Y <- 85 -->
<!-- bottlenecks_technology <- get_bottleneck_cases(model, target.Y) -->
<!-- bottlenecks_technology -->
<!-- # Scope change: theoretical -->
<!-- # General arguments -->
<!-- data <- dataset1 -->
<!-- ceilings = "ce_fdh" -->
<!-- test.rep = 10000 #set the number of permutations for estimating the p value -->
<!-- # Arguments for the bottleneck table -->
<!-- bottleneck.y = "actual" -->
<!-- bottleneck.x = "percentile" -->
<!-- steps=seq(0, 100, 5) -->
<!-- # Multiple NCA for Technology use with unstandardized latent variable scores -->
<!-- model_Scope.technology <- nca_analysis(data,  -->
<!--                                        1:5, -->
<!--                                        6, -->
<!--                                        ceilings = ceilings, -->
<!--                                        bottleneck.x = bottleneck.x, -->
<!--                                        bottleneck.y = bottleneck.y, -->
<!--                                        steps = steps, -->
<!--                                        test.rep = test.rep, -->
<!--                                        scope = list(c(0,100,0,100),  -->
<!--                                                     c(0,100,0,100), -->
<!--                                                     c(0,100,0,100), -->
<!--                                                     c(0,100,0,100), -->
<!--                                                     c(0,100,0,100))) -->
<!-- model_Scope.technology -->
<!-- # Bottlenecks -->
<!-- model <- model_Scope.technology  -->
<!-- target.Y <- 85 -->
<!-- bottlenecks_technology <- get_bottleneck_cases(model, target.Y) -->
<!-- bottlenecks_technology -->
<!-- # Change scope: Outliers -->
<!-- data <- dataset1 -->
<!-- ceilings = "ce_fdh" -->
<!-- outliers.1 <- nca_outliers(data, 1, 6, ceiling = ceilings) -->
<!-- outliers.1 -->
<!-- outliers.2 <- nca_outliers(data, 2, 6, ceiling = ceilings) -->
<!-- outliers.2 -->
<!-- outliers.3 <- nca_outliers(data, 3, 6, ceiling = ceilings, plotly = TRUE) -->
<!-- outliers.3 -->
<!-- outliers.4 <- nca_outliers(data, 4, 6, ceiling = ceilings) -->
<!-- outliers.4 -->
<!-- outliers.5 <- nca_outliers(data, 5, 6, ceiling = ceilings) -->
<!-- outliers.5 -->
<!-- #Perceived ease of use -->
<!-- #   outliers eff.or eff.nw dif.abs dif.rel ceiling scope -->
<!-- # 1      19    0.24   0.15   -0.09   -37.1       X     X -->
<!-- data_Outlier1 <- dataset1[-19,] -->
<!-- data <- data_Outlier1 -->
<!-- ceilings = "ce_fdh" -->
<!-- test.rep = 10000 #set the number of permutations for estimating the p value -->
<!-- # General arguments -->
<!-- ceilings = "ce_fdh" -->
<!-- test.rep = 10000 #set the number of permutations for estimating the p value -->
<!-- # Arguments for the bottleneck table -->
<!-- bottleneck.y = "actual" -->
<!-- bottleneck.x = "percentile" -->
<!-- steps=seq(0, 100, 5) -->
<!-- # Multiple NCA for Technology use with unstandardized latent variable scores -->
<!-- model_Outlier1.technology <- nca_analysis(data, 1:5, 6, ceilings = ceilings, bottleneck.x = bottleneck.x , bottleneck.y = bottleneck.y, steps = steps, test.rep = test.rep) -->
<!-- # effect size and p value -->
<!-- model_Outlier1.technology -->
<!-- # Bottlenecks -->
<!-- model <- model_Outlier1.technology  -->
<!-- target.Y <- 85 -->
<!-- bottlenecks_technology <- get_bottleneck_cases(model, target.Y) -->
<!-- bottlenecks_technology -->
<!-- #multiple outliers -->
<!-- outliers.1 <- nca_outliers(data, 1, 6, ceiling = ceilings, k=2) -->
<!-- outliers.1 -->
<!-- outliers.2 <- nca_outliers(data, 2, 6, ceiling = ceilings, k=2) -->
<!-- outliers.2 -->
<!-- outliers.3 <- nca_outliers(data, 3, 6, ceiling = ceilings, k=2, plotly = TRUE) -->
<!-- outliers.3 -->
<!-- outliers.4 <- nca_outliers(data, 4, 6, ceiling = ceilings, k=2) -->
<!-- outliers.4 -->
<!-- outliers.5 <- nca_outliers(data, 5, 6, ceiling = ceilings, k=2) -->
<!-- outliers.5 -->
<!-- #Perceived ease of use -->
<!-- #     outliers eff.or eff.nw dif.abs dif.rel ceiling scope -->
<!-- # 1  19 - 103    0.24   0.08   -0.15   -63.9       X     X -->
<!-- data_Outlier2 <- dataset1[-c(19,103),] -->
<!-- data <- data_Outlier2 -->
<!-- ceilings = "ce_fdh" -->
<!-- test.rep = 10000 #set the number of permutations for estimating the p value -->
<!-- # General arguments -->
<!-- ceilings = "ce_fdh" -->
<!-- test.rep = 10000 #set the number of permutations for estimating the p value -->
<!-- # Arguments for the bottleneck table -->
<!-- bottleneck.y = "actual" -->
<!-- bottleneck.x = "percentile" -->
<!-- steps=seq(0, 100, 5) -->
<!-- # Multiple NCA for Technology use with unstandardized latent variable scores -->
<!-- model_Outlier2.technology <- nca_analysis(data, 1:5, 6, ceilings = ceilings, bottleneck.x = bottleneck.x , bottleneck.y = bottleneck.y, steps = steps, test.rep = test.rep) -->
<!-- # effect size and p value -->
<!-- model_Outlier2.technology -->
<!-- # Bottlenecks -->
<!-- model <- model_Outlier2.technology  -->
<!-- target.Y <- 85 -->
<!-- bottlenecks_technology <- get_bottleneck_cases(model, target.Y) -->
<!-- bottlenecks_technology -->
<!-- # Target 80 -->
<!-- # General arguments -->
<!-- data <- dataset1 -->
<!-- ceilings = "ce_fdh" -->
<!-- test.rep = 10000 #set the number of permutations for estimating the p value -->
<!-- # Arguments for the bottleneck table -->
<!-- bottleneck.y = "actual" -->
<!-- bottleneck.x = "percentile" -->
<!-- steps=seq(0, 100, 5) -->
<!-- # Multiple NCA for Technology use with unstandardized latent variable scores -->
<!-- model_Original.technology <- nca_analysis(data, 1:5, 6, ceilings = ceilings, bottleneck.x = bottleneck.x , bottleneck.y = bottleneck.y, steps = steps, test.rep = test.rep) -->
<!-- # effect size and p value -->
<!-- model_Original.technology -->
<!-- # Bottlenecks -->
<!-- model <- model_Original.technology  -->
<!-- target.Y <- 80 -->
<!-- bottlenecks_technology <- get_bottleneck_cases(model, target.Y) -->
<!-- bottlenecks_technology -->
<!-- # Target 90 -->
<!-- # General arguments -->
<!-- data <- dataset1 -->
<!-- ceilings = "ce_fdh" -->
<!-- test.rep = 10000 #set the number of permutations for estimating the p value -->
<!-- # Arguments for the bottleneck table -->
<!-- bottleneck.y = "actual" -->
<!-- bottleneck.x = "percentile" -->
<!-- steps=seq(0, 100, 5) -->
<!-- # Multiple NCA for Technology use with unstandardized latent variable scores -->
<!-- model_Original.technology <- nca_analysis(data, 1:5, 6, ceilings = ceilings, bottleneck.x = bottleneck.x , bottleneck.y = bottleneck.y, steps = steps, test.rep = test.rep) -->
<!-- # effect size and p value -->
<!-- model_Original.technology -->
<!-- # Bottlenecks -->
<!-- model <- model_Original.technology  -->
<!-- target.Y <- 90 -->
<!-- bottlenecks_technology <- get_bottleneck_cases(model, target.Y) -->
<!-- bottlenecks_technology -->
<!-- ``` -->
<!-- ##### Changing the Scope -->
<!-- In the second robustness check, the originally selected *empirical* scope (default) is changed towards the *theoretical* scope. One candidate theoretical scope is 0-100% corresponding the the 0-100 normalized Likert scales that were for measuring the predictor indicators.The effect of this change is shown in Table \@ref(tab:robustchecks). It turns out that only Perceived ease of use is affected by changing the scope. This corresponds to the earlier observation that the lowest end of the scale was not used fpr all three indicators of Perceived ease of use. A larger theoretical scope than the empirical scope normally results in an increase in the effect size. This is also the case here. Since the p values remain the same it can be concluded that the results are robust regarding necessity with respect to change of scope. -->
<!-- ##### Changing treatment of outliers -->
<!-- In the third robustness check, an outlier analysis is done to study the effect of removing potential outliers. The ```NCA``` software includes the function ```nca_outliers```, which evaluates one scatter plot at a time. It studies the influence of removing *k* outliers at a time on the effect size. In this demonstration first *k* = 1 is selected and then *k* = 2. The code is shown for Perceived ease of use. -->
<!-- ``` {r, echo = TRUE} -->
<!-- data <- dataset1 -->
<!-- ceilings = "ce_fdh" -->
<!-- outliers.3 <- nca_outliers(data, 3, 6, ceiling = ceilings, plotly = TRUE) -->
<!-- outliers.3 -->
<!-- ``` -->
<!-- The potential outliers are ranked according the their largest influence on the effect size of removed. It turns out that case 19 is the largest potential outlier that reduces the effect size by 37.1% when this case is removed. Case 19 is both a ceiling and a scope outlier. -->
<!-- First the most one outlier is i -->
<!-- the originally selected *empirical* scope (default) is changed towards the *theoretical* scope. One candidate theoretical scope is 0-100% corresponding the the 0-100 normalized Likert scales that were for measuring the predictor indicators.The effect of this change is shown in Table \@ref(tab:robustchecks). It turns out that only Perceived ease of use is affected by changing the scope. This corresponds to the earlier observation that the lowest end of the scale was not used fpr all three indicators of Perceived ease of use. A larger theoretical scope than the empirical scope normally results in an increase in the effect size. This is also the case here. Since the p values remain the same it can be concluded that the results are robust regarding necessity with respect to change of scope. -->
<!-- ##### Changing the target outcome -->
<!-- ``` {r, echo = TRUE, eval = FALSE} -->
<!-- # cIPMA target output 80% -->
<!-- model <- model3.technology # model made by nca_analysis with bottleneck.x = 'percentile' -->
<!-- target.Y <- 80 -->
<!-- bottlenecks_technology <- get_bottleneck_cases(model, target.Y) -->
<!-- CIPMA_df_technology <- CIPMA_df(IPMA_df = IPMA_df, bottlenecks = bottlenecks_technology) -->
<!-- cipma80 <- cIPMA_plot(CIPMA_df_technology) -->
<!-- ``` -->
<!-- ``` {r, echo=FALSE, cache=TRUE, include=FALSE, eval = FALSE, out.width='90%'} -->
<!-- pdf("cipma80.pdf", 5,5) -->
<!-- cipma80 -->
<!-- dev.off() -->
<!-- ``` -->
<!-- ```{r cipma80, echo=FALSE, out.width='70%', fig.align = "center", fig.cap="Combined Impotance Performance Map Analysis (cIPMA) for the outcome Technology use. The size of the dots is an indication of the number of cases that cannot achieve the target outcome of 85% of maximum outcome.", cache=TRUE} -->
<!-- knitr::include_graphics('cipma80.png') -->
<!-- ``` -->
<!-- ``` {r, echo = TRUE, eval = FALSE} -->
<!-- # cIPMA target output 90% -->
<!-- model <- model3.technology # model made by nca_analysis with bottleneck.x = 'percentile' -->
<!-- target.Y <- 90 -->
<!-- bottlenecks_technology <- get_bottleneck_cases(model, target.Y) -->
<!-- CIPMA_df_technology <- CIPMA_df(IPMA_df = IPMA_df, bottlenecks = bottlenecks_technology) -->
<!-- cipma90 <- cIPMA_plot(CIPMA_df_technology) -->
<!-- ``` -->
<!-- ``` {r, echo=FALSE, cache=TRUE, include=FALSE, eval = FALSE, out.width='90%'} -->
<!-- pdf("cipma90.pdf", 5,5) -->
<!-- cipma90 -->
<!-- dev.off() -->
<!-- ``` -->
<!-- ```{r cipma90, echo=FALSE, out.width='70%', fig.align = "center", fig.cap="Combined Impotance Performance Map Analysis (cIPMA) for the outcome Technology use. The size of the dots is an indication of the number of cases that cannot achieve the target outcome of 90% of maximum outcome.", cache=TRUE} -->
<!-- knitr::include_graphics('cipma90.png') -->
<!-- ``` -->
<!-- ```{r twocipma, echo=FALSE, cache=TRUE, include=FALSE, eval = FALSE, out.width='90%'} -->
<!-- library(ggplot2) -->
<!-- library(gridExtra) -->
<!-- plot1 <- cipma90 -->
<!-- plot2 <- cipma80 -->
<!-- pdf("cipma8090.pdf") -->
<!-- grid.arrange(plot1, plot2, ncol = 2) -->
<!-- dev.off() -->
<!-- ``` -->
<!-- Afterwards the results are summarized in the Robustness table. The general Robustness table for NCA introduced in Section \@ref() is adapted by focusing in single bottlenecks per predictor to facilitate the interpretation of BIPMA.   -->
<!-- <!-- ```{r cipma8090, echo=FALSE, out.width='70%', fig.align = "center", fig.cap="Combined Impotance Performance Map Analysis (cIPMA) for the outcome Technology use. The size of the dots is an indication of the number of cases that cannot achieve the target outcome of 85% of maximum outcome.", cache=TRUE} -->
<!-- <!-- knitr::include_graphics('cipma8090.png') -->
<!-- <!-- ``` -->
<!-- #END###RESET#REMOVE##########DO NOT RUN##################### -->
</div>
</div>
<div id="recommendations-for-combining-nca-and-pls-sem" class="section level3 hasAnchor" number="4.6.3">
<h3><span class="header-section-number">4.6.3</span> Recommendations for combining NCA and (PLS-)SEM<a href="dataanalysis.html#recommendations-for-combining-nca-and-pls-sem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In publications where NCA is applied in combination with (PLS-)SEM, usually (PLS-)SEM is the main analysis and NCA is used as an additional analysis. However, several guidelines for applying NCA are often violated. This applies, for example, to the following recommendations with ‘must-have’ or ‘should-have’ priority level (see the checklist in Section <a href="summary.html#review">1.8</a>):</p>
<ul>
<li><p>Checklist item 4: <em>“When comparing necessity (causal) logic and NCA with causal interpretations of conventional regression-based/statistical approaches, use the term “probabilistic sufficiency” and not just “sufficiency” for the latter approaches, as “sufficiency” suggests (quasi-)determinism, like in QCA configurational sufficiency logic. This recommendation is often violated in studies that combine NCA with PLS-SEM. […]“</em>.
The results of regression analysis (path coefficients of the structural model) are often interpreted as ‘sufficiency’, whereas sufficiency (like necessity) refers to deterministic causal logic and not to the probabilistic causal logic. A better description of the presumed causal relationships of the structural model (like any relationship that is analysed with regression analysis) would be ‘probabilistic sufficiency’ <span class="citation">(<a href="#ref-dul2024different">Dul, 2024a</a>)</span>.</p></li>
<li><p>Checklist item 7: <em>“Formulate the necessity relationship explicitly as a necessary condition hypothesis:”X is necessary for Y”. For hypothesis testing research this is done before data analysis; for hypothesis building/exploration research this is done after data analysis when a potential necessity relationship is found.”</em>
In studies that combine NCA with (PLS-)SEM often well-founded probabilistic sufficiency hypotheses are formulated (to be tested with the structural (PLS-)SEM model). However, necessity hypotheses are missing. Formulating necessity hypotheses is a requirement since the necessity causal perspective differs from the probabilistic sufficiency causal perspective. This applies also to studies that use NCA for exploration or as an additional analysis. A good practice is to formulate necessity hypotheses prior to conducting the analysis, just as is done with probabilistic sufficiency hypotheses.</p></li>
<li><p>Checklist item 9: <em>“Explain why X is necessary for Y using necessity logic (why cases with the outcome will almost always have the condition (if Y then X); why cases without the condition rarely have the outcome (if no X then no Y); why the absence of the condition cannot be compensated or substituted by another factor. Consider doing and reporting the results of a thought experiment (searching for exceptions) in the development of a necessity hypothesis. Note that formulating and justifying a necessity relationship is a creative process, supported by literature and experiences of academics and practitioners.”</em>
This often violated recommendation is related to the previous one. Even if a necessity hypothesis is formulated, it should also be explained <strong>why</strong> it is expected that X is necessary for Y (the theoretical necessity mechanism).</p></li>
<li><p>Checklist item 18: <em>“Explain possible data transformations. NCA only allows linear data transformation (e.g., min-max transformation, normalization, standardization, or percentage transformation), unless non-linear transformed data validly represent X and Y of the hypothesis. NCA’s data analysis does not require data transformation. Often non-transformed data are more meaningful and better interpretable (e.g., levels of a Likert scale) than transformed data. This particularly applies to NCA’s necessity in degree for interpreting that a certain level of X is necessary for a certain level of Y. Do not conduct non-linear data transformation (e.g., log-transformation, logistic transformation) unless only the transformed X or Y represent the concepts X and Y in the necessity hypothesis. […]”.</em>
In most applications of (PLS-)SEM, latent variable scores are standardized (centering the data around zero and scaling the data to have a standard deviation of one). For proper interpretation of necessity in degree (bottleneck table) the use of unstandardized scores is more meaningful. Unstandardized scores are closer related to the original measurement scale than standardized scores, which makes interpretations of levels more meaningful.</p></li>
<li><p>Checklist item 21: <em>“Specify and justify the primary selection of the ceiling line (e.g., CE-FDH when X or Y is discrete or when the ceiling line is expected to be non-linear; CR-FDH when X and Y are continuous or when the ceiling line is expected to be straight).”</em>
Often no justification is given for the selection of the ceiling line. The CE-FDH ceiling line is commonly selected without further explanation, possibly because this line was used for good reasons in the original publication that introduced NCA in the (PLS-)SEM context <span class="citation">(<a href="#ref-richter2020predictors">Richter, Schubring, et al., 2020</a>)</span>. However, this reason might not apply in other situations. Similarly, when the two default ceiling lines (CE-FDH and CR-FDH) are used no explanation is given for this selection.</p></li>
<li><p>Checklist item 28: <em>“Show in the main text or an appendix the XY tables or XY plots of all tested/explored relationships such that the reader can inspect the patterns.”</em>
Often not all scatter plots of tested necessity relationships are presented. Sometime no scatter plots, or only scatter plots of supported necessity relationships are shown.</p></li>
<li><p>Checklist item 30: <em>“Conclude about necessity in kind using three criteria: 1. theoretical justification (the hypothesis); 2. Effect size large enough (above the selected threshold value), p value small enough (below the selected threshold value).”</em>
In many studies not all three criteria for concluding about necessity (theoretical support, large effect size, small p value) are taken into consideration. Often the requirement of theoretical support is lacking (see above checklist items 7 and 9). Usually only theoretical support for the probabilistic sufficiency relationships of the structural model is provided, but this is not informative about the necessity relationship. Without theoretical support for a necessity relationship, it is impossible to conclude that a necessity relationship was identified, even if the effect size was large enough, and the p value small enough.</p></li>
<li><p>Checklist item 34: <em>“Summarize the results of the robustness checks: is the conclusion about necessity sensitive for choices by the researcher regarding ceiling line, effect size threshold, p value threshold, scope (theoretical, empirical), and removing/keeping outliers (ceiling and scope outliers). Conclude if the results are robust or fragile.”</em>
In many studies a robustness check is done for the (PLS-)SEM part of the study, but not for the NCA part. Robustness checks for NCA are different than those for (PLS-)SEM, and equally important. For example, outliers for (PLS-)SEM may not be outliers for NCA and vice-versa. NCA’s outlier analysis can be done with the NCA software in R (see Section <a href="dataanalysis.html#examplencaplssem">4.6.2</a> for an example).</p></li>
<li><p>Checklist item 38: <em>“When NCA is used in combination with another methods (e.g., regression-based methods or QCA), report how the results of NCA and of the other method complement each other.”</em>
In many studies (PLS-)SEM results and NCA results are presented separately without discussing the insights that obtained from combining them. The discussion could focus on the consequences of the combined results for theory and practice. The use of BIPMA (see Section <a href="dataanalysis.html#producebipma">4.6.1.5</a>), an extended version of CIPMA <span class="citation">(<a href="#ref-hauff2024importance">Hauff et al., 2024</a>)</span> could be helpful to integrate the results.</p></li>
</ul>
<p>The quality of studies that combine NCA with (PLS-)SEM could be enhanced by ensuring that these ‘must-have’ recommendations are fulfilled. Once the foundational requirements are met, further improvements can be achieved by addressing the ‘should-have’ and ‘nice-to-have’ recommendations in the checklist (Section <a href="summary.html#review">1.8</a>). As the number of combined NCA and (PLS-)SEM studies grows, reviewers may raise the standard for the appropriate application of NCA. The checklist includes references that support the implementation of the recommendations.</p>
</div>
</div>
<div id="ncaqca" class="section level2 hasAnchor" number="4.7">
<h2><span class="header-section-number">4.7</span> Combining NCA with QCA<a href="dataanalysis.html#ncaqca" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- see: [NCA website](https://www.erim.eur.nl/necessary-condition-analysis/about-nca/faq/nca-and-other-data-analysis-methods/nca-and-qca/). -->
<div id="introduction-to-qca" class="section level3 hasAnchor" number="4.7.1">
<h3><span class="header-section-number">4.7.1</span> Introduction to QCA<a href="dataanalysis.html#introduction-to-qca" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="history-of-qca" class="section level4 hasAnchor" number="4.7.1.1">
<h4><span class="header-section-number">4.7.1.1</span> History of QCA<a href="dataanalysis.html#history-of-qca" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Qualitative Comparative Analysis (QCA) has its roots in political science and sociology, and
was developed by Charles Ragin <span class="citation">(<a href="#ref-ragin1987comparative">Ragin, 1987</a>, <a href="#ref-ragin2000fuzzy">2000</a>, <a href="#ref-ragin2009redesigning">2008</a>)</span>. QCA has steadily evolved and used over
the years, and currently many types of QCA approaches exist. A common interpretation of
QCA is described by <span class="citation">Schneider &amp; Wagemann (<a href="#ref-schneider2012set">2012</a>)</span> and <span class="citation">Mello (<a href="#ref-mello2021qualitative">2021</a>)</span>, which I follow in this book.</p>
</div>
<div id="logic-and-theory-of-qca" class="section level4 hasAnchor" number="4.7.1.2">
<h4><span class="header-section-number">4.7.1.2</span> Logic and theory of QCA<a href="dataanalysis.html#logic-and-theory-of-qca" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Set theory is in the core of QCA. It means that relations between sets, rather than relations
between variables are studied. A case can be part of a set or not part of the set. For example,
the Netherlands is a case (of all countries) that is ‘in the set’ of rich countries, and Ethiopia is
a case that is ‘out of the set’ of rich countries. Set membership scores (rather than variable
scores) are linked to a case. Regarding the set of rich countries, the Netherlands has a set
membership score of 1 and Ethiopia of 0. In the original version of QCA the set membership
scores could only be 0 or 1. This version of QCA is called crisp-set QCA. Later also fuzzy-set
QCA (fsQCA) was developed. Here the membership scores can also have values between 0
and 1. For example, Croatia could be allocated a set membership score of 0.7 indicating that
it is ‘more in the set’ than ‘out of the set’ of rich countries.
In QCA relations between sets are studied. Suppose that one set is the set of rich countries
(<span class="math inline">\(X\)</span>), and another set is the set of countries with happy people (‘happy countries’, <span class="math inline">\(Y\)</span>). QCA uses
Boolean (binary) algebra and expresses the relationship between condition <span class="math inline">\(X\)</span> and outcome <span class="math inline">\(Y\)</span>
as the presence or absence of <span class="math inline">\(X\)</span> is related to the presence or absence of <span class="math inline">\(Y\)</span>. More specifically,
the relations are expressed in terms of sufficiency and necessity. For example, the presence
of X (being a country that is part of the set of rich countries) could be theoretically stated as
sufficient for the presence of <span class="math inline">\(Y\)</span> (being a country that is part of the set of happy countries). All
rich countries are happy countries. The set of rich countries is a subset of the set of happy
countries. No rich country is not a happy country. Set <span class="math inline">\(X\)</span> is a subset of set <span class="math inline">\(Y\)</span>. Alternatively, in
another theory it could be stated that the presence of <span class="math inline">\(X\)</span> (being country that is part of the set
of rich countries) is necessary for the presence of <span class="math inline">\(Y\)</span> (being a country that is part of the set of
happy countries). All happy countries are rich countries. The set of happy countries is a
superset of the set of rich countries. No happy country is not a rich county. Set <span class="math inline">\(X\)</span> is a superset
of set <span class="math inline">\(Y\)</span>.
QCA’s main interest is about sufficiency. QCA assumes that a configuration of single
conditions produces the outcome. For example, the condition of being in the set of rich
countries (<span class="math inline">\(X_1\)</span>) AND the condition of being in the set of democratic countries (<span class="math inline">\(X_2\)</span>) is sufficient
for the outcome of being in the set of happy countries (<span class="math inline">\(Y\)</span>).
QCA’s Boolean logic statements for this sufficiency relationship is expressed as follows:</p>
<p><span class="math display" id="eq:qca1">\[\begin{equation}
\tag{4.3}
X_1*X_2 → Y
\end{equation}\]</span></p>
<p>where the symbol ‘<span class="math inline">\(*\)</span>’ means the logical ‘AND’, and the symbol ‘<span class="math inline">\(→\)</span>’ means ‘is sufficient for’.</p>
<p>Furthermore, QCA assumes that several alternative configurations may exits that can
produce the outcome, known as ‘equifinality’. This is expressed in the following example:</p>
<p><span class="math display" id="eq:qca2">\[\begin{equation}
\tag{4.4}
X_1*X_2 + X_2*X_3*X_4 → Y
\end{equation}\]</span></p>
<p>where the symbol ‘<span class="math inline">\(+\)</span>’ means the logical ‘OR’.</p>
<p>It is also possible that the absence of a condition
is part of a configuration. This is shown in the following example:</p>
<p><span class="math display" id="eq:qca3">\[\begin{equation}
\tag{4.5}
X_1*X_2 + X_2*{\sim}X_3*X_4 → Y
\end{equation}\]</span></p>
<p>where the symbol ‘<span class="math inline">\(\sim\)</span>’ means ‘absence of’.</p>
<p>Single conditions in a configuration that is sufficient for the outcome are called INUS conditions <span class="citation">(<a href="#ref-mackie1965causes">Mackie, 1965</a>)</span>. An INUS condition is an ‘Insufficient but Non-redundant (i.e., Necessary) part of an Unnecessary but Sufficient condition.’ In this expression, the words ‘part’ and ‘condition’ are somewhat confusing because ‘part’ refers to the single condition and ‘condition’ refers to the configuration that consists of single conditions. Insufficient refers to the fact that a part (single condition) is not itself sufficient for the outcome. Non-redundant refers to the necessity of the part (single condition) for the configurations being sufficient for the outcome. Unnecessary refers to the possibility that also other configurations can be sufficient for the outcome. Sufficient refers to the fact that the configuration is sufficient for the outcome. Although a single condition may be locally necessary for the configuration to be sufficient for the outcome, it is not globally necessary for the outcome because the single condition may be absent in another sufficient configuration. INUS conditions are thus usually not necessary conditions for the outcome (the latter are the conditions that NCA considers). Hence, in above generic logical statements about relations between sets, see Equations <a href="dataanalysis.html#eq:qca1">(4.3)</a>, <a href="dataanalysis.html#eq:qca2">(4.4)</a>, <a href="dataanalysis.html#eq:qca3">(4.5)</a>, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> can only be absent of present (Boolean algebra), even though the individual members of the sets can have fuzzy scores. Both csQCA and fsQCA use only binary levels (absent or present) of the condition and the outcome when formulating the solution. In fsQCA absence means set membership scores &lt; 0.5 and presence means set membership scores &gt; 0.5.</p>
</div>
<div id="data-and-data-analysis-of-qca" class="section level4 hasAnchor" number="4.7.1.3">
<h4><span class="header-section-number">4.7.1.3</span> Data and data analysis of QCA<a href="dataanalysis.html#data-and-data-analysis-of-qca" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The starting point of the QCA data analysis is to transform variable scores into set membership scores. The transformation process is called ‘calibration’. Calibration can be based on the distribution of the data, the measurement scale, or expert knowledge.
The goal of calibration is to get scores of 0 or 1 (csQCA) or between 0 and 1 (fsQCA) to represent the extent to which the case belongs to the set (set membership score). Particularly in large <span class="math inline">\(N\)</span> fsQCA studies and in the business and management field ‘mechanistic’ (data driven) transformation is often done. For this transformation the non-linear logistic function is usually selected. This selection is somewhat arbitrary (build in popular QCA software) and moves the variable scores to the extremes (0 and 1) in comparison to just (linear) normalization of the data: low values move to 0 and high values move to 1. When no substantive reason exists for the logistic transformation, I have proposed <span class="citation">(<a href="#ref-dul2016orm">Dul, 2016b</a>)</span> to use a transformation by normalization. This transformation keeps the distribution of the data intact. The reason for my proposal is that moving the scores to the extremes implies that cases in the <span class="math inline">\(XY\)</span> scatter plot with low to middle values of <span class="math inline">\(X\)</span> move to the left and cases with middle to high values of <span class="math inline">\(Y\)</span> move upwards. As a result, the upper left corner is more filled with cases. Consequently, potential meaningful empty spaces in the original data (indicating necessity) may not be identifiable. With the transformation by normalization, the cases stay where they are; an empty space in a corner of the <span class="math inline">\(XY\)</span> plot with the original data stays empty. The transformation by normalization is an alternative to an arbitrary transformation: it just changes variable score into set membership scores, without affecting the distribution of the data. A calibration evaluation tool to check the effect of calibration on the necessity effect size is available at <a href="https://r.erim.eur.nl/r-apps/qca/" class="uri">https://r.erim.eur.nl/r-apps/qca/</a>.</p>
<!-- <iframe src="https://r.erim.eur.nl/r-apps/qca/" width="100%" height="1600" frameborder="0"></iframe> -->
<p>QCA performs two separate analyses with calibrated data: a necessity analysis for identifying (single) necessary conditions, and a sufficiency analysis (‘truth table’ analysis) for identifying sufficient configurations. In this book I focus on the necessary condition analysis of single necessary conditions, which precedes the sufficiency analysis.
In csQCA the necessity analysis is similar to a dichotomous necessary condition analysis of NCA with the contingency table approach when <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are dichotomous set membership scores that can only be present (in the set) or absent (not in the set). By visual inspection of the contingency table a necessary condition ‘in kind’ can be identified when the upper left cell is empty (Figure <a href="dataanalysis.html#fig:qcanca1">4.21</a>) using set membership scores 0
and 1.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:qcanca1"></span>
<img src="Figure%201.png" alt="Necessity analysis by dichotomous NCA and crist set QCA." width="100%" />
<p class="caption">
Figure 4.21: Necessity analysis by dichotomous NCA and crist set QCA.
</p>
</div>
<p>For fuzzy set membership scores the necessity analyses of fsQCA and NCA differ. In fsQCA a diagonal is drawn in the <span class="math inline">\(XY\)</span> scatter plot (Figure <a href="dataanalysis.html#fig:qcanca2">4.22</a>A) with data from <span class="citation">Rohlfing &amp; Schneider (<a href="#ref-rohlfing2013improving">2013</a>)</span>; see also <span class="citation">Vis &amp; Dul (<a href="#ref-vis2018analyzing">2018</a>)</span>). For necessity, there can be no cases above the diagonal. Necessity consistency is a measure of the extent to which cases are not above the diagonal, which can range from 0 to 1. When some cases are present in the ‘empty’ zone above the diagonal, fsQCA considers these cases as ‘deviant cases’. FsQCA accepts some deviant cases as long as the necessity consistency level, which is computed from the total vertical distances of the deviant cases to the diagonal, is not smaller than a certain threshold, usually 0.9. The necessity consistency is large enough, fsQCA makes a qualitative (‘in kind’) statement about the necessity of <span class="math inline">\(X\)</span> for <span class="math inline">\(Y\)</span>: ‘<span class="math inline">\(X\)</span> is necessary for <span class="math inline">\(Y\)</span>’, e.g., the presence of <span class="math inline">\(X\)</span> (membership score &gt; 0.5) is necessary for the presence of <span class="math inline">\(Y\)</span> (membership score &gt; 0.5).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:qcanca2"></span>
<img src="Figure%202AB.png" alt="Comparison of necessity analysis with fsQCA’s (A) and with NCA (B). " width="100%" />
<p class="caption">
Figure 4.22: Comparison of necessity analysis with fsQCA’s (A) and with NCA (B).
</p>
</div>
</div>
</div>
<div id="the-differences-between-nca-and-qca" class="section level3 hasAnchor" number="4.7.2">
<h3><span class="header-section-number">4.7.2</span> The differences between NCA and QCA<a href="dataanalysis.html#the-differences-between-nca-and-qca" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The major differences between NCA and QCA are summarized in Figure <a href="dataanalysis.html#fig:table1ncaqca">4.23</a> (see also <span class="citation">Dul (<a href="#ref-dul2016jbr">2016a</a>)</span> and <span class="citation">Vis &amp; Dul (<a href="#ref-vis2018analyzing">2018</a>)</span>) and discussed below.</p>
<!-- ```{r, echo = FALSE, warning=FALSE, message=FALSE, include=TRUE} -->
<!-- library("kableExtra") -->
<!-- g <- read.csv("DifferencesNCAQCA.csv")  -->
<!-- kbl(g, caption = "Basic guidelines for good NCA practice", longtable = TRUE, align = c("l", "l", "l")) %>% -->
<!--   kable_styling() -->
<!--     # kable_paper("striped", full_width = F) %>% -->
<!--   # pack_rows("Theoretical justification", 1,3) %>% -->
<!--   # pack_rows("Meaningful data", 4, 4) %>% -->
<!--   # pack_rows("Scatter plot", 5, 6) %>% -->
<!--   # pack_rows("Ceiling line", 7, 7) %>% -->
<!--   # pack_rows("Effect size", 8, 9) %>% -->
<!--   # pack_rows("Statistical test", 10, 11) %>% -->
<!--   # pack_rows("Bottleneck analysis (necessity in degree)", 12, 17) %>% -->
<!--   # pack_rows("Descriptions of NCA", 18, 26)  -->
<!-- ``` -->
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:table1ncaqca"></span>
<img src="Table1ncaqcav2.png" alt="Comparison of NCA and QCA." width="100%" />
<p class="caption">
Figure 4.23: Comparison of NCA and QCA.
</p>
</div>
<div id="logic-and-theory-1" class="section level4 hasAnchor" number="4.7.2.1">
<h4><span class="header-section-number">4.7.2.1</span> Logic and theory<a href="dataanalysis.html#logic-and-theory-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>NCA and QCA are only the same in a very specific situation of ‘in kind’ necessity: A single <span class="math inline">\(X\)</span> is
necessary for <span class="math inline">\(Y\)</span>, and <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are dichotomous set membership scores (0 and 1). Then the
analyses of NCA and QCA are exactly the same. However, NCA normally uses variable scores,
but can also set membership scores when NCA is applied in combination with QCA (see
below). In addition to the ‘in kind’ necessity that both methods share, NCA also formulates
‘in degree’ necessity. QCA also formulates ‘in kind’ necessity of ‘OR’ combinations of
conditions, as well as ‘in kind’ sufficiency of configurations of conditions.
The main interest of NCA is the necessity ‘in degree’ of single factors that enable the outcome,
whereas the main interest of QCA is the sufficiency ‘in kind’ of (alternative) configurations of
conditions.</p>
</div>
<div id="data-and-data-analysis" class="section level4 hasAnchor" number="4.7.2.2">
<h4><span class="header-section-number">4.7.2.2</span> Data and data analysis<a href="dataanalysis.html#data-and-data-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Regarding research strategy most NCA studies are observational studies (both small N and large N), although also experiments are possible. Most QCA studies are small N observational studies, although increasingly also large N studies are employed with QCA, in particular in the business and management area. The experimental research strategy is rare (if not absent) in QCA. Regarding case selection/sampling purposive sampling is the main case selection strategy in QCA. It is also possible in small N NCA studies. For large N studies sampling strategies such as those used in regression analysis (preferably probability sampling) are used both in NCA and QCA. Regarding measurement, NCA uses valid and reliable variable scores unless it is used in combination with QCA, in which case NCA uses calibrated set membership scores. QCA uses calibrated set membership scores and cannot use variable scores. In QCA data with variable scores may be used as input for the ‘calibration’ process to transform variable scores into set membership scores. Regarding data analysis in fsQCA a necessary condition is assumed to exist if the area above the diagonal reference line in an <span class="math inline">\(XY\)</span> scatter plot is virtually empty (see Figure <a href="dataanalysis.html#fig:qcanca2">4.22</a> A). In contrast, NCA uses the ceiling line as the reference line (see Figure <a href="dataanalysis.html#fig:qcanca2">4.22</a> B) for evaluating the necessity of <span class="math inline">\(X\)</span> for <span class="math inline">\(Y\)</span> (with possibly some cases above the ceiling line; accuracy below 100%). In situations where fsQCA observes ‘deviant cases’, NCA includes these cases in the analysis by ‘moving’ the reference line from the diagonal position to the boundary between the zone with cases and the zone without cases. <span class="citation">(Note that moving the QCA’s diagonal parallel upward to address inaccuracy has been suggested by <a href="#ref-ragin2000fuzzy">Ragin, 2000</a> (p. 225, Figure 8.4), but this was not followed up by other QCA researchers)</span>. NCA considers cases around the ceiling line (and usually above the diagonal) as ‘best practice’ cases rather than ‘deviant’ cases. These cases are able to reach a high level of outcome (e.g., an output that is desired) for a relatively low level of condition (e.g., an input that requires effort). For deciding about necessity, NCA evaluates the size of the ‘empty’ zone as a fraction of the total zone (empty plus full zone), which ratio is called the necessity effect size. If the effect size is greater than zero (an empty zone is present), and if according to NCA’s statistical test this is unlikely a random result of unrelated <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, NCA identifies a necessary condition ‘in kind’ that can be formulated as: ‘<span class="math inline">\(X\)</span> is necessary for <span class="math inline">\(Y\)</span>’, indicating that for at least a part of the range of <span class="math inline">\(X\)</span> and the range of <span class="math inline">\(Y\)</span> a certain level of <span class="math inline">\(X\)</span> is necessary for a certain level of Y. Additionally, NCA can quantitatively formulate necessary condition ‘in degree’ by using the ceiling line: ‘level <span class="math inline">\(X_c\)</span> of <span class="math inline">\(X\)</span> is necessary for level <span class="math inline">\(Y_c\)</span> of <span class="math inline">\(Y\)</span>’. The ceiling line represents all combinations <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> where <span class="math inline">\(X\)</span> is necessary for <span class="math inline">\(Y\)</span>. Although also fsQCA’s diagonal reference line allows for making quantitative necessary conditions statements, e.g., <span class="math inline">\(X\)</span> &gt; 0.3 is necessary for <span class="math inline">\(Y\)</span> = 0.3, fsQCA does not make such statements.
When the ceiling line coincides with the diagonal (corresponding to the situation that fsQCA considers) the statement ‘<span class="math inline">\(X\)</span> is necessary for <span class="math inline">\(Y\)</span>’ applies to all <span class="math inline">\(X\)</span>-levels [0,1] and all <span class="math inline">\(Y\)</span>-levels [0,1]
and the results of the qualitative necessity analysis of fsQCA and NCA are the same. When the ceiling line is positioned above the diagonal ‘<span class="math inline">\(X\)</span> is necessary for <span class="math inline">\(Y\)</span>’ only applies to a specific range of <span class="math inline">\(X\)</span> and a specific range of <span class="math inline">\(Y\)</span>. Outside these ranges <span class="math inline">\(X\)</span> is not necessary for <span class="math inline">\(Y\)</span> (‘necessity inefficiency’). Then the results of the qualitative necessity analysis of fsQCA and NCA can be different.
Normally, NCA identifies more necessary conditions than fsQCA, mostly because the diagonal is used as reference line. In the example of Figure <a href="dataanalysis.html#fig:qcanca2">4.22</a>, NCA identifies that <span class="math inline">\(X\)</span> is necessary for <span class="math inline">\(Y\)</span> because there is an empty zone above the ceiling line. However, fsQCA would conclude that <span class="math inline">\(X\)</span> is not necessary for <span class="math inline">\(Y\)</span>, because the necessity consistency level is below 0.9. FsQCA’s necessity analysis can be considered as a special case of NCA: an NCA analysis with discrete or continuous fuzzy set membership scores for <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, a ceiling line that is diagonal, an allowance of a specific number of cases in the empty zone given by the necessity consistency threshold, and the formulation of a qualitative ‘in kind’ necessity statement.</p>
</div>
</div>
<div id="recommendation-for-combining-nca-and-qca" class="section level3 hasAnchor" number="4.7.3">
<h3><span class="header-section-number">4.7.3</span> Recommendation for combining NCA and QCA<a href="dataanalysis.html#recommendation-for-combining-nca-and-qca" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Although in most NCA applications variable scores are used for quantifying condition <span class="math inline">\(X\)</span> and outcome <span class="math inline">\(Y\)</span>, NCA can also employ set membership scores for the conditions and the outcome, allowing to combine NCA and QCA. The other way around is not possible: combining QCA to a regular NCA with variable scores is not possible because QCA is a set theoretic approach that does not use variable scores.
How can NCA with membership scores complement QCA? For answering this question first another question should be raised: how does QCA integrate an identified necessary condition in kind with the results of the sufficiency analysis: the identified sufficient configurations. By definition the necessary condition must be part of all sufficient configurations, otherwise this configuration cannot produce the outcome. However, within the QCA community five different views exist about how to integrate necessary conditions in sufficiency solution. In the first view only sufficient configurations that include the necessary conditions are considered as a result. Hence, all selected configurations have the necessary condition. In the second view the truth table analysis to find the sufficient configurations are done without the necessary conditions and afterwards the necessary conditions are added to the configuration. This also ensures that all configurations have the necessary conditions. In the third view configurations that do not include the necessary condition are excluded from the truth table before this table is further analysed to find the sufficient configurations. This ‘ESA’ approach <span class="citation">(<a href="#ref-schneider2012set">Schneider &amp; Wagemann, 2012</a>)</span> also ensures that all configurations have the necessary conditions. In the fourth view sufficient configurations are analysed without worrying about necessary conditions. Afterwards, the necessary conditions are discussed separately. In the fifth view a separate necessity analysis is not done, or necessity is ignored. All views have been employed in QCA; hence no consensus exists yet. And additional complexity of integrating necessity with sufficient configuration is that NCA produces necessary conditions in degree, rather than QCA’s necessary condition and sufficient configurations in kind. The conditions that are part of the sufficient configurations can only be absent or present.
Given these complexities, I suggest, a combination of the second and the fourth view:</p>
<ol style="list-style-type: decimal">
<li><p>Perform the NCA analysis ‘in degree’ before QCA’s sufficiency analysis.</p></li>
<li><p>Integrate a part of the results of NCA’s necessity analysis into QCA’s sufficient configurations, namely the conditions (‘in degree’) that are necessary for outcome &gt; 0.5. (use the NEST Tool: the NCA-Extended Solution Table, which adds a column to QCA’s solution table based on NCA results)</p></li>
<li><p>Discuss the full results of NCA’s necessity analysis afterwards.</p></li>
</ol>
<p>In particular it could be discussed that specific levels of necessary membership scores found by NCA must be present in each sufficient configuration found by QCA. If that membership in degree is not in place, the configuration will not produce the outcome.</p>
</div>
<div id="examples" class="section level3 hasAnchor" number="4.7.4">
<h3><span class="header-section-number">4.7.4</span> Examples<a href="dataanalysis.html#examples" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>I discuss two examples of integrating NCA in QCA according to this recommendation.
The first example is a study by Emmenegger (2011) about the effects of six conditions: S = state-society relationships, C = non-market coordination, L = strength labour movement, R = denomination, P = strength religious parties and V = veto points on JSR = job security regulation in Western European countries. He performed an fsQCA analysis with a necessity analysis and a sufficiency analysis. His necessity analysis showed that no condition was necessary for job security regulation (necessity consistency of each condition was &lt; 0.9).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:qcanca3"></span>
<img src="Figure%203.png" alt="Example of a necessity analysis with NCA (Data from @emmenegger2011job." width="100%" />
<p class="caption">
Figure 4.24: Example of a necessity analysis with NCA (Data from <span class="citation">Emmenegger (<a href="#ref-emmenegger2011job">2011</a>)</span>.
</p>
</div>
<p>However, the NCA analysis in degree with the six conditions and using the CE-FDH ceiling line (Figure <a href="dataanalysis.html#fig:qcanca3">4.24</a>) shows the following effect sizes and corresponding p values (Figure <a href="dataanalysis.html#fig:table2ncaqca">4.25</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:table2ncaqca"></span>
<img src="Table2ncaqca.png" alt="NCA necessity analysis. d = effect size; p = p value." width="100%" />
<p class="caption">
Figure 4.25: NCA necessity analysis. d = effect size; p = p value.
</p>
</div>
<p>A condition could be considered necessary when the effect size has a small p value (e.g., p &lt; 0.05). Hence, the NCA analysis shows that certain strength of labour movement (L), a certain level of denomination (R), and a certain strength of religious parties (P) are necessary for high levels of job security regulation (JSR). From Figure <a href="dataanalysis.html#fig:qcanca3">4.24</a> it can be observed that the following conditions are necessary for JSR &gt; 0.5:</p>
<ul>
<li><p>L &gt; 0.29 is necessary for JSR &gt; 0.5 (presence of JSR)</p></li>
<li><p>R &gt; 0.20 is necessary for JSR &gt; 0.5 (presence of JSR)</p></li>
<li><p>P &gt; 0.20 is necessary for JSR &gt; 0.5 (presence of JSR)</p></li>
</ul>
<p>Although in QCA’s binary logic these small necessary membership scores of L, R, P (all &lt; 0.5) would be framed as ‘absence’ of the condition, in NCA these membership scores are considered small, yet must be present for having the outcome. Thus, according to NCA the low level of membership scores must be present, otherwise the sufficient configurations identified by QCA will not produce the outcome.
Emmenegger (2010) identified four possible sufficient configurations for the outcome JSR:</p>
<ol style="list-style-type: decimal">
<li><p>S*R*~V (presence of S AND presence of R AND absence of V)</p></li>
<li><p>S*L*R*P (presence of S AND presence of L AND presence of R AND presence of P)</p></li>
<li><p>S*C*R*P (presence of S AND presence of C AND presence of R AND presence of P)</p></li>
<li><p>C*L*P*~V (presence of C AND presence of L AND presence of P AND absence of V)</p></li>
</ol>
<p>This combination of solutions can be expressed by the following logical expression:
S*R*~V + S*L*R*P + S*C*R*P + C*L*P*~V → JSR
The presence of a condition and the outcome means that the membership score is &gt; 0.5. The absence of a condition means that the membership score is &lt; 0.5. A common way to summarize the results is shown in Figure <a href="dataanalysis.html#fig:table3ncaqca">4.26</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:table3ncaqca"></span>
<img src="Table3ncaqca.png" alt="QCA sufficiency solutions (sufficient configurations)." width="100%" />
<p class="caption">
Figure 4.26: QCA sufficiency solutions (sufficient configurations).
</p>
</div>
<p>The NCA necessity results can be combined with the QCA sufficiency results as shown in Figure <a href="dataanalysis.html#fig:table4ncaqca">4.27</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:table4ncaqca"></span>
<img src="Table4ncaqca2.png" alt="NEST tool for combining QCA sufficiency results with NCA necessity results. NEST = NCA-Extended Solution Table. The extension consist of adding the symbol ◢ when the necessary condition in degree is missing in the sufficiency solution, and adding the column 'Necessity requirement' with the required level of the necessary condition." width="100%" />
<p class="caption">
Figure 4.27: NEST tool for combining QCA sufficiency results with NCA necessity results. NEST = NCA-Extended Solution Table. The extension consist of adding the symbol ◢ when the necessary condition in degree is missing in the sufficiency solution, and adding the column ‘Necessity requirement’ with the required level of the necessary condition.
</p>
</div>
<p>Figure <a href="dataanalysis.html#fig:table4ncaqca">4.27</a> presents the NEST tool, which is the NCA-Extended Solution Table. NEST signifies if a necessary condition ‘in degree’ is missing in the configuration. If so, the triangle symbol (◢) is added to the sufficient QCA configuration to ensure that the minimum required necessity membership score (according to NCA) is fulfilled such that the solution can produce the outcome. The triangle symbol ◢ for necessity ‘in degree’ differs from the square symbol ■ proposed by <span class="citation">Greckhamer (<a href="#ref-greckhamer2016ceo">2016</a>)</span>, and the diamond symbol <span class="math inline">\(\blacklozenge\)</span> used by <span class="citation">Holtrop et al. (<a href="#ref-holtrop2024increasing">2024</a>)</span>, which both indicate the presence of a necessary condition ‘in kind’ according to QCA’s necessity analysis. An additional column ‘Necessity requirement’ is added to ensure that the minimum required necessity membership score (according to NCA) is fulfilled such that the solution can produce the outcome. Note that a condition with 0.29 membership score is not interpreted in a binary ‘in kind’ way as the absence of the condition (although the score is &lt; 0.5), but as an ‘in degree’ interpretation where to condition is ‘somewhat’ (0.29) present, like a pinch of salt is necessary for a tasty cake.</p>
<p>The NCA results that the presence of L &gt; 0.29 is necessary for JSR &gt; 0.5 is already achieved in the QCA sufficient configurations 2 and 4, but not in configurations 1 and 3. In these latter configurations the requirement L &gt; 0.29 is added to the configuration (◢). Similarly, R &gt; 0.20 is added to configuration 4, and P &gt; 0.20 is added to configuration 1. Without adding these requirements to the configuration, the configuration cannot produce the outcome. Only configuration 2 includes all three necessary conditions according to NCA, without a need for adding them. If the results of NCA would be ignored and the QCA of configurations 1, 3 and 4 would not produce the outcome (or only by chance if the required minimum levels of the ignored NCA necessary conditions would be present by chance). Additionally, the NCA results can show what levels of the condition would be necessary for a higher level of the outcome than a membership score &gt; 0.5. This can be observed in Figure 3. For example, for a membership score of JSR of 0.9, it is necessary to have membership scores of S = 1, L &gt; 0.45, R = 1, P &gt; 0.2, and ~V &gt; 0.35.
I therefore recommend presenting the NCA necessity results together with the QCA sufficient configurations results as in Figure <a href="dataanalysis.html#fig:table4ncaqca">4.27</a>, and additionally to discuss the full results of NCA for deeper understanding of the sufficient configurations.</p>
<p>The second example is from a study of Skarmeas et al. (2014) that I discuss in my book (Dul, 2020, pp. 77-83). This study is about the effect of four organizational motives (Egoistic-driven motives, absence of Value-driven motives, Strategy-driven motives, Stakeholder-driven motives) on customer scepticism about an organization’s Corporate Social Responsibility (CSR) initiative. The results of NCA’s necessity analysis with raw scores, and with calibrated set membership scores are shown in Figure <a href="dataanalysis.html#fig:table5ncaqca">4.28</a> and Figure <a href="dataanalysis.html#fig:table6ncaqca">4.29</a>, respectively.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:table5ncaqca"></span>
<img src="Table5ncaqca.png" alt="NCA necessity analysis with raw scores." width="100%" />
<p class="caption">
Figure 4.28: NCA necessity analysis with raw scores.
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:table6ncaqca"></span>
<img src="Table6ncaqca.png" alt="NCA necessity analysis with calibrated cores." width="100%" />
<p class="caption">
Figure 4.29: NCA necessity analysis with calibrated cores.
</p>
</div>
<p>NCA with raw variable scores shows that Absence of Value-driven motives and Strategy-driven motives could be considered are necessary for Scepticism given the medium effect sizes and the small p values (p &lt; 0.05). Also, the NCA with calibrated set membership scores shows that these two conditions have low p values; however, their effect sizes are small (0.04 and 0.02, respectively). This means that these necessary conditions may be statistically significant but may not be practically significant: nearly all cases reached the required level of necessity. Also, Egoistic-driven motives are statistically, but not practically significant. NCA with raw variable scores (the conventional NCA approach) can be used in combination with regression analysis, as regression analysis uses raw variable scores. NCA with calibrated set scores (set membership scores) can be used in combination with QCA, because QCA uses calibrated set membership scores.</p>
<p>Figure <a href="dataanalysis.html#fig:table7ncaqca">4.30</a> shows the two sufficient configurations according the QCA analysis of <span class="citation">Skarmeas et al. (<a href="#ref-skarmeas2014examining">2014</a>)</span>.
(2014).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:table7ncaqca"></span>
<img src="Table7ncaqca.png" alt="Sufficient configurations (QCA) and necessity requirements (NCA) of the study by Skarmeas et al., 2014." width="100%" />
<p class="caption">
Figure 4.30: Sufficient configurations (QCA) and necessity requirements (NCA) of the study by Skarmeas et al., 2014.
</p>
</div>
<p>In each configuration the necessity of Egoistic-driven motives and the Absence of Valuedriven motives are ensured in the configuration. However, the necessity of Strategy-driven motives is not ensured in Sufficient configuration 1. Therefore, the minimum required level of Stakeholder-driven motives according to NCA (0.01) is added to ensure that the configuration is able to produce the outcome. However, the practical meaning of this addition is very limited because the necessity effect size is small. It is added here for illustration of our recommendation.</p>
</div>
<div id="misinterpretationsqca" class="section level3 hasAnchor" number="4.7.5">
<h3><span class="header-section-number">4.7.5</span> Logical misinterpretations when combining NCA and QCA<a href="dataanalysis.html#misinterpretationsqca" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When NCA is combined with QCA sometimes a logical misinterpretation is made about the role of necessary conditions in sufficient configurations. Although a factor that is a necessary condition for the outcome <em>must</em> be part of each sufficient configuration, the opposite is not true: a factor that is part of the sufficient configuration must <em>not</em> automatically be a necessary condition for the outcome. The latter misinterpretation has been introduced in the tourism and hospitality field <span class="citation">(<a href="#ref-dul2022problematic">Dul, 2022</a>)</span> and can be found for example in studyies by <span class="citation">Farmaki et al. (<a href="#ref-farmaki2022hotel">2022</a>)</span>, <span class="citation">Pappas &amp; Farmaki (<a href="#ref-pappas2022attributes">2022</a>)</span>, <span class="citation">Pappas &amp; Glyptou (<a href="#ref-pappas2021risk">2021b</a>)</span>, <span class="citation">Pappas &amp; Glyptou (<a href="#ref-pappas2021accommodation">2021a</a>)</span>, <span class="citation">Pappas (<a href="#ref-pappas2021covid19">2021</a>)</span>, and <span class="citation">Farmaki &amp; Pappas (<a href="#ref-farmaki2021poverty">2022</a>)</span>. The misinterpretation was also exported to other fields <span class="citation">(e.g., <a href="#ref-mostafiz2021configuring">Mostafiz et al., 2023</a>)</span>.</p>
<!-- In these articles NCA is applied to evaluate QCA's sufficient configurations by first applying QCA to identify sufficient configurations, then applying NCA to identify necessary conditions (although often not according to the basic guidelines, see Section \@ref(guidelines): without a threshold value for the effect size and without NCA's statistical test), and finally it is checked whether all factors in the sufficient configurations are also necessary conditions. If not, the sufficient configuration is rejected as a configuration that can produce the outcome, and the configuration is deleted from further analysis with QCA. This procedure is incorrect because it should not be checked whether *all factors that are part of the sufficient configuration are necessary conditions for the outcome* but instead it should be checked whether *all factors that are necessary conditions for the outcome are part of the sufficient configuration*. For example, @pappas2021risk find with fsQCA three possible sufficient configurations (consisting of five or six factors) for purchase intentions of holidaymakers. After performing NCA on all factors, the article excludes one configuration because, according to NCA, one of its factors (‘high scores in price risks’) is *not* a necessary condition for the outcome ‘purchase intention’. @pappas2021risk state: “Combined with the fsQCA results, the only solution that includes high scores in price risks is the first one …, meaning that this complex configuration should be excluded from further analysis” (p. 2942) and that "NCA has excluded" that configuration (p. 2945). However, a factor in the configuration not being a necessary condition for the outcome, is not a reason to exclude the configuration from further analysis.  -->
<p>This misinterpretation may be caused by mixing necessary conditions for the outcome (as analysed with NCA) with necessary parts of a sufficient configuration (INUS conditions). An INUS condition is an <em>Insufficient but Necessary part of an Unnecessary but Sufficient configuration</em>. INUS conditions are the necessary elements of a configuration to make that configuration sufficient. NCA captures necessary conditions for the outcome, not INUS conditions, see also <span class="citation">Dul, Vis, et al. (<a href="#ref-dul2021necessary">2021</a>)</span>.</p>
</div>
</div>
<div id="causalinference" class="section level2 hasAnchor" number="4.8">
<h2><span class="header-section-number">4.8</span> Causal inference<a href="dataanalysis.html#causalinference" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Applications of NCA often use cross-sectional research designs. In order to make a causal interpretation of findings from a cross-sectional study, several requirements need to be met. Cross-sectional studies observe cases at a single point in time without manipulating variables. This contrasts with experimental studies where potential causes are manipulated and effects are observed, which allows a direct causal interpretation. Cross-sectional studies can infer causality only indirectly if certain criteria are fulfilled. These criteria include: relevant association, temporal sequence, theoretical plausibility, and control of confounders. Because of the way that necessity is defined, NCA findings are immune to confounding because the observed necessity relationship is not influenced by including or excluding other variables. Therefore, the three main requirements for inferring causality from an NCA cross-sectional study are (1) observing a relevant association, (2) justifying a temporal sequence, and (3) formulating a plausible theory.</p>
<!-- ^[In terms of the Directed Acyclic Graphs (DAGs) framework of @pearl2009causality, the backdoor path of a potential confounder disappears, because $X = 0$ blocks all influence on $Y$.] -->
<p>In NCA the requirement for observing a relevant association between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> means observing that one of the corners of an <span class="math inline">\(XY\)</span> plot is empty (rather than observing a correlation). When it is expected that the presence of <span class="math inline">\(X\)</span> is necessary for the presence of <span class="math inline">\(Y\)</span> the expected empty corner is in the upper left corner.</p>
<p>The requirement for observing a relevant association can be satisfied by having proper values of NCA’s effect size (e.g., <span class="math inline">\(d\geq0.10\)</span>) representing practical relevance and p value (e.g., <span class="math inline">\(p\leq0.05\)</span>) representing statistical relevance.</p>
<p>The requirement for justifying the temporal sequence implies that there must be evidence that <span class="math inline">\(X\)</span> precedes <span class="math inline">\(Y\)</span>: first <span class="math inline">\(X\)</span> then <span class="math inline">\(Y\)</span>. If <span class="math inline">\(X\)</span> precedes <span class="math inline">\(Y\)</span>, the empty space is compatible with <span class="math inline">\(X\)</span> being necessary for <span class="math inline">\(Y\)</span>. However, if <span class="math inline">\(Y\)</span> precedes <span class="math inline">\(X\)</span> the empty space is compatible with <span class="math inline">\(Y\)</span> being sufficient for <span class="math inline">\(X\)</span> (reverse causality). If both directions can be theoretically justified the empty space may be compatible with reciprocal (bi-directional) causality: <span class="math inline">\(X\)</span> is necessary for <span class="math inline">\(Y\)</span>, and <span class="math inline">\(Y\)</span> is sufficient for <span class="math inline">\(X\)</span>. The requirement for justifying a temporal sequence can be satisfied as part of the formulation of a plausible theory (see below).</p>
<p>The requirement for formulating a plausible theory implies that there should be a rational explanation how <span class="math inline">\(X\)</span> is a necessary cause for <span class="math inline">\(Y\)</span>. This means that the expected causal direction and the causal mechanism are explained theoretically. This requirement is usually satisfied by formulating a hypothesis for example “the presence of <span class="math inline">\(X\)</span> is a necessary cause for the presence of <span class="math inline">\(Y\)</span>”, while specifying and justifying the temporal direction, and explaining the mechanism why this relationship exists. Explaining the necessity mechanism can be done by explaining the <em>enabling</em> mechanism why cases with the outcome must have the condition, or by explaining the <em>constraining</em> mechanism why cases without the condition cannot have the outcome and why the absence of this condition is not compensible.</p>
<p>If the above requirements are not convincingly met, an alternative research design may be selected to infer causality. In order of increasing confidence, this can be the time-lagged study design in which <span class="math inline">\(X\)</span> is measured first followed by <span class="math inline">\(Y\)</span>, the longitudinal study design in which <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are measured in multiple points in time, and the experimental study design in which <span class="math inline">\(X\)</span> is manipulated and the effect on <span class="math inline">\(Y\)</span> is observed.</p>
<p>In practical applications of NCA each of the following requirements need to be fulfilled to interpret an empty space as a necessary causal condition:</p>
<ol style="list-style-type: decimal">
<li>Theoretical support that <span class="math inline">\(X\)</span> is a necessary cause for <span class="math inline">\(Y\)</span> (causal direction, mechanism).</li>
<li>The corresponding empty space is relevant (e.g., <span class="math inline">\(d \geq 0.10\)</span>).</li>
<li>The p value of the empty space is small (e.g., p <span class="math inline">\(\leq 0.05\)</span>).</li>
</ol>
<p>If one of the conditions is not met, it cannot be concluded that there is empirical evidence for necessity causality.</p>
</div>
<div id="metaanalysis" class="section level2 hasAnchor" number="4.9">
<h2><span class="header-section-number">4.9</span> Meta-analysis<a href="dataanalysis.html#metaanalysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Given the growth of NCA publications (see Figure <a href="index.html#fig:pubs">0.1</a> and Table <a href="index.html#tab:pubstable">0.1</a>), it can become a realistic option to conduct a meta-analysis of NCA studies for a specific topic. The general aim of a meta-analysis is to systematically combine results from multiple independent studies that address the same research question. A common goal is to estimate an overall effect size across studies by combining results from different samples. This gives an estimate of the ‘true’ effect size in an underlying population from which the samples are assumed to be drawn. This is done, by estimating an overall mean effect size using weighting of the effect sizes of the different samples (e.g., based on sample size). In other words, a weighted average is used as an estimate of the overall effect size. The assumption is made that the effect sizes can be compared (e.g., in each study the <span class="math inline">\(XY\)</span> variables are measured on the same scale), and that there is no measurement error.</p>
<p>However, this approach does not apply to NCA because the sample necessity effect size is always larger than the true effect size, such that the weighted average of the sample effect sizes is not a proper representation of the true effect size. Instead, with the same assumptions as in a regular meta-analysis (no measurement error, comparable effect sizes), and an additional assumption that the scopes of the separate studies are the same (empirically or by setting the same theoretical scope for each study), the minimum of the sample effect sizes might be the best representation of the true effect size. Alternatively, and probably even more convincing, all samples could be combined into one master sample (as they are assumed coming from the same population) and then the effect size of the combined sample could be the estimation of the true effect size. Such meta-analysis is called an “individual participant meta-analysis” (IPD meta-analysis) and assumes that raw data are available. If it cannot be assumed that the samples are from the same (underlying) population, then differences in sample effect sizes could be explained by the different characteristics of the population. If absence of measurement error cannot be assumed, then an NCA outlier-analysis may possibly find cases with measurement error that could have partly caused sample effect size differences (and could be deleted).</p>
<!-- ## multilevel analysis {#multilevel} -->
<!-- due to nested data structure and other dependencies: -->
<!-- - regression line at student level is biased if school effects (or other dependencies) are not taken into account (confounding) -->
<!-- - ceiling line at student level is not biased even if school effect are not taken into account -->
<!-- - statistical test for regression is strongly biased (too small p-value) -->
<!-- - statistical test for NCA is weakly biased (too small -pvalue) -->
<!-- exchangebility assumption is weaker than idd assumtion  -->
<!-- Should be a section about group comparisons. -->
<!-- some groups are independent others are dependent (how?) -->
<!-- Whether a sample is considered independent or dependent depends on how you define your theoretical domain, population and theoretical scope. -->
<!-- Statistical dependence is always relative to the defined population and sampling unit. -->
<!-- Because NCA’s significance test (permutation test) is nonparametric and only assumes exchangeability of the outcome variable — not independence of residuals, normality, or linearity like regression does. -->
<!-- In other words: -->
<!-- Regression requires strong, model-based assumptions to calculate standard errors. -->
<!-- NCA simply shuffles data and compares the observed pattern to random patterns — which is more robust, though not immune to dependence. -->
<!-- 1. What does regression assume? -->
<!-- Observations are independent and identically distributed (i.i.d.) -->
<!-- Residuals are independent, normally distributed, and homoscedastic (equal variance) -->
<!-- Coefficients and p-values rely on parametric inference (t-distribution, F-distribution) -->
<!-- Even small violations of independence (e.g., from clustering) can severely bias standard errors → inflated p-values -->
<!-- What does NCA assume? -->
<!-- NCA uses a permutation test, which assumes: -->
<!-- The null hypothesis is true (no necessity) -->
<!-- The Y-values (outcome) are exchangeable — i.e., their position relative to X doesn’t matter under the null -->
<!-- It does not assume: -->
<!-- A specific distribution -->
<!-- Linearity -->
<!-- Homoscedasticity -->
<!-- Additivity -->
<!-- Residual independence in the regression sense -->
<!-- Fewer and weaker assumptions overall -->
<!-- What Is Exchangeability? -->
<!-- Exchangeability is a weaker version of independence. -->
<!-- It means: -->
<!-- The joint probability distribution of the data does not change when you shuffle the Y-values -->
<!-- So under the null (no necessity), it shouldn't matter where you assign each Y to an X -->
<!-- This is less strict than full independence, but: -->
<!-- Still violated by clustering (e.g., students from the same school with similar Y-values) -->
<!-- Can still lead to biased p-values in permutation tests -->
<!-- Summary: Why Independence Is Weaker in NCA -->
<!-- Feature    Regression  NCA -->
<!-- Type of test   Parametric  Nonparametric (permutation) -->
<!-- Requires residual independence?    Yes No -->
<!-- Assumes linearity, normality, etc.?     Yes     No -->
<!-- Core assumption    i.i.d. errors   Exchangeability of outcomes -->
<!-- Violation of independence → impact  Strong (biases SEs)     Moderate (can bias p-values if dependence is strong) -->
<!-- Independence is a weaker assumption in NCA because: -->
<!-- NCA does not model residuals -->
<!-- It relies on distribution-free, rank-based testing -->
<!-- The permutation test is robust to many forms of irregularity -->
<!-- But: strong clustering or structured dependence can still bias significance testing, so it's not assumption-free -->
<!-- permutation test assumes iid -->
<!-- - multilevel: students versus school/teacher -->
<!-- - gender -->
<!-- - pre-post with same group -->
<!-- - different industries -->
<!-- - longitudinal data; same people measured twice -->
<!-- independent": -->
<!-- - two random samples from the same population -->
<!-- - a random sub-sample from a population -->
<!-- - Two samples from different populations -->
<!-- separate schools with no shared teachers, policies, or students. -->
<!-- Multilevel analysis is used in regression analysis when cases are grouped, for example students within schools or patients within hospitals. This means that the data structured at more than one level (nested).  -->
<!-- Two issues: -->
<!-- - biased regression coefficient / ceiling line -->
<!-- - biased significance test  -->
<!-- Consequently, the regression assumption that data points are independent is violated and a multilevel analysis must be done to account for individual-level and group-level effects.  -->
<!-- Violation of the independence assumption results in more similar observations, reduced variability, smaller standard errors and thus make effect look more significant than they actually are.  -->
<!-- Also the regression coefficient may be biased when group variables  -->
<!-- that affect the outcome (school funding, teacher quality) are not included in the regression model. -->
<!-- In NCA  -->
<!-- - having more similar observ  -->
<!-- - hypothesis for a specific domain  -->
<!-- - universal constraint in the population -->
<!-- - subgroups -->
<!-- Since NCA predicts the ceiling line, but not the variability in the cloud of cases below the ceiling line, having similar observations does not effect the ceiling line and is problemeatic,  -->

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0" line-spacing="2">
<div id="ref-benjamin2018redefine" class="csl-entry">
Benjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., et al. (2018). Redefine statistical significance. <em>Nature <span>H</span>uman <span>B</span>ehaviour</em>, <em>2</em>(1), 6–10. <a href="https://doi.org/10.1038/s41562-017-0189-z">https://doi.org/10.1038/s41562-017-0189-z</a>
</div>
<div id="ref-berry1993understanding" class="csl-entry">
Berry, W. D. (1993). <em>Understanding regression assumptions</em> (Vol. 92). Sage. <a href="https://us.sagepub.com/en-us/nam/book/understanding-regression-assumptions">https://us.sagepub.com/en-us/nam/book/understanding-regression-assumptions</a>
</div>
<div id="ref-bokrantz2022building" class="csl-entry">
Bokrantz, J., &amp; Dul, J. (2023). Building and testing necessity theories in supply chain management. <em>Journal of Supply Chain Management</em>, <em>59</em>, 48–65. <a href="https://doi.org/10.1111/jscm.12287">https://doi.org/10.1111/jscm.12287</a>
</div>
<div id="ref-bouquet2008weight" class="csl-entry">
Bouquet, C., &amp; Birkinshaw, J. (2008). Weight versus voice: How foreign subsidiaries gain attention from corporate headquarters. <em>Academy of Management Journal</em>, <em>51</em>(3), 577–601. <a href="https://www.jstor.org/stable/20159527">https://www.jstor.org/stable/20159527</a>
</div>
<div id="ref-dul2016jbr" class="csl-entry">
Dul, J. (2016a). Identifying single necessary conditions with <span>NCA</span> and fs<span>QCA</span>. <em>Journal of Business Research</em>, <em>69</em>(4), 1516–1523. <a href="https://doi.org/10.1016/j.jbusres.2015.10.134">https://doi.org/10.1016/j.jbusres.2015.10.134</a>
</div>
<div id="ref-dul2016orm" class="csl-entry">
Dul, J. (2016b). <span>Necessary Condition Analysis</span> (<span>NCA</span>): Logic and methodology of <span>“necessary but not sufficient”</span> causality. <em>Organizational Research Methods</em>, <em>19</em>(1), 10–52. <a href="https://doi.org/10.1177/1094428115584005">https://doi.org/10.1177/1094428115584005</a>
</div>
<div id="ref-dul2020book" class="csl-entry">
Dul, J. (2020). <em><span>Conducting Necessary Condition Analysis</span>.</em> Sage. <a href="https://uk.sagepub.com/en-gb/eur/conducting-necessary-condition-analysis-for-business-and-management-students/book262898">https://uk.sagepub.com/en-gb/eur/conducting-necessary-condition-analysis-for-business-and-management-students/book262898</a>
</div>
<div id="ref-dul2022problematic" class="csl-entry">
Dul, J. (2022). Problematic applications of <span>Necessary Condition Analysis</span> (<span>NCA</span>) in tourism and hospitality research. <em>Tourism Management</em>, <em>93</em>, 104616. <a href="https://doi.org/10.1016/j.tourman.2022.104616">https://doi.org/10.1016/j.tourman.2022.104616</a>
</div>
<div id="ref-dul2024different" class="csl-entry">
Dul, J. (2024a). A different causal perspective with <span>Necessary Condition Analysis</span>. <em>Journal of Business Research</em>, <em>177</em>, 114618. <a href="https://doi.org/10.1016/j.jbusres.2024.114618">https://doi.org/10.1016/j.jbusres.2024.114618</a>
</div>
<div id="ref-dul2021marketing" class="csl-entry">
Dul, J., Hauff, S., &amp; Tóth, Z. (2021). <span>Necessary Condition Analysis</span> in marketing research. In R. Nunkoo, V. Teeroovengadum, &amp; C. Ringle (Eds.), <em>Handbook of research methods for marketing management</em> (pp. 51–72). Edward Elgar Publishing. <a href="https://www.e-elgar.com/shop/gbp/handbook-of-research-methods-for-marketing-management-9781788976947.html">https://www.e-elgar.com/shop/gbp/handbook-of-research-methods-for-marketing-management-9781788976947.html</a>
</div>
<div id="ref-dul2021necessary" class="csl-entry">
Dul, J., Vis, B., &amp; Goertz, G. (2021). <span>N</span>ecessary <span>C</span>ondition <span>A</span>nalysis <span>(NCA)</span> does exactly what it should do when applied properly: A reply to a comment on <span>NCA</span>. <em>Sociological Methods &amp; Research</em>, <em>50</em>(2), 926–936. <a href="https://doi.org/10.1177%2F0049124118799383">https://doi.org/10.1177%2F0049124118799383</a>
</div>
<div id="ref-emmenegger2011job" class="csl-entry">
Emmenegger, P. (2011). Job security regulations in western democracies: A fuzzy set analysis. <em>European Journal of Political Research</em>, <em>50</em>(3), 336–364. <a href="https://doi.org/10.1111/j.1475-6765.2010.01933.x">https://doi.org/10.1111/j.1475-6765.2010.01933.x</a>
</div>
<div id="ref-farmaki2021poverty" class="csl-entry">
Farmaki, A., &amp; Pappas, N. (2022). Poverty and tourism decision-making: A chaordic perspective. <em>International Journal of Contemporary Hospitality Management</em>, <em>34</em>(3), 1012–1036. <a href="https://doi.org/10.1108/IJCHM-07-2021-0859">https://doi.org/10.1108/IJCHM-07-2021-0859</a>
</div>
<div id="ref-farmaki2022hotel" class="csl-entry">
Farmaki, A., Pappas, N., Kvasova, O., &amp; Stergiou, D. P. (2022). Hotel CSR and job satisfaction: A chaordic perspective. <em>Tourism Management</em>, <em>91</em>, 104526. <a href="https://doi.org/10.1016/j.tourman.2022.104526">https://doi.org/10.1016/j.tourman.2022.104526</a>
</div>
<div id="ref-galton1886regression" class="csl-entry">
Galton, F. (1886). Regression towards mediocrity in hereditary stature. <em>The Journal of the Anthropological Institute of Great Britain and Ireland</em>, <em>15</em>, 246–263. <a href="https://www.jstor.org/stable/2841583">https://www.jstor.org/stable/2841583</a>
</div>
<div id="ref-greckhamer2016ceo" class="csl-entry">
Greckhamer, T. (2016). CEO compensation in relation to worker compensation across countries: The configurational impact of country-level institutions. <em>Strategic Management Journal</em>, <em>37</em>(4), 793–815. <a href="https://doi.org/10.1002/smj.2370">https://doi.org/10.1002/smj.2370</a>
</div>
<div id="ref-hauff2024importance" class="csl-entry">
Hauff, S., Richter, N. F., Sarstedt, M., &amp; Ringle, C. M. (2024). Importance and performance in <span>PLS-SEM</span> and <span>NCA</span>: Introducing the combined importance-performance map analysis <span class="nocase">(cIPMA)</span>. <em>Journal of Retailing and Consumer Services</em>, <em>78</em>, 103723. <a href="https://doi.org/10.1016/j.jretconser.2024.103723">https://doi.org/10.1016/j.jretconser.2024.103723</a>
</div>
<div id="ref-hogan2002hogan" class="csl-entry">
Hogan, R., &amp; Hogan, J. (2007). <em>The <span>Hogan Personality Inventory</span> manual (3rd ed.)</em>. Hogan Assessment Systems, Tulsa, OK.
</div>
<div id="ref-holtrop2024increasing" class="csl-entry">
Holtrop, J. S., Mullen, R., Curcija, K., Rubinson, C., Westfall, J. M., Nease Jr, D. E., &amp; Zittleman, L. (2024). Increasing medication assisted treatment in rural primary care practice: A qualitative comparative analysis from IT MATTTRs colorado. <em>Frontiers in Medicine</em>, <em>11</em>, 1450672. <a href="https://doi.org/10.3389/fmed.2024.1450672">https://doi.org/10.3389/fmed.2024.1450672</a>
</div>
<div id="ref-lu2014robustness" class="csl-entry">
Lu, X., &amp; White, H. (2014). Robustness checks and robustness tests in applied economics. <em>Journal of Econometrics</em>, <em>178</em>, 194–206. <a href="https://doi.org/10.1016/j.jeconom.2013.08.016">https://doi.org/10.1016/j.jeconom.2013.08.016</a>
</div>
<div id="ref-mackie1965causes" class="csl-entry">
Mackie, J. L. (1965). Causes and conditions. <em>American Philosophical Quarterly</em>, <em>2</em>(4), 245–264. <a href="https://www.jstor.org/stable/20009173">https://www.jstor.org/stable/20009173</a>
</div>
<div id="ref-mello2021qualitative" class="csl-entry">
Mello, P. A. (2021). <em>Qualitative comparative analysis: An introduction to research design and application</em>. Georgetown University Press. <a href="http://press.georgetown.edu/book/georgetown/qualitative-comparative-analysis">http://press.georgetown.edu/book/georgetown/qualitative-comparative-analysis</a>
</div>
<div id="ref-mostafiz2021configuring" class="csl-entry">
Mostafiz, M. I., Sambasivan, M., Goh, S.-K., &amp; Ahmad, P. (2023). Configuring foreign market knowledge and opportunity recognition capabilities to predict the performance of export-manufacturing firms. <em>Knowledge Management Research &amp; Practice</em>, <em>21</em>(2), 316–330. <a href="https://doi.org/10.1080/14778238.2021.1919573">https://doi.org/10.1080/14778238.2021.1919573</a>
</div>
<div id="ref-mwesiumo2025identifying" class="csl-entry">
Mwesiumo, D. (in press). Identifying critical factors in higher education studies: Combining necessary condition and importance-performance map analyses. <em>Studies in Higher Education</em>. <a href="https://doi.org/10.1080/03075079.2025.2478948">https://doi.org/10.1080/03075079.2025.2478948</a>
</div>
<div id="ref-pappas2021covid19" class="csl-entry">
Pappas, N. (2021). COVID19: Holiday intentions during a pandemic. <em>Tourism Management</em>, <em>84</em>, 104287. <a href="https://doi.org/10.1016/j.tourman.2021.104287">https://doi.org/10.1016/j.tourman.2021.104287</a>
</div>
<div id="ref-pappas2022attributes" class="csl-entry">
Pappas, N., &amp; Farmaki, A. (2022). Attributes attitudes and chaordic travel intentions during COVID-19. <em>Current Issues in Tourism</em>, <em>25</em>(24), 4014–4030. <a href="https://doi.org/10.1080/13683500.2022.2056004">https://doi.org/10.1080/13683500.2022.2056004</a>
</div>
<div id="ref-pappas2021accommodation" class="csl-entry">
Pappas, N., &amp; Glyptou, K. (2021a). Accommodation decision-making during the COVID-19 pandemic: Complexity insights from greece. <em>International Journal of Hospitality Management</em>, <em>93</em>, 102767. <a href="https://doi.org/10.1016/j.ijhm.2020.102767">https://doi.org/10.1016/j.ijhm.2020.102767</a>
</div>
<div id="ref-pappas2021risk" class="csl-entry">
Pappas, N., &amp; Glyptou, K. (2021b). Risk-induced competitive productivity in times of recession: A chaordic tourism decision-making perspective. <em>International Journal of Contemporary Hospitality Management</em>, <em>33</em>(9), 2932–2949. <a href="https://doi.org/10.1108/IJCHM-09-2020-1046">https://doi.org/10.1108/IJCHM-09-2020-1046</a>
</div>
<div id="ref-ragin1987comparative" class="csl-entry">
Ragin, C. C. (1987). <em>The comparative method: Moving beyond qualitative and quantitative strategies</em>. JSTOR. <a href="https://www.jstor.org/stable/10.1525/j.ctt1pnx57?turn_away=true">https://www.jstor.org/stable/10.1525/j.ctt1pnx57?turn_away=true</a>
</div>
<div id="ref-ragin2000fuzzy" class="csl-entry">
Ragin, C. C. (2000). <em>Fuzzy-set social science</em>. University of Chicago Press. <a href="https://press.uchicago.edu/ucp/books/book/chicago/F/bo3635786.html">https://press.uchicago.edu/ucp/books/book/chicago/F/bo3635786.html</a>
</div>
<div id="ref-ragin2009redesigning" class="csl-entry">
Ragin, C. C. (2008). <em>Redesigning social inquiry: Fuzzy sets and beyond</em>. University of Chicago Press. <a href="https://press.uchicago.edu/ucp/books/book/chicago/R/bo5973952.html">https://press.uchicago.edu/ucp/books/book/chicago/R/bo5973952.html</a>
</div>
<div id="ref-richter2023dataset" class="csl-entry">
Richter, N. F., Hauff, S., Kolev, A. E., &amp; Schubring, S. (2023). Dataset on an extended technology acceptance model: A combined application of <span>PLS-SEM</span> and <span>NCA</span>. <em>Data in Brief</em>, <em>48</em>, 109190. <a href="https://doi.org/10.1016/j.dib.2023.109190">https://doi.org/10.1016/j.dib.2023.109190</a>
</div>
<div id="ref-richter2022use" class="csl-entry">
Richter, N. F., Hauff, S., Ringle, C. M., &amp; Gudergan, S. P. (2022). The use of partial least squares structural equation modeling and complementary methods in international management research. <em>Management International Review</em>, <em>62</em>(4), 449–470. <a href="https://doi.org/10.1007/s11575-022-00475-0">https://doi.org/10.1007/s11575-022-00475-0</a>
</div>
<div id="ref-richter2023apply" class="csl-entry">
Richter, N. F., Hauff, S., Ringle, C. M., Sarstedt, M., Kolev, A. E., &amp; Schubring, S. (2023). How to apply necessary condition analysis in <span>PLS-SEM</span>. In <em>Partial least squares path modeling: Basic concepts, methodological issues and applications</em> (pp. 267–297). Springer. <a href="https://link.springer.com/chapter/10.1007/978-3-031-37772-3_10">https://link.springer.com/chapter/10.1007/978-3-031-37772-3_10</a>
</div>
<div id="ref-richter2020predictors" class="csl-entry">
Richter, N. F., Schubring, S., Hauff, S., Ringle, C. M., &amp; Sarstedt, M. (2020). When predictors of outcomes are necessary: Guidelines for the combined use of <span>PLS-SEM</span> and <span>NCA</span>. <em>Industrial Management &amp; Data Systems</em>, <em>120</em>(12), 2243–2267. <a href="https://doi.org/10.1108/IMDS-11-2019-0638">https://doi.org/10.1108/IMDS-11-2019-0638</a>
</div>
<div id="ref-ringle2016gain" class="csl-entry">
Ringle, C. M., &amp; Sarstedt, M. (2016). Gain more insight from your <span>PLS-SEM</span> results: The importance-performance map analysis. <em>Industrial Management &amp; Data Systems</em>, <em>116</em>(9), 1865–1886. <a href="https://doi-org.eur.idm.oclc.org/10.1108/IMDS-10-2015-0449">https://doi-org.eur.idm.oclc.org/10.1108/IMDS-10-2015-0449</a>
</div>
<div id="ref-rohlfing2013improving" class="csl-entry">
Rohlfing, I., &amp; Schneider, C. Q. (2013). Improving research on necessary conditions: Formalized case selection for process tracing after <span>QCA</span>. <em>Political Research Quarterly</em>, <em>66</em>(1), 220–235. <a href="https://www.jstor.org/stable/23563606">https://www.jstor.org/stable/23563606</a>
</div>
<div id="ref-sarstedt2024combined" class="csl-entry">
Sarstedt, M., Richter, N. F., Hauff, S., &amp; Ringle, C. M. (2024). Combined importance–performance map analysis <span class="nocase">(cIPMA)</span> in partial least squares structural equation modeling <span>(PLS–SEM)</span>: A <span>SmartPLS</span> 4 tutorial. <em>Journal of Marketing Analytics</em>, <em>12</em>, 746–760. <a href="https://doi.org/10.1057/s41270-024-00325-y">https://doi.org/10.1057/s41270-024-00325-y</a>
</div>
<div id="ref-schneider2012set" class="csl-entry">
Schneider, C. Q., &amp; Wagemann, C. (2012). <em>Set-theoretic methods for the social sciences: A guide to qualitative comparative analysis</em>. Cambridge University Press. <a href="https://www.cambridge.org/nl/academic/subjects/social-science-research-methods/qualitative-methods/set-theoretic-methods-social-sciences-guide-qualitative-comparative-analysis?format=PB">https://www.cambridge.org/nl/academic/subjects/social-science-research-methods/qualitative-methods/set-theoretic-methods-social-sciences-guide-qualitative-comparative-analysis?format=PB</a>
</div>
<div id="ref-schubring2023extended" class="csl-entry">
Schubring, S., &amp; Richter, N. (2023). <em>Extended TAM</em> (Version V4). Mendeley Data. <a href="https://doi.org/10.17632/pd5dp3phx2.4">https://doi.org/10.17632/pd5dp3phx2.4</a>
</div>
<div id="ref-skarmeas2014examining" class="csl-entry">
Skarmeas, D., Leonidou, C. N., &amp; Saridakis, C. (2014). Examining the role of CSR skepticism using fuzzy-set qualitative comparative analysis. <em>Journal of Business Research</em>, <em>67</em>(9), 1796–1805. <a href="https://doi.org/10.1016/j.jbusres.2013.12.010">https://doi.org/10.1016/j.jbusres.2013.12.010</a>
</div>
<div id="ref-vis2018analyzing" class="csl-entry">
Vis, B., &amp; Dul, J. (2018). Analyzing relationships of necessity not just in kind but also in degree: Complementing fs<span>QCA</span> with <span>NCA</span>. <em>Sociological Methods &amp; Research</em>, <em>47</em>(4), 872–899. <a href="https://doi.org/10.1177/0049124115626179">https://doi.org/10.1177/0049124115626179</a>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>See for example the advise “While a non-significant effect provides evidence that a total effect is zero in the population, researchers should retain the corresponding construct in the IPMA since this outcome may also represent a valuable finding (e.g., a company invests into the performance of a construct that has no effect), which also can change with different data, for instance, in alternative contexts of the analysis” <span class="citation">(<a href="#ref-ringle2016gain">Ringle &amp; Sarstedt, 2016, p. 1872</a>)</span>, and the practice of the example in <span class="citation">Hauff et al. (<a href="#ref-hauff2024importance">2024</a>)</span> that includes non-significant total effects in CIPMA<a href="dataanalysis.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>This aligns with NCA’s recommendation that the absence of any of the three critical requirements for support for necessity falsifies the necessary condition claim: the absence of theoretical support (no necessity hypothesis), the absence of a practically relevant effect size (e.g., <span class="math inline">\(d &lt; 0.10\)</span>), and a statistically non-significant necessity effect size (e.g., <span class="math inline">\(p &gt; 0.05\)</span>).<a href="dataanalysis.html#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mathematical.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": true,
    "weibo": true,
    "instapaper": false,
    "vk": false,
    "whatsapp": true,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "serif",
    "size": 2
  },
  "edit": null,
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  },
  "info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
